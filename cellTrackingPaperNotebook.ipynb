{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27824,"status":"ok","timestamp":1700589352665,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"},"user_tz":-330},"id":"Kd1WPPjX7LO5","outputId":"1e44eda4-c64d-440f-caa0-e2f13f4ae26a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# !pip install libtiff\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","\n","# from libtiff import TIFF\n","from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","import numpy as np\n","import os\n","import glob\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.models as models\n","import shutil\n","import pandas as pd\n","import random\n","import math\n","import cv2\n","from sklearn.model_selection import StratifiedKFold, KFold\n","from PIL import Image\n","import copy,time\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","CNNDIM = 2048\n","TIMESTAMPDIM = 128\n","STATEDIM = 128"]},{"cell_type":"code","source":["!ls \"/content/drive/My Drive/Cell Tracking/\" |grep -i \"\\.json$\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P68plbw2KUFr","executionInfo":{"status":"ok","timestamp":1699450831011,"user_tz":-330,"elapsed":486,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}},"outputId":"fd914ca1-82eb-4046-c28d-9f913f0a82f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train6.json\n","train.json\n","train_new_1.json\n","train_new_2.json\n","train_new_3.json\n","val6.json\n","val.json\n","val_new_1.json\n","val_new_2.json\n","val_new_3.json\n"]}]},{"cell_type":"code","source":["dataset='original_3'"],"metadata":{"id":"98OKpdANXCDT","executionInfo":{"status":"ok","timestamp":1700589352665,"user_tz":-330,"elapsed":4,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"sH5So0P_7Pcl","executionInfo":{"status":"ok","timestamp":1700589354282,"user_tz":-330,"elapsed":1620,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"361aca70-a6b6-45e5-a703-925808099260"},"outputs":[{"output_type":"stream","name":"stdout","text":["no. of train files: 260\n","no. of val files: 10\n"]}],"source":["path = \"/content/drive/My Drive/Cell Tracking/CellTracking1\"\n","import json\n","\n","dataset_paths={\n","    'original_3':{\n","        'train':\"/content/drive/My Drive/Cell Tracking/train.json\",\n","        'val':\"/content/drive/My Drive/Cell Tracking/val.json\"\n","    },\n","    'lsd1':{\n","        'train':\"/content/drive/My Drive/Cell Tracking/train_new_1.json\",\n","        'val':\"/content/drive/My Drive/Cell Tracking/val_new_1.json\"\n","    },\n","    'lsm710':{\n","       'train':\"/content/drive/My Drive/Cell Tracking/train_new_2.json\",\n","       'val':\"/content/drive/My Drive/Cell Tracking/val_new_2.json\"\n","    },\n","    'nikonxlight':{\n","       'train':\"/content/drive/My Drive/Cell Tracking/train_new_3.json\",\n","       'val':\"/content/drive/My Drive/Cell Tracking/val_new_3.json\"\n","    },\n","    'recql4':{\n","       'train':\"/content/drive/My Drive/Cell Tracking/train_new_4.json\",\n","       'val':\"/content/drive/My Drive/Cell Tracking/val_new_4.json\"\n","    }\n","}\n","\n","train_files = []\n","val_files = []\n","\n","# for filename in os.listdir(path):\n","#   mask_names = []\n","#   raw_names = []\n","\n","#   for p in sorted(os.listdir(path+\"/\"+filename+\"/Mask\")):\n","#     mask_names.append(path+\"/\"+filename+\"/Mask/\"+p)\n","#   for p in sorted(os.listdir(path+\"/\"+filename+\"/Raw\")):\n","#     raw_names.append(path+\"/\"+filename+\"/Raw/\"+p)\n","\n","#   df = pd.read_csv(path+\"/\"+filename+\"/\"+filename+\"_Synchronization.csv\")\n","#   vals=tuple(map(lambda x:int(x),df.columns[0].split(';')))\n","#   mask_names = tuple(mask_names)\n","#   raw_names = tuple(raw_names)\n","\n","#   random_variable = random.random()\n","#   if random_variable<0.05:\n","#     val_files.append((raw_names,mask_names,vals))\n","#   else:\n","#     train_files.append((raw_names,mask_names,vals))\n","\n","with open(dataset_paths[dataset]['train']) as f:\n","  train_files = json.load(f)\n","\n","with open(dataset_paths[dataset]['val']) as f:\n","  val_files = json.load(f)\n","\n","print(f\"no. of train files: {len(train_files)}\")\n","print(f\"no. of val files: {len(val_files)}\")"]},{"cell_type":"code","source":["def clean_files(files:list):\n","  cnt=0\n","  temp_files=[]\n","  for i,data in enumerate(files):\n","    if len(data[0])==len(data[2]) and len(data[2])!=0:\n","      temp_files.append(data)\n","  return temp_files\n","\n","train_files=clean_files(train_files)\n","val_files=clean_files(val_files)\n","\n","print(f\"no. of train files: {len(train_files)}\")\n","print(f\"no. of val files: {len(val_files)}\")"],"metadata":{"id":"vWYyUvURZERD","executionInfo":{"status":"ok","timestamp":1700589354282,"user_tz":-330,"elapsed":7,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"03a1847a-7fdb-435d-8513-0c89037728b3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["no. of train files: 260\n","no. of val files: 10\n"]}]},{"cell_type":"code","source":["# from collections import Counter\n","\n","# for l in train_files:\n","#   one_index=-1\n","#   two_index=-1\n","#   three_index=-1\n","#   try:\n","#     one_index=l[2].index(1)\n","#   except:\n","#     pass\n","#   try:\n","#     two_index=l[2].index(2)\n","#   except:\n","#     pass\n","#   try:\n","#     three_index=l[2].index(3)\n","#   except:\n","#     pass\n","\n","#   all_counts=Counter(l[2])\n","#   if (min(all_counts.values())>=20):\n","#     print(all_counts)\n","#   print(two_index-one_index,three_index-two_index,len(l[2])-three_index)"],"metadata":{"id":"Mp6WeMp5WED-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OG78lcU9k1KD"},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, max_len, d_model):\n","        super().__init__()\n","        position = torch.arange(max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n","        self.pe = torch.zeros(1,max_len, d_model)\n","        self.pe[0,:, 0::2] = torch.sin(position * div_term)\n","        self.pe[0,: ,1::2] = torch.cos(position * div_term)\n","        self.pe = nn.Parameter(self.pe)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Args:\n","            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n","        \"\"\"\n","        x = x + self.pe\n","        return x\n","\n","class TransformerLayer(nn.Module):\n","    def __init__(self,max_len,d_model,num_heads):\n","      super().__init__()\n","      self.mha = nn.MultiheadAttention(d_model,num_heads,dropout=0.1,batch_first=True)\n","\n","      self.norm1 = nn.LayerNorm(d_model)\n","      self.norm2 = nn.LayerNorm(d_model)\n","      self.linear1 = nn.Linear(in_features=d_model,out_features=d_model//2)\n","      self.linear2 = nn.Linear(in_features=d_model//2,out_features=d_model)\n","\n","      self.relu = nn.ReLU()\n","\n","    def forward(self,query):\n","      out1 = query+self.mha(query=query,key=query,value=query)[0]\n","      out1 = self.norm1(out1)\n","\n","      out2 = self.linear1(out1)\n","      out2 = self.relu(out2)\n","      out2 = self.linear2(out2)\n","      out2 = self.relu(out2)\n","      out2 = self.norm2(out2+out1)\n","\n","      return out2\n","\n","\n","class Transformer(nn.Module):\n","    def __init__(self,max_len,d_model,num_heads,num_layers):\n","      super().__init__()\n","      self.pos = PositionalEncoding(max_len+1,d_model)\n","      self.cls = nn.Parameter(torch.randn(1,1,d_model))\n","      self.layers = nn.ModuleList([TransformerLayer(max_len,d_model,num_heads) for _\n","                                  in range(num_layers)])\n","\n","    def forward(self,query):\n","      cls = self.cls.expand((query.size(0),1,self.cls.size(2)))\n","      query = torch.cat([cls,query],dim=1)\n","      query = self.pos(query)\n","      for layer in self.layers:\n","        query = layer(query)\n","\n","      extracted_cls = query[:,0,:]\n","      return extracted_cls"]},{"cell_type":"markdown","metadata":{"id":"RsMn78YYCUeq"},"source":["# Checking Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gDBYyMZ1XUtW"},"outputs":[],"source":["for folder_index in range(len(train_files)):\n","  max_val_folder=None\n","  min_val_folder=None\n","  for file_name in train_files[folder_index][0]:\n","    arr=np.array(Image.open(file_name))\n","    file_name=file_name.split('/')[-1]\n","    if np.any(np.isnan(arr)):\n","      print(f\"nan detected at {file_name} of folder_index:{folder_index}\")\n","      input(\"Enter to continue!!!\")\n","    # if max_val_folder is None:\n","    #   max_val_folder=np.max(arr)\n","    # max_val_folder=max(max_val_folder,np.max(arr))\n","    # if min_val_folder is None:\n","    #   min_val_folder=np.min(arr)\n","    # min_val_folder=min(min_val_folder,np.min(arr))\n","    print(f\"{folder_index} {file_name} {np.max(arr)} {np.min(arr)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EoWXxaIFIyKf"},"outputs":[],"source":["im_arr=np.array(Image.open(\"/content/drive/My Drive/Cell Tracking/CellTracking1/\"+\"cell_0054/Raw/cell_0054_t=032_Raw.png\"))\n","plt.imshow(im_arr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h2ERlcbUey1b"},"outputs":[],"source":["import torch.utils.model_zoo as model_zoo\n","from torch.nn import init\n","\n","__all__ = ['xception']\n","\n","model_urls = {\n","    'xception':'https://www.dropbox.com/s/1hplpzet9d7dv29/xception-c0a72b38.pth.tar?dl=1'\n","}\n","\n","\n","class SeparableConv2d(nn.Module):\n","    def __init__(self,in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False):\n","        super(SeparableConv2d,self).__init__()\n","\n","        self.conv1 = nn.Conv2d(in_channels,in_channels,kernel_size,stride,padding,dilation,groups=in_channels,bias=bias)\n","        self.pointwise = nn.Conv2d(in_channels,out_channels,1,1,0,1,1,bias=bias)\n","\n","    def forward(self,x):\n","        x = self.conv1(x)\n","        x = self.pointwise(x)\n","        return x\n","\n","\n","class Block(nn.Module):\n","    def __init__(self,in_filters,out_filters,reps,strides=1,start_with_relu=True,grow_first=True):\n","        super(Block, self).__init__()\n","\n","        if out_filters != in_filters or strides!=1:\n","            self.skip = nn.Conv2d(in_filters,out_filters,1,stride=strides, bias=False)\n","            self.skipbn = nn.BatchNorm2d(out_filters)\n","        else:\n","            self.skip=None\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        rep=[]\n","\n","        filters=in_filters\n","        if grow_first:\n","            rep.append(self.relu)\n","            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n","            rep.append(nn.BatchNorm2d(out_filters))\n","            filters = out_filters\n","\n","        for i in range(reps-1):\n","            rep.append(self.relu)\n","            rep.append(SeparableConv2d(filters,filters,3,stride=1,padding=1,bias=False))\n","            rep.append(nn.BatchNorm2d(filters))\n","\n","        if not grow_first:\n","            rep.append(self.relu)\n","            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n","            rep.append(nn.BatchNorm2d(out_filters))\n","\n","        if not start_with_relu:\n","            rep = rep[1:]\n","        else:\n","            rep[0] = nn.ReLU(inplace=False)\n","\n","        if strides != 1:\n","            rep.append(nn.MaxPool2d(3,strides,1))\n","        self.rep = nn.Sequential(*rep)\n","\n","    def forward(self,inp):\n","        x = self.rep(inp)\n","\n","        if self.skip is not None:\n","            skip = self.skip(inp)\n","            skip = self.skipbn(skip)\n","        else:\n","            skip = inp\n","\n","        x+=skip\n","        return x\n","\n","\n","\n","class Xception(nn.Module):\n","    \"\"\"\n","    Xception optimized for the ImageNet dataset, as specified in\n","    https://arxiv.org/pdf/1610.02357.pdf\n","    \"\"\"\n","    def __init__(self, num_classes=1000):\n","        \"\"\" Constructor\n","        Args:\n","            num_classes: number of classes\n","        \"\"\"\n","        super(Xception, self).__init__()\n","\n","\n","        self.num_classes = num_classes\n","\n","        self.conv1 = nn.Conv2d(3, 32, 3,2, 0, bias=False)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.conv2 = nn.Conv2d(32,64,3,bias=False)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        #do relu here\n","\n","        self.block1=Block(64,128,2,2,start_with_relu=False,grow_first=True)\n","        self.block2=Block(128,256,2,2,start_with_relu=True,grow_first=True)\n","        self.block3=Block(256,728,2,2,start_with_relu=True,grow_first=True)\n","\n","        self.block4=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n","        self.block5=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n","        self.block6=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n","        self.block7=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n","\n","        self.block8=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n","        self.block9=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n","        self.block10=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n","        self.block11=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n","\n","        self.block12=Block(728,1024,2,2,start_with_relu=True,grow_first=False)\n","\n","        self.conv3 = SeparableConv2d(1024,1536,3,1,1)\n","        self.bn3 = nn.BatchNorm2d(1536)\n","\n","        #do relu here\n","        self.conv4 = SeparableConv2d(1536,2048,3,1,1)\n","        self.bn4 = nn.BatchNorm2d(2048)\n","\n","        self.fc = nn.Linear(2048, num_classes)\n","\n","\n","\n","        #------- init weights --------\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","        #-----------------------------\n","\n","\n","\n","\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.relu(x)\n","\n","        x = self.block1(x)\n","        x = self.block2(x)\n","        x = self.block3(x)\n","        x = self.block4(x)\n","        x = self.block5(x)\n","        x = self.block6(x)\n","        x = self.block7(x)\n","        x = self.block8(x)\n","        x = self.block9(x)\n","        x = self.block10(x)\n","        x = self.block11(x)\n","        x = self.block12(x)\n","\n","        x = self.conv3(x)\n","        x = self.bn3(x)\n","        x = self.relu(x)\n","\n","        x = self.conv4(x)\n","        x = self.bn4(x)\n","        x = self.relu(x)\n","\n","        x = F.adaptive_avg_pool2d(x, (1, 1))\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","\n","        return x\n","\n","\n","\n","def xception(pretrained=True,**kwargs):\n","    \"\"\"\n","    Construct Xception.\n","    \"\"\"\n","\n","    model = Xception(**kwargs)\n","    if pretrained:\n","        model.load_state_dict(model_zoo.load_url(model_urls['xception']))\n","\n","    model.fc = nn.Identity()\n","    for param in model.parameters():\n","      param.requires_grad = False\n","    return model\n","\n","\n","import torch.nn as nn\n","\n","\n","class TimeDistributed(nn.Module):\n","    def __init__(self, module, batch_first=True):\n","        super(TimeDistributed, self).__init__()\n","        self.module = module\n","        self.batch_first = batch_first\n","\n","    def forward(self, x):\n","\n","        if len(x.size()) <= 2:\n","            return self.module(x)\n","\n","        # Squash samples and timesteps into a single axis\n","        x_reshape = x.contiguous().view(-1, x.size(-3),x.size(-2),x.size(-1))  # (samples * timesteps, input_size)\n","\n","        y = self.module(x_reshape)\n","\n","        # We have to reshape Y\n","        if self.batch_first:\n","            y = y.contiguous().view(x.size(0), -1, y.size(-1))  # (samples, timesteps, output_size)\n","        else:\n","            y = y.view(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)\n","\n","        return y\n","\n","\n","class CnnTransformer(nn.Module):\n","  def __init__(self,max_len,d_model,num_heads,num_layers):\n","    super().__init__()\n","    self.cnn = TimeDistributed(xception())\n","    self.transformer = Transformer(max_len,d_model,num_heads,num_layers)\n","    self.embed = nn.Embedding(90,TIMESTAMPDIM)\n","    self.embed2 = nn.Embedding(3,STATEDIM)\n","\n","  def forward(self,x,timestamps,cellStates):\n","    timestamps = self.embed(timestamps)\n","    cellStates = self.embed2(cellStates)\n","\n","    x = self.cnn(x)\n","    x = torch.concat([x,timestamps,cellStates],dim=-1)\n","    x = self.transformer(x)\n","\n","    return x"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"xtBY1Y16b2gV","executionInfo":{"status":"ok","timestamp":1700589354282,"user_tz":-330,"elapsed":5,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}}},"outputs":[],"source":["from PIL import Image\n","# import tsfresh as ts\n","\n","MAXFUTURE = 5\n","NUMFRAMES = 5\n","DMODEL = 2048\n","NUM = 10\n","\n","def getImageFromPath(path):\n","  im=Image.open(path)\n","  t = transforms.ToTensor()(im)\n","  t = transforms.Resize((256,256))(t)\n","  t = torch.concat([t,t,t],dim=0)/torch.max(t)\n","  # raise Exception(\"divide by max\")\n","  return t\n","\n","class GetDataset(Dataset):\n","  def __init__(self,index_list):\n","    self.index_list = index_list\n","    self.normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5],\n","                                  std=[0.5, 0.5, 0.5])\n","\n","  def __len__(self):\n","    return 1000\n","\n","  def __getitem__(self,idx):\n","    video = random.choice(self.index_list)\n","    num_frames = len(video[2])\n","\n","    indices = sorted(random.sample(range(0,num_frames-MAXFUTURE),NUMFRAMES))\n","\n","    imageArr = [self.normalize(getImageFromPath(video[0][i]).float()) for i in indices]\n","    timeStampArr = indices\n","    cellStateArr = [video[2][i]-1 for i in indices]\n","\n","\n","    imageArr = torch.stack(imageArr,dim=0)\n","    timeStampArr = torch.as_tensor(timeStampArr)\n","    cellStateArr = torch.as_tensor(cellStateArr)\n","\n","    timeFuture = random.choice(range(0,MAXFUTURE))\n","    predLabel = torch.as_tensor(video[2][indices[-1]+timeFuture]-1)\n","\n","    timeFuture = torch.as_tensor(timeFuture)\n","\n","    imageArr = imageArr.to(device).float()\n","    timeStampArr = timeStampArr.type(torch.LongTensor).to(device)\n","    cellStateArr = cellStateArr.type(torch.LongTensor).to(device)\n","    timeFuture = timeFuture.type(torch.LongTensor).to(device)\n","    predLabel = predLabel.to(device)\n","\n","\n","    return imageArr,timeStampArr,cellStateArr,timeFuture,predLabel\n","\n","def getStatistics(tensor,model):\n","  out = model(tensor)\n","  len = out.size(0)\n","  # index = list(range(0,len))\n","  # id = [0 for i in range(0,len)]\n","  # column = list(range(0,DMODEL))\n","\n","  # data = out.cpu().detach().numpy()\n","  # df0 = pd.DataFrame(data = data,index=index,columns=column)\n","\n","  # df0['id'] = id\n","  # df0['ind'] = index\n","\n","  # features=ts.extract_features(out[0],column_id=\"ind\", column_sort=\"id\", column_kind=None, column_value=None)\n","  mean = torch.mean(out,dim=0)\n","  std = torch.std(out,dim=0)\n","\n","  return torch.concat([mean,std],axis=0)\n","\n","class GetStatDataset(Dataset):\n","  def __init__(self,index_list,model):\n","    super().__init__()\n","    self.index_list = index_list\n","    self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    self.model = model\n","\n","  def __len__(self):\n","    return 10000\n","\n","  def __getitem__(self,ind):\n","    ind = random.choice(self.index_list)\n","    bin = random.choice([1,2,3])\n","\n","    lists = dict()\n","    lists[1] = [i for i in range(len(ind[2])) if ind[2][i]==1]\n","    lists[2] = [i for i in range(len(ind[2])) if ind[2][i]==2]\n","    lists[3] = [i for i in range(len(ind[2])) if ind[2][i]==3]\n","\n","    imageInd = random.sample(lists[bin],max(min(random.randint(0,len(lists[bin])-1),5),2))\n","\n","    imageArr = [self.normalize(getImageFromPath(ind[0][i]).float()) for i in imageInd]\n","    imageArr = torch.stack(imageArr,dim=0)\n","\n","    pred = torch.as_tensor(bin-1)\n","    imageArr = imageArr.to(device)\n","    ret = getStatistics(imageArr,self.model)\n","\n","    return ret,pred.to(device)\n","\n","class getGNNDataset(Dataset):\n","  def __init__(self,index_list,model):\n","    super().__init__()\n","    self.index_list = index_list\n","    self.model = model\n","    self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    self.len_=100\n","\n","  def __len__(self):\n","    return self.len_\n","\n","  def set_len(self,len_):\n","    self.len_=len_\n","\n","  def __getitem__(self,idx):\n","    ind = random.choice(self.index_list)\n","    # startInd = random.choice(list(range(0,len(ind[2])-NUM-1)))\n","    # startInd=random.randint(0,len(ind[2])-NUM-1)\n","    # imageInd = list(range(startInd,startInd+NUM))\n","\n","    num0 = len([i for i in range(len(ind[2])-NUM) if ind[2][i+NUM]==1 ])\n","    num1 = len([i for i in range(len(ind[2])-NUM) if ind[2][i+NUM]==2 ])\n","    num2 = len([i for i in range(len(ind[2])-NUM) if ind[2][i+NUM]==3 ])\n","\n","    weights = []\n","\n","    # for i in range(num0):\n","    #   weights.append(1/(3*num0))\n","\n","    # for i in range(num1):\n","    #   weights.append(1/(3*num1))\n","\n","    # for i in range(num2):\n","    #   weights.append(1/(3*num2))\n","\n","    for i in range(len(ind[2])-NUM):\n","      if ind[2][i+NUM]==1:\n","        weights.append(1/(3*num0))\n","      elif ind[2][i+NUM]==2:\n","        weights.append(1/(3*num1))\n","      else:\n","        weights.append(1/(3*num2))\n","\n","    startInd = random.choices(list(range(0,len(ind[2])-NUM)),weights=weights,k=1)[0]\n","    imageInd=range(startInd,startInd+NUM)\n","\n","    imageArr = [self.normalize(getImageFromPath(ind[0][i]).float()) for i in imageInd]\n","    imageArr=torch.stack(imageArr,dim=0)\n","\n","    timeStampArr = imageInd\n","    timeStampArr = torch.as_tensor(timeStampArr)\n","    timeStampArr = timeStampArr.type(torch.LongTensor).to(device)\n","\n","    cellStateArr = [ind[2][i]-1 for i in imageInd]\n","    cellStateArr = torch.as_tensor(cellStateArr)\n","    cellStateArr = cellStateArr.type(torch.LongTensor).to(device)\n","\n","\n","    predNext = torch.as_tensor(ind[2][startInd+NUM]-1)\n","\n","    imageArr = imageArr.to(device)\n","    predNext = predNext.float().to(device)\n","    return imageArr,timeStampArr,cellStateArr,predNext\n","\n","def get_video_dict(indexes,model):\n","  return_dict = dict()\n","  return_dict[0] = list()\n","  return_dict[1] = list()\n","  return_dict[2] = list()\n","\n","  normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                 std=[0.229, 0.224, 0.225])\n","\n","  ind = random.choice(indexes)\n","  indices = list(range(0,len(ind[2])))\n","\n","  for i in indices:\n","    img = getImageFromPath(ind[0][i]).float().to(device)\n","    img = normalize(img.unsqueeze(0))\n","\n","    ret = model(img).squeeze(0)\n","    return_dict[ind[2][i]-1].append(ret.cpu().detach().numpy())\n","\n","  temp_0 = np.array(return_dict[0])\n","  temp_1 = np.array(return_dict[1])\n","  temp_2 = np.array(return_dict[2])\n","\n","  index_0 = list(range(0,len(return_dict[0])))\n","  index_1 = list(range(0,len(return_dict[1])))\n","  index_2 = list(range(0,len(return_dict[2])))\n","\n","  column = list(range(0,DMODEL))\n","\n","  df0 = pd.DataFrame(data = temp_0,index=index_0,columns=column)\n","  df1 = pd.DataFrame(data = temp_1,index=index_1,columns=column)\n","  df2 = pd.DataFrame(data = temp_2,index=index_2,columns=column)\n","\n","  df0['id'] = index_0\n","  df1['id'] = index_1\n","  df2['id'] = index_2\n","\n","  df0['ind'] = [0 for i in index_0]\n","  df1['ind'] = [1 for i in index_1]\n","  df2['ind'] = [2 for i in index_2]\n","\n","  return_dict[0] = df0\n","  return_dict[1] = df1\n","  return_dict[2] = df2\n","\n","  return return_dict\n"]},{"cell_type":"code","source":["vgg16=models.vgg16(pretrained=True)\n","vgg16.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n","vgg16.classifier=nn.Identity()\n","# vgg16.classifier[6]=nn.Identity()\n","\n","# for param in vgg16.parameters():\n","#   param.requires_grad = False\n","vgg16.to(device)\n","vgg16"],"metadata":{"id":"e11Njes7jRTh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZOUJ7Iox4tvO"},"outputs":[],"source":["\n","# import tsfresh as ts\n","vgg16 = None\n","if vgg16 is not None:\n","  del(vgg16)\n","vgg16 = models.resnet50(pretrained=True)\n","vgg16.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n","vgg16.fc = nn.Flatten()\n","vgg16=vgg16.to(device)\n","vgg16\n","# out = get_video_dict(train_files,vgg16)\n","# features = dict()\n","# del(out)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U3KJHNmrHsvT"},"outputs":[],"source":["densenet=models.densenet121(pretrained=True)\n","densenet.classifier=nn.Identity()\n","# for param in densenet.parameters():\n","#   param.requires_grad=False\n","densenet.to(device)\n","densenet"]},{"cell_type":"code","source":["class ScaledInception(nn.Module):\n","  def __init__(self,_size=(512,512)):\n","    super().__init__()\n","\n","    self.scaler=transforms.Resize(_size)\n","    self.inception=models.inception_v3(pretrained=True)\n","    self.inception.fc=nn.Identity()\n","\n","  def forward(self,x):\n","    return self.inception(self.scaler(x))[0] # get only the linear layer output and ignore the aux_logits\n","\n","\n","scaled_inception=ScaledInception((512,512))\n","scaled_inception.to(device)\n","scaled_inception"],"metadata":{"id":"k3rrPSE3NJMj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vit=models.maxvit_t(pretrained=True)\n","vit.classifier=nn.Identity()\n","vit.to(device)\n","vit"],"metadata":{"id":"o_A4XoiyOh2v"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"noilFpfKdv3m"},"outputs":[],"source":["class PredNet(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.cnnTransformer = CnnTransformer(5,CNNDIM+TIMESTAMPDIM+STATEDIM,2,4)\n","    self.embedding = nn.Embedding(90,TIMESTAMPDIM)\n","\n","    self.fc1 = nn.Sequential(\n","        nn.Linear(CNNDIM+TIMESTAMPDIM+STATEDIM,1024),\n","        nn.ReLU(),\n","        nn.Linear(1024,512)\n","    )\n","\n","    self.fc2 = nn.Sequential(\n","        nn.Linear(512+TIMESTAMPDIM,256),\n","        nn.ReLU(),\n","        nn.Linear(256,128),\n","        nn.ReLU(),\n","        nn.Linear(128,64),\n","        nn.ReLU(),\n","        nn.Linear(64,3)\n","    )\n","\n","  def forward(self,imageArr,timeStampArr,cellStateArr,timeFuture):\n","    feat = self.cnnTransformer(imageArr,timeStampArr,cellStateArr)\n","    feat = self.fc1(feat)\n","\n","    embedding = self.embedding(timeFuture)\n","\n","    feat = torch.cat([feat,embedding],dim=1)\n","    feat = self.fc2(feat)\n","    return feat\n","\n","class Mlp(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.seq = nn.Sequential(\n","        nn.Linear(2*DMODEL,DMODEL),\n","        nn.ReLU(),\n","        nn.Linear(DMODEL,DMODEL//2),\n","        nn.ReLU(),\n","        nn.Linear(DMODEL//2,DMODEL//4),\n","        nn.ReLU(),\n","        nn.Linear(DMODEL//4,DMODEL//8),\n","        nn.ReLU(),\n","        nn.Linear(DMODEL//8,3)\n","    )\n","\n","  def forward(self,x):\n","    return self.seq(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gBI4kNszH3BI"},"outputs":[],"source":["model = Mlp()\n","model.to(device)\n","dataset = GetStatDataset(train_files,vgg16)\n","loader = DataLoader(dataset,batch_size=4)\n","adam = torch.optim.Adam(model.parameters(),lr=0.0001)"]},{"cell_type":"code","source":["DIM=512\n","\"\"\"\n","  VGG16: 512\n","  RESNET50:2048\n","  RESNET18:512\n","  DENSENET201:1920\n","  DENSENET161:2208\n","  DENSENET121:1024\n","  INCEPTION:2048\n","\"\"\"\n","CLASS=3"],"metadata":{"id":"W9fNfoA2m9q1","executionInfo":{"status":"ok","timestamp":1700589354283,"user_tz":-330,"elapsed":5,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# ContrastiveLossResnet"],"metadata":{"id":"X_G93R5-ylQB"}},{"cell_type":"code","source":["\n","\n","class CenterLoss(nn.Module):\n","    def __init__(self, num_classes=CLASS, feat_dim=DIM, use_gpu=True):\n","        super(CenterLoss, self).__init__()\n","        self.num_classes = num_classes\n","        self.feat_dim = feat_dim\n","        self.use_gpu = use_gpu\n","\n","        if self.use_gpu:\n","            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).cuda())\n","        else:\n","            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim))\n","\n","    def forward(self, x, labels):\n","        batch_size = x.size(0)\n","        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n","                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n","        distmat.addmm_(1, -2, x, self.centers.t())\n","\n","        classes = torch.arange(self.num_classes).long()\n","        if self.use_gpu: classes = classes.cuda()\n","        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n","        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n","\n","        dist = distmat * mask.float()\n","        loss = dist.clamp(min=1e-12, max=1e+12).sum() / batch_size\n","\n","        return x,loss\n","\n","class finalModel(nn.Module):\n","  def __init__(self,baseline,classifier):\n","    super().__init__()\n","    self.baseline = baseline\n","    self.classifier = classifier\n","    self.centre = CenterLoss()\n","\n","  def forward(self,x,trueLabels):\n","    feats = self.baseline(x)\n","    feats,loss = self.centre(feats,trueLabels)\n","    preds = self.classifier(feats)\n","    return preds,loss\n","\n","contrastive_resnet_model= torch.load(\"/content/drive/My Drive/Cell Tracking/classifier3_centerresnet18_2_final.pth\").baseline.to(device)\n","contrastive_resnet_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HDH1k1Meyf3Y","executionInfo":{"status":"ok","timestamp":1700589440300,"user_tz":-330,"elapsed":6277,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}},"outputId":"87eae263-9cb7-4fd5-c275-5f237b0c317d"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Identity()\n",")"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["!ls \"/content/drive/My Drive/Cell Tracking/\" | grep -i \"^classifier3_\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1VhaNdsC5Db","executionInfo":{"status":"ok","timestamp":1700589357525,"user_tz":-330,"elapsed":7,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}},"outputId":"afe347a1-0b55-47e4-f9cc-75ba4350efa6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["classifier3_centerresnet18_2_final_lsd1.pth\n","classifier3_centerresnet18_2_final_lsd2.pth\n","classifier3_centerresnet18_2_final_lsd3.pth\n","classifier3_centerresnet18_2_final_lsd4.pth\n","classifier3_centerresnet18_2_final.pth\n","classifier3_centerresnet50_2_final_lsd2.pth\n","classifier3_centerresnet50_2_final_lsd3.pth\n","classifier3_centervgg16_2_final_lsd1.pth\n","classifier3_centerVgg16_2_final_lsd2.pth\n","classifier3_centerVgg16_2_final_lsd3.pth\n","classifier3_centerVgg16_2_final_lsd4.pth\n","classifier3_centreresnet_2_final.pth\n","classifier3_centreresnet_2.pth\n","classifier3_centreresnet50_2_final_lsd1.pth\n","classifier3_centreresnet50_2_final.pth\n","classifier3_centreresnet.pth\n","classifier3_centrevgg16_2_final.pth\n","classifier3_contrastivecentrevgg16_2_final.pth\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q8Nodl0BhevE","colab":{"base_uri":"https://localhost:8080/","height":217},"executionInfo":{"status":"error","timestamp":1699465944539,"user_tz":-330,"elapsed":532,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}},"outputId":"29896530-587c-4150-c10d-3c7b11621730"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-81-efe4eca5baa1>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"After epoch {i} loss is {l} and acc is {a}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'loader' is not defined"]}],"source":["class Trainer:\n","  stepsPerEpoch = 50\n","\n","  def __init__(self,model,dataLoader,optimizer):\n","    self.history = dict()\n","    self.model = model\n","    self.optimizer = optimizer\n","    self.loader = dataLoader\n","\n","  def train_one_epoch(self):\n","    loader = iter(self.loader)\n","    running_loss=0\n","    running_acc = 0\n","\n","    for i in range(Trainer.stepsPerEpoch):\n","      # imgs,timeStamps,cellStates,timeFuture,trueLabel = loader.next()\n","      imgs,trueLabel = loader.next()\n","\n","      self.optimizer.zero_grad()\n","      # pred = self.model(imgs,timeStamps,cellStates,timeFuture)\n","      pred = self.model(imgs)\n","      loss = nn.CrossEntropyLoss()(pred,trueLabel)\n","      loss.backward()\n","      self.optimizer.step()\n","\n","      t = trueLabel.cpu().detach().numpy()\n","      p = pred.cpu().detach().numpy()\n","      p = np.argmax(p,axis=1)\n","      # print(t)\n","      # print(p)\n","\n","      running_acc+=(np.sum((p==t).astype(float)))/4\n","      running_loss+=loss.item()\n","\n","    return running_loss/Trainer.stepsPerEpoch,running_acc/Trainer.stepsPerEpoch\n","\n","  def train(self,epochs):\n","    for i in range(epochs):\n","      l,a = self.train_one_epoch()\n","\n","      self.history[i] = dict()\n","      self.history[i]['loss'] = l\n","\n","      print(f\"After epoch {i} loss is {l} and acc is {a}\")\n","\n","train = Trainer(model,loader,adam)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7bINabeeiBZh"},"outputs":[],"source":["gnn_data=getGNNDataset(index_list=train_files,model=None)\n","gnn_data_loader=DataLoader(gnn_data,batch_size=4,shuffle=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"0y1v4tEt3mRM","executionInfo":{"status":"ok","timestamp":1700589440300,"user_tz":-330,"elapsed":3,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}}},"outputs":[],"source":["#the main differene of this implementation is that the gso is changing throughout the training\n","\n","# 2.1\n","\n","def FilterFunction(h, S, x):\n","    #x->(b,n,f)\n","    K = h.shape[0]\n","    B = x.shape[0]\n","    N = x.shape[1]\n","    f=  x.shape[2]\n","\n","    # x = x.reshape([B, 1, N])\n","    #(b,f,n)\n","    x=x.permute(0,2,1)\n","    S = S.reshape([B, N, N]) #### change since resnet\n","    z = h[0]*x\n","    running_x=x\n","    for k in range(1, K):\n","      runnning_x=torch.matmul(x,S)\n","      z+=h[k]*running_x\n","    return z.permute(0,2,1)\n","\n","# 2.2\n","\n","class GraphFilter(nn.Module):\n","    def __init__(self, gso, k):\n","        super().__init__()\n","        self.gso = torch.tensor(gso)\n","        self.n = gso.shape[0]\n","        self.k = k\n","        self.weight = nn.Parameter(torch.randn(self.k))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        stdv = 1. / (math.sqrt(self.k)+1e-5)\n","        self.weight.data.uniform_(-stdv, stdv)\n","\n","    def forward(self, mix_x_gso):\n","        x,gso=mix_x_gso\n","        return FilterFunction(self.weight, gso, x)\n","\n","# 3.1\n","\n","class GraphPerceptron(nn.Module):\n","    def __init__(self, gso, k, sigma):\n","        super().__init__()\n","        self.gso = torch.tensor(gso)\n","        self.n = gso.shape[0]\n","        self.k = k\n","        self.sigma = sigma\n","        self.weight = nn.Parameter(torch.randn(self.k))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        stdv = 1. / (math.sqrt(self.k)+1e-5)\n","        self.weight.data.uniform_(-stdv, stdv)\n","\n","    def forward(self, mix_x_gso):\n","        # print(mix_x_gso)\n","        x,gso=mix_x_gso\n","        y = FilterFunction(self.weight, gso, x)\n","        y = self.sigma(y)\n","        return (y,gso)\n","\n","# 3.2\n","\n","class MLGNN(nn.Module):\n","    def __init__(self, gso, l, k, sigma):\n","        super().__init__()\n","        layers = []\n","        for layer in range(l):\n","            layers.append(GraphPerceptron(gso, k, sigma))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, mix_x_gso):\n","        x,gso=mix_x_gso\n","        y = self.layers((x,gso))\n","        return y\n","\n","class f_to_1_combiner(nn.Module):\n","  def __init__(self,gso,k,sigma,f,f_=1):\n","    super().__init__()\n","    self.gso=gso\n","    self.k=k\n","    self.sigma=sigma\n","    self.f=f\n","    self.f_=f_\n","    self.weights=nn.Parameter(torch.randn((k,self.f,self.f_)))#k,f,g\n","\n","\n","  def forward(self,mix_x_gso):\n","    x,gso=mix_x_gso\n","    # x -> (b,n,f)\n","    b,n,f=x.shape\n","    gso=gso.reshape([-1,n,n])\n","\n","    running_x=x\n","    y=torch.zeros((b,n,self.f_),dtype=torch.float32).to(device)\n","    for k in range(self.k):\n","      y+=torch.matmul(running_x,self.weights[k])\n","      running_x=torch.matmul(gso,running_x) #unsure about the dimension here\n","\n","    y=self.sigma(y)\n","    y=y.reshape([b,n,self.f_])\n","    return y\n","\n","class simple_nn(nn.Module):\n","  def __init__(self,in_size,hid_size,out_size):\n","    super().__init__()\n","    layers=[\n","        nn.Linear(in_size,hid_size),\n","        # nn.ReLU(),\n","        nn.Tanh(),\n","        nn.Linear(hid_size,hid_size),\n","        # nn.ReLU(),\n","        nn.Tanh(),\n","        nn.Linear(hid_size,hid_size),\n","        # nn.ReLU(),\n","        nn.Tanh(),\n","        nn.Linear(hid_size,out_size),\n","        # nn.ReLU()\n","    ]\n","    self.layers=nn.Sequential(*layers)\n","\n","  def forward(self,x):\n","    #b,n format\n","    return self.layers(x)\n","\n","class CombinedLayers(nn.Module):\n","    def __init__(self,gso,l,k,sigma,f,f_,in_size,hid_size,out_size):\n","      super().__init__()\n","      self.graph_layer=MLGNN(gso,l,k,sigma)\n","      self.combiner_layer=f_to_1_combiner(gso,k,sigma,f,f_)\n","      self.fc=simple_nn(f_*in_size,hid_size,out_size)\n","\n","    def forward(self,mix_x_gso):\n","      x,gso=mix_x_gso\n","      x=self.graph_layer((x,gso))\n","      x=self.combiner_layer(x)\n","      x=torch.flatten(x,start_dim=1)\n","      x=self.fc(x)\n","\n","      return x\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"eZfxewCe5oGY","executionInfo":{"status":"ok","timestamp":1700589440300,"user_tz":-330,"elapsed":2,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}}},"outputs":[],"source":["# one_data = getGNNDataset(train_files,model=None)[0]\n","\n","def get_augmented_data(feature_model,imageArr,timeStampArr,cellStateArr,predNext):\n","  listy=[feature_model(i.unsqueeze(0)).view(1,DIM) for i in imageArr]#[1,3,256,256]\n","  listy=torch.cat(listy,dim=0)\n","  x=torch.cat([listy,timeStampArr.view(-1,1),cellStateArr.view(-1,1)],dim=1)#.view(dtype=torch.float32)\n","  # x=x.cpu()\n","  # print(x.shape)\n","  return x.detach(),predNext\n","\n","def get_normalized_gso(gso):\n","  n,_=gso.shape\n","  d_sqrt_inv=torch.zeros(n,n).to(device)\n","  for i in range(n):\n","    d_sqrt_inv[i][i]=1/(torch.sum(gso[i])+1e-5)\n","  d_sqrt_inv=torch.sqrt(d_sqrt_inv)\n","  # d_sqrt_inv = d_sqrt_inv.to(device)\n","  # print(gso)\n","  # return ((torch.eye(n).to(device)-d_sqrt_inv) @ gso @ d_sqrt_inv).float()\n","  return ((torch.eye(n).to(device)-d_sqrt_inv @ gso @ d_sqrt_inv)).float() ####change here since resnet\n","\n","def get_gso(x):\n","  n,_=x.shape\n","  gso=torch.zeros((n,n),dtype=torch.float32)\n","  sim=nn.CosineSimilarity(dim=0)\n","  for i in range(n):\n","    for j in range(i+1,n):\n","      # gso[i][j]=sim(x[i],x[j]) #####change since resnet\n","      gso[i][j]=sim(x[i],x[j])*0.5+0.5\n","      gso[j][i]=gso[i][j]\n","\n","  ##### change since new resnet\n","  gso=(gso-torch.mean(gso))/(torch.std(gso)+1e-9)\n","  gso=gso-torch.min(gso)\n","\n","  #change this normalizing scheme\n","  gso = gso.to(device)\n","  gso=get_normalized_gso(gso).to(device)\n","  # eigenvalues, _ = np.linalg.eig(gso)\n","  # gso=gso / (np.max(eigenvalues.real)+1e-5)\n","\n","  # gso = gso/torch.norm(gso) ####change here since resnet\n","  return gso\n","\n","# x,p=get_augmented_data(*one_data)\n","# print(x.shape)\n","# print(p.shape)"]},{"cell_type":"code","source":["def smoothen_labels(y_real,epsilon,tot_classes):\n","  return (1-epsilon)*y_real+(epsilon/tot_classes)*torch.ones_like(y_real)\n","\n","__random_y=torch.randn(5,3)\n","__random_y=(__random_y==torch.max(__random_y,axis=1)[0].reshape(5,1)).to(__random_y.dtype)\n","print(__random_y,smoothen_labels(__random_y,0.1,3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A12ePb5AzHN1","executionInfo":{"status":"ok","timestamp":1700589440927,"user_tz":-330,"elapsed":2,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}},"outputId":"119d2a08-16b5-40e5-9a07-2a1ebcdc253d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., 1., 0.],\n","        [0., 0., 1.],\n","        [0., 0., 1.],\n","        [1., 0., 0.],\n","        [0., 0., 1.]]) tensor([[0.0333, 0.9333, 0.0333],\n","        [0.0333, 0.0333, 0.9333],\n","        [0.0333, 0.0333, 0.9333],\n","        [0.9333, 0.0333, 0.0333],\n","        [0.0333, 0.0333, 0.9333]])\n"]}]},{"cell_type":"code","source":["epoch_num=100\n","num_frame=NUM\n","loss_func=nn.CrossEntropyLoss()\n","f=DIM+2\n","label_smoothening_eps=0.1"],"metadata":{"id":"No8qVnd7xwSM","executionInfo":{"status":"ok","timestamp":1700589442605,"user_tz":-330,"elapsed":3,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["feature_model=contrastive_resnet_model\n","# model=CombinedLayers(gso=torch.zeros((num_frame,num_frame)),k=5,l=8,sigma=nn.Tanh(),f=f,in_size=num_frame,out_size=3) # contr.resnet50 best(frame=10,k=5,l=8,f=dim+2,hid_size=128,f_=1)\n","#some changes to f_1 combiner since last time\n","\n","# model=CombinedLayers(gso=torch.zeros((num_frame,num_frame)),k=5,l=8,sigma=nn.Tanh(),f=f,f_=32,in_size=num_frame,hid_size=128,out_size=3) # contr.resnet50 new best(frame=10,k=5,l=8,f=dim+2)\n","\n","model=CombinedLayers(gso=torch.zeros((num_frame,num_frame)),k=6,l=8,sigma=nn.Tanh(),f=f,f_=64,in_size=num_frame,hid_size=128,out_size=3)\n","model.to(device)"],"metadata":{"id":"LrVfUelRxtX9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700589443118,"user_tz":-330,"elapsed":3,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}},"outputId":"f968560b-8ade-444b-c2c9-61b2dbbdd518"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-9-89c4fbda0f52>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.gso = torch.tensor(gso)\n"]},{"output_type":"execute_result","data":{"text/plain":["CombinedLayers(\n","  (graph_layer): MLGNN(\n","    (layers): Sequential(\n","      (0): GraphPerceptron(\n","        (sigma): Tanh()\n","      )\n","      (1): GraphPerceptron(\n","        (sigma): Tanh()\n","      )\n","      (2): GraphPerceptron(\n","        (sigma): Tanh()\n","      )\n","      (3): GraphPerceptron(\n","        (sigma): Tanh()\n","      )\n","      (4): GraphPerceptron(\n","        (sigma): Tanh()\n","      )\n","      (5): GraphPerceptron(\n","        (sigma): Tanh()\n","      )\n","      (6): GraphPerceptron(\n","        (sigma): Tanh()\n","      )\n","      (7): GraphPerceptron(\n","        (sigma): Tanh()\n","      )\n","    )\n","  )\n","  (combiner_layer): f_to_1_combiner(\n","    (sigma): Tanh()\n","  )\n","  (fc): simple_nn(\n","    (layers): Sequential(\n","      (0): Linear(in_features=640, out_features=128, bias=True)\n","      (1): Tanh()\n","      (2): Linear(in_features=128, out_features=128, bias=True)\n","      (3): Tanh()\n","      (4): Linear(in_features=128, out_features=128, bias=True)\n","      (5): Tanh()\n","      (6): Linear(in_features=128, out_features=3, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["model((torch.randn(2,num_frame,f).to(device),torch.randn(2,num_frame,num_frame).to(device)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOAmxoWRfULx","executionInfo":{"status":"ok","timestamp":1700589447820,"user_tz":-330,"elapsed":3077,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}},"outputId":"0467330b-33ce-4bd7-8792-60bd0a67027a"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.0742, -0.0136, -0.0341],\n","        [-0.0774, -0.0193, -0.0456]], device='cuda:0',\n","       grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","execution_count":15,"metadata":{"id":"tdS41w_BXNVP","executionInfo":{"status":"ok","timestamp":1700589447820,"user_tz":-330,"elapsed":2,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}}},"outputs":[],"source":["def validate_model(model,feature_model,val_data_loader):\n","  model.eval()\n","  actual_y=[]\n","  predicted_y=[]\n","  with torch.no_grad():\n","    cnt=0\n","    tot=0\n","    tot_loss=0\n","    loss_func=nn.CrossEntropyLoss()\n","    for imageArrarr,timeStampArrarr,cellStateArrarr,predNextarr in val_data_loader:\n","      batch_size=imageArrarr.shape[0]\n","      aug_data=[get_augmented_data(feature_model,imageArrarr[i],timeStampArrarr[i],cellStateArrarr[i],predNextarr[i]) for i in range(batch_size)]\n","      batch_x=torch.cat([aug_data[i][0].reshape([1,num_frame,-1]) for i in range(batch_size)],dim=0)\n","      batch_y=torch.zeros((batch_size,3)).to(device)\n","      for i in range(batch_size):\n","        batch_y[i][int(aug_data[i][1])]=1\n","      gso=torch.cat([get_gso(aug_data[i][0]).reshape([1,num_frame,num_frame]) for i in range(batch_size)],dim=0) #### change since resnet\n","\n","      batch_y = torch.argmax(batch_y,dim=1)\n","\n","      output_y=model((batch_x,gso))\n","      loss_now=loss_func(output_y,batch_y)\n","      tot_loss+=loss_now.item()\n","      print(f\"loss_now: {loss_now.item()}\")\n","      cnt_c=0\n","      for i in range(batch_size):\n","        tot+=1\n","        if batch_y[i]==torch.argmax(smax(output_y[i])).item():\n","          cnt_c+=1\n","        actual_y.append(batch_y[i].item())\n","        predicted_y.append(torch.argmax(smax(output_y[i])).item())\n","      cnt+=cnt_c\n","      print(f\"batch_acc: {cnt_c/batch_size}\")\n","    print(f\"tot_loss: {tot_loss/len(val_data_loader)}, accuracy: {cnt/tot}\")\n","\n","    return actual_y,predicted_y"]},{"cell_type":"code","source":["# optimizer=torch.optim.Adam(model.parameters(),lr=1e-3)\n","optimizer=torch.optim.Adam(model.parameters(),lr=1e-3)# changed to 1e-3 from 1e-4\n","# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[25,50,75,100],gamma=0.5)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=5,gamma=0.75)\n","batch_size=16\n","smax=nn.Softmax(dim=0)\n","loss_now=torch.inf\n","best_model=None\n","\n","\n","gnn_data=getGNNDataset(index_list=train_files,model=None)\n","gnn_data.set_len(400)\n","gnn_data_loader=DataLoader(gnn_data,batch_size=batch_size,shuffle=True)\n","val_gnn_dataset=getGNNDataset(index_list=val_files,model=None)\n","# val_gnn_dataset.set_len(400)\n","val_gnn_data_loader=DataLoader(val_gnn_dataset,batch_size=10,shuffle=True)"],"metadata":{"id":"knoOMYD0ZKf6","executionInfo":{"status":"ok","timestamp":1700589448602,"user_tz":-330,"elapsed":3,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3RDSRHiWE_OR","outputId":"eee6637d-948b-49ea-c9cd-e68a9859546b","executionInfo":{"status":"error","timestamp":1700598859685,"user_tz":-330,"elapsed":897883,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 0:  tensor([[ 3.2179, -0.0297, -3.7561],\n","        [ 2.3137,  0.1253, -2.8892],\n","        [-2.2644, -1.3256,  4.0473],\n","        [-4.0912, -0.4832,  5.1527],\n","        [ 3.4067, -0.8492, -2.9962],\n","        [ 1.9022,  0.7616, -3.1764],\n","        [-3.9760,  2.4396,  1.5168],\n","        [ 1.9962,  0.0389, -2.4255],\n","        [-2.6887,  4.6250, -2.0922],\n","        [-4.0763, -1.0010,  5.8666],\n","        [-3.5301,  2.0573,  1.4671],\n","        [ 2.4223,  0.4891, -3.4429],\n","        [-2.1466,  4.3917, -2.4655],\n","        [-3.7515, -1.7324,  6.5881],\n","        [-1.3592, -1.6517,  3.3509],\n","        [-3.0093, -1.9881,  5.8180]]) tensor([0, 0, 2, 2, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 2]) 0.20438411831855774\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 1:  tensor([[ 3.4052, -0.6187, -3.2588],\n","        [ 2.8732, -0.2726, -3.0490],\n","        [-2.4303,  4.4685, -2.2275],\n","        [ 2.4592, -0.2397, -2.6375],\n","        [ 3.4465, -0.6467, -3.2729],\n","        [ 2.6828,  0.1599, -3.3535],\n","        [-3.1375, -2.4675,  6.7549],\n","        [-3.3845,  4.1045, -0.8532],\n","        [-1.9544,  4.7551, -3.0047],\n","        [-1.7757, -3.0552,  5.4970],\n","        [-2.5943, -2.8337,  6.3767],\n","        [-3.1983, -2.4422,  6.8287],\n","        [ 2.0463,  0.4825, -3.0215],\n","        [-1.1598, -4.1324,  5.8354],\n","        [-3.9828, -0.9521,  5.6737],\n","        [-2.6086,  4.5355, -2.0954]]) tensor([0, 0, 1, 0, 0, 0, 2, 1, 1, 2, 2, 2, 0, 2, 2, 1]) 0.02776196040213108\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 2:  tensor([[-3.9124, -1.4545,  6.3620],\n","        [-3.4760, -2.1205,  6.7926],\n","        [-4.0490, -0.9709,  5.7893],\n","        [-3.9514, -1.2113,  6.0291],\n","        [ 3.0998, -0.7505, -2.7489],\n","        [-3.1050, -2.4852,  6.7194],\n","        [ 2.7370, -0.2633, -2.9192],\n","        [-3.5327, -1.7150,  6.1879],\n","        [-2.2577,  4.7262, -2.6483],\n","        [-2.9986,  4.4825, -1.6291],\n","        [ 0.6513,  2.1791, -3.3770],\n","        [-3.4174,  4.1351, -0.8484],\n","        [ 2.3707,  0.7739, -3.7311],\n","        [-3.6585,  3.8777, -0.3332],\n","        [-2.9064, -1.1994,  4.6694],\n","        [-1.0680, -1.9588,  3.3409]]) tensor([2, 2, 2, 2, 0, 2, 0, 2, 1, 1, 0, 1, 1, 1, 2, 2]) 0.22728873789310455\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 3:  tensor([[-3.3617, -1.5736,  5.7283],\n","        [-1.6230,  4.5250, -3.1735],\n","        [ 2.4822, -0.4488, -2.4187],\n","        [ 2.1604, -0.0330, -2.5381],\n","        [-3.2511,  1.7393,  1.5220],\n","        [ 2.3543, -0.7777, -1.8813],\n","        [-4.4865, -0.2965,  5.3532],\n","        [-3.3700,  2.7851,  0.4954],\n","        [-2.8730, -2.7370,  6.6977],\n","        [-2.4900,  4.6878, -2.3594],\n","        [ 2.4289,  0.1765, -3.0862],\n","        [-4.0725,  2.3613,  1.7017],\n","        [-2.7535,  4.3338, -1.7521],\n","        [ 1.6242,  0.8544, -2.9540],\n","        [ 2.3736, -0.1996, -2.5806],\n","        [-2.5830, -3.0700,  6.6936]]) tensor([2, 1, 0, 0, 2, 0, 2, 1, 2, 1, 0, 1, 1, 0, 0, 2]) 0.13376525044441223\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 4:  tensor([[-3.2669, -2.3675,  6.8250],\n","        [-3.2230, -2.4252,  6.8423],\n","        [-3.7091,  3.9674, -0.3715],\n","        [-2.7674,  4.6186, -2.0012],\n","        [-2.6010,  4.6576, -2.2165],\n","        [-2.6013,  4.6445, -2.2068],\n","        [-3.8770,  2.2488,  1.6194],\n","        [-3.4470,  3.9698, -0.6540],\n","        [-3.9824, -1.0422,  5.8042],\n","        [-2.3418,  4.5332, -2.3830],\n","        [ 2.8882, -1.0078, -2.2330],\n","        [-3.1125, -2.3868,  6.5608],\n","        [-3.9882, -1.3872,  6.3687],\n","        [-3.4073, -2.1069,  6.6248],\n","        [-3.4315, -2.1469,  6.7490],\n","        [ 2.7089, -0.6169, -2.4698]]) tensor([2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 0, 2, 2, 2, 2, 0]) 0.03306027129292488\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 5:  tensor([[-3.5207, -1.4744,  5.8080],\n","        [ 2.2875, -0.4017, -2.2559],\n","        [ 2.2484, -0.3570, -2.2596],\n","        [-1.8713,  4.7225, -3.0717],\n","        [-3.7118, -1.5702,  6.2321],\n","        [-1.1867, -3.6930,  5.4334],\n","        [ 2.4326, -0.7538, -2.0206],\n","        [ 2.5185, -0.1548, -2.7975],\n","        [ 2.5550, -0.7228, -2.1910],\n","        [-2.1355,  4.7581, -2.8114],\n","        [-3.6795,  3.8304, -0.2665],\n","        [ 2.3001, -0.3449, -2.3204],\n","        [-3.9838, -1.4161,  6.4212],\n","        [-3.2137, -2.4289,  6.8256],\n","        [ 2.9497, -0.5268, -2.8532],\n","        [-4.2767,  2.3049,  1.9721]]) tensor([2, 0, 0, 1, 2, 2, 0, 0, 0, 1, 1, 0, 2, 2, 0, 2]) 0.08338992297649384\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 6:  tensor([[-2.8005,  4.6269, -1.9754],\n","        [-2.6779, -2.9124,  6.6209],\n","        [-3.4190,  1.0090,  2.5295],\n","        [ 2.3728, -0.6088, -2.1088],\n","        [-1.8494,  4.5911, -2.9808],\n","        [ 2.2579, -0.2891, -2.3585],\n","        [-3.1017, -2.4563,  6.6567],\n","        [-3.4282,  4.1179, -0.8219],\n","        [-2.5237, -2.4684,  5.7837],\n","        [ 2.0549,  0.0808, -2.5533],\n","        [-1.9018,  4.6883, -3.0108],\n","        [-2.4720,  4.6482, -2.3481],\n","        [-3.1256, -2.5472,  6.8530],\n","        [ 2.4323, -0.5104, -2.2848],\n","        [-2.1715,  4.3194, -2.3821],\n","        [ 0.3518,  0.9178, -1.5986]]) tensor([1, 2, 1, 0, 1, 0, 2, 1, 2, 0, 1, 1, 2, 0, 1, 1]) 0.1614033579826355\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 7:  tensor([[ 1.7981,  0.3363, -2.5562],\n","        [-1.9729, -3.2807,  6.0255],\n","        [ 2.6849, -0.2494, -2.8762],\n","        [ 2.1946,  0.0179, -2.6306],\n","        [-2.0780, -3.5425,  6.4955],\n","        [ 2.4228, -0.4052, -2.3984],\n","        [-3.1193, -2.5260,  6.8055],\n","        [-2.4091,  4.7226, -2.4833],\n","        [ 2.4983, -0.4396, -2.4359],\n","        [-3.6973,  3.1076,  0.4972],\n","        [ 2.2667,  0.0074, -2.7144],\n","        [-2.3191,  4.6534, -2.5187],\n","        [-3.2574, -2.3664,  6.7937],\n","        [ 3.3962, -0.5836, -3.2883],\n","        [ 1.5966,  0.5619, -2.5784],\n","        [-1.7819, -2.9904,  5.4257]]) tensor([0, 2, 0, 0, 2, 0, 2, 1, 0, 1, 0, 1, 2, 0, 1, 2]) 0.12905026972293854\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 8:  tensor([[-2.6945,  4.6464, -2.1103],\n","        [-1.9248, -3.5640,  6.2932],\n","        [-0.9560,  2.0084, -1.3376],\n","        [ 2.5177, -1.3248, -1.4550],\n","        [ 3.5802, -1.2681, -2.7076],\n","        [-2.4657, -3.1457,  6.5907],\n","        [ 1.9155,  0.0736, -2.3903],\n","        [-2.0914,  4.4829, -2.6225],\n","        [ 2.2832, -0.7295, -1.8675],\n","        [-4.0501, -1.1808,  6.1059],\n","        [-3.2229, -2.0761,  6.2566],\n","        [ 2.1737, -0.5283, -1.9830],\n","        [-1.7780,  4.6148, -3.0838],\n","        [-3.2006, -2.0793,  6.2198],\n","        [-2.6086, -2.8323,  6.3988],\n","        [-2.5700, -2.7599,  6.2310]]) tensor([1, 2, 1, 0, 0, 2, 0, 1, 0, 2, 2, 0, 1, 2, 2, 2]) 0.0276237353682518\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 9:  tensor([[-2.7860, -2.3631,  6.0121],\n","        [ 3.3162, -0.9554, -2.7646],\n","        [ 2.5458, -0.7535, -2.1335],\n","        [-3.6451, -1.7123,  6.3527],\n","        [-3.4627,  2.1284,  1.3033],\n","        [ 2.9015, -1.0686, -2.1768],\n","        [-2.0047,  4.6801, -2.8920],\n","        [-0.7387, -1.5811,  2.5339],\n","        [ 2.4837, -0.2669, -2.6219],\n","        [-2.9409,  4.2301, -1.4583],\n","        [-2.1916,  4.7942, -2.7867],\n","        [-2.0759,  4.6393, -2.7747],\n","        [-1.9766,  4.5407, -2.8008],\n","        [-3.1183,  4.4547, -1.4830],\n","        [-2.5142,  4.6769, -2.3311],\n","        [ 2.9350, -0.6453, -2.6960]]) tensor([2, 0, 0, 2, 1, 0, 1, 2, 0, 2, 1, 1, 1, 1, 1, 0]) 0.39428946375846863\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 10:  tensor([[ 3.7511e+00, -1.2866e+00, -2.8641e+00],\n","        [-2.3496e+00,  4.7517e+00, -2.5797e+00],\n","        [-3.5852e+00, -1.9861e+00,  6.7365e+00],\n","        [ 3.7511e+00, -1.2866e+00, -2.8641e+00],\n","        [-2.6260e+00,  4.6966e+00, -2.2324e+00],\n","        [-1.7381e+00,  4.6402e+00, -3.1541e+00],\n","        [ 1.9112e+00,  1.7574e-03, -2.2881e+00],\n","        [-3.4877e+00,  3.9561e+00, -6.0065e-01],\n","        [ 2.3816e+00, -3.3052e-01, -2.4412e+00],\n","        [-2.9987e+00,  4.5154e+00, -1.6687e+00],\n","        [-3.3396e+00,  4.3028e+00, -1.1024e+00],\n","        [-1.0716e+00, -4.1004e+00,  5.6838e+00],\n","        [-2.3674e+00,  4.7416e+00, -2.5522e+00],\n","        [-2.4685e+00, -3.0606e+00,  6.4796e+00],\n","        [-4.1229e+00,  3.2895e+00,  7.3746e-01],\n","        [ 2.6084e+00,  6.0554e-02, -3.1599e+00]]) tensor([0, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 2, 1, 2, 1, 1]) 0.3047855496406555\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 11:  tensor([[ 1.0522,  1.8905, -3.5243],\n","        [-2.5807, -2.4793,  5.8728],\n","        [-4.3394,  2.2302,  2.0963],\n","        [ 2.9099, -0.0914, -3.3167],\n","        [-2.3878, -3.1496,  6.4703],\n","        [ 3.7733, -1.2225, -2.9562],\n","        [-3.0942,  4.1870, -1.2584],\n","        [-3.6304,  3.9057, -0.4081],\n","        [ 2.6939, -0.3539, -2.7701],\n","        [-2.8276,  4.5902, -1.9226],\n","        [-3.5631, -0.3538,  4.3519],\n","        [ 3.0210, -1.0549, -2.3288],\n","        [-1.9241,  4.4103, -2.7457],\n","        [-2.6633, -2.6017,  6.1569],\n","        [-0.7499,  3.6326, -3.3294],\n","        [-4.4050, -0.0118,  4.8659]]) tensor([1, 2, 1, 0, 2, 0, 1, 1, 0, 1, 2, 0, 1, 2, 1, 2]) 0.07354456186294556\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 12:  tensor([[-3.4261,  4.1466, -0.8638],\n","        [-2.8906,  4.5997, -1.8663],\n","        [-3.2662, -2.3666,  6.8107],\n","        [-2.1989,  4.7466, -2.7388],\n","        [-1.5614, -3.7569,  5.9973],\n","        [ 2.1974, -0.2942, -2.2685],\n","        [-1.5225, -1.3864,  3.2036],\n","        [-2.7519,  4.6818, -2.0884],\n","        [-2.4277,  4.5510, -2.3162],\n","        [-2.9249, -2.7313,  6.7792],\n","        [ 2.3577, -0.3109, -2.4202],\n","        [ 2.0638,  0.1187, -2.5968],\n","        [ 3.7758, -1.1608, -3.0288],\n","        [ 2.3042, -0.4580, -2.2022],\n","        [ 2.5003, -0.3450, -2.5378],\n","        [ 3.2445, -0.8260, -2.8258]]) tensor([1, 1, 2, 1, 2, 0, 2, 1, 1, 2, 0, 0, 0, 0, 0, 0]) 0.0314163975417614\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 13:  tensor([[ 2.0894, -0.0156, -2.4873],\n","        [ 2.1740, -0.3133, -2.2256],\n","        [ 2.5457, -0.1254, -2.8553],\n","        [ 2.6201, -1.1443, -1.7815],\n","        [-2.5321,  4.6969, -2.3376],\n","        [-1.4657, -3.7873,  5.9008],\n","        [ 2.3263, -0.0422, -2.7134],\n","        [-1.2318, -3.8682,  5.6725],\n","        [-2.8792, -2.5548,  6.4315],\n","        [-4.2463, -0.4952,  5.3357],\n","        [-2.3417,  4.7764, -2.6139],\n","        [-2.9487,  4.1921, -1.4152],\n","        [ 2.3795, -0.4054, -2.3468],\n","        [-4.1326, -1.2160,  6.3034],\n","        [-2.5798,  4.7402, -2.3269],\n","        [-2.0895,  4.0677, -2.2490]]) tensor([1, 0, 0, 0, 1, 2, 0, 2, 2, 2, 1, 1, 0, 2, 1, 1]) 0.1630128175020218\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 14:  tensor([[ 2.2181, -0.2530, -2.3409],\n","        [ 2.7596, -0.3040, -2.9048],\n","        [-0.5762,  3.4808, -3.3886],\n","        [-2.5174,  4.7608, -2.4107],\n","        [ 2.1476,  0.2503, -2.8430],\n","        [ 2.2825,  0.3974, -3.1630],\n","        [-3.7651, -1.6865,  6.5161],\n","        [-1.3944, -3.2813,  5.2558],\n","        [-2.3243, -2.2241,  5.2070],\n","        [ 2.4839,  0.3047, -3.3050],\n","        [-2.7838,  4.6911, -2.0668],\n","        [-3.2923, -2.3414,  6.8272],\n","        [-2.3243,  4.4255, -2.3195],\n","        [-3.5991, -1.9831,  6.7714],\n","        [-3.0368, -2.5668,  6.7242],\n","        [-1.7867,  0.3178,  1.5262]]) tensor([0, 0, 1, 1, 0, 0, 2, 2, 2, 0, 1, 2, 1, 2, 2, 2]) 0.05352696031332016\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 15:  tensor([[ 2.3954, -0.1265, -2.6853],\n","        [-2.7717, -2.8644,  6.7156],\n","        [ 0.3264,  1.6190, -2.3790],\n","        [-2.7342,  4.7063, -2.1329],\n","        [-3.6368, -1.7205,  6.3621],\n","        [-4.3713, -0.6902,  5.7771],\n","        [-3.3638, -1.3668,  5.4410],\n","        [-4.8510,  0.0933,  5.1854],\n","        [ 3.1641, -0.6970, -2.8823],\n","        [-4.0540,  2.9644,  1.0146],\n","        [ 3.5467, -0.5643, -3.4670],\n","        [-3.4753, -2.0463,  6.6401],\n","        [-3.3027, -2.3308,  6.8325],\n","        [-2.6453, -2.4410,  5.9311],\n","        [-3.2875,  4.3771, -1.2394],\n","        [-3.9388, -1.4697,  6.4293]]) tensor([0, 2, 1, 1, 2, 2, 2, 2, 0, 1, 0, 2, 2, 2, 1, 2]) 0.0331522636115551\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 16:  tensor([[ 1.2021,  0.7980, -2.4110],\n","        [-3.4031, -1.9949,  6.4241],\n","        [-2.6929, -2.9122,  6.6434],\n","        [-3.0118,  4.2623, -1.4199],\n","        [-3.0026, -2.6008,  6.7176],\n","        [-2.9554, -2.2347,  6.0795],\n","        [-1.8124, -2.1217,  4.4365],\n","        [ 2.5504, -0.3824, -2.5642],\n","        [ 3.5898, -0.4486, -3.6473],\n","        [-2.8172, -0.9284,  4.1834],\n","        [-2.4472,  4.7360, -2.4668],\n","        [-2.8969, -2.7730,  6.8010],\n","        [-3.3193, -2.0860,  6.4213],\n","        [-3.0150, -1.9681,  5.8053],\n","        [-3.6480, -1.8910,  6.6941],\n","        [-3.3150,  4.5140, -1.3428]]) tensor([1, 2, 2, 1, 2, 2, 2, 0, 0, 2, 1, 2, 2, 2, 2, 1]) 0.06428088992834091\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 17:  tensor([[-3.3943, -2.1971,  6.7636],\n","        [-3.5194, -2.0698,  6.7837],\n","        [-3.4786, -2.1209,  6.7975],\n","        [-2.6083, -2.7258,  6.2420],\n","        [ 3.7926, -0.7353, -3.5458],\n","        [-3.3209, -2.2172,  6.6587],\n","        [-3.9911,  3.0962,  0.7978],\n","        [-2.8227,  4.7238, -2.0602],\n","        [ 2.1513, -0.0954, -2.4486],\n","        [-2.9702, -2.0091,  5.7860],\n","        [ 3.6042, -0.6121, -3.4760],\n","        [-2.9686, -2.6955,  6.8115],\n","        [-2.0995,  4.7889, -2.8935],\n","        [-3.4751,  4.3998, -1.0702],\n","        [-3.1973, -2.2352,  6.4659],\n","        [-3.6566,  1.3536,  2.3789]]) tensor([2, 2, 2, 2, 0, 2, 2, 1, 0, 2, 0, 2, 1, 1, 2, 2]) 0.17807228863239288\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 18:  tensor([[-2.2553,  4.6869, -2.6371],\n","        [-2.3532,  4.6601, -2.5034],\n","        [-2.7643,  4.5704, -1.9749],\n","        [-3.7875, -1.6210,  6.4333],\n","        [ 2.5476, -0.0120, -2.9911],\n","        [ 2.9987, -0.3020, -3.1537],\n","        [ 2.2196,  0.5250, -3.2606],\n","        [-2.5940,  4.6465, -2.2289],\n","        [-2.0480, -3.2433,  6.1056],\n","        [-2.6908, -2.9411,  6.6925],\n","        [ 0.9545,  0.5594, -1.8510],\n","        [ 1.9139,  1.0976, -3.5723],\n","        [ 2.0082, -0.3554, -1.9693],\n","        [-3.0849,  4.6301, -1.6973],\n","        [ 1.8330,  0.5084, -2.7917],\n","        [ 1.8737,  0.1595, -2.4317]]) tensor([1, 1, 1, 2, 0, 0, 0, 1, 2, 2, 1, 1, 0, 1, 0, 0]) 0.18481294810771942\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 19:  tensor([[-3.1236,  4.5517, -1.5873],\n","        [-3.0128, -2.4169,  6.4443],\n","        [-2.9313,  4.6728, -1.8989],\n","        [-3.2390,  4.5777, -1.4908],\n","        [-3.5514,  4.3933, -0.9874],\n","        [-2.8796,  4.6967, -1.9761],\n","        [ 2.0588, -0.1594, -2.2641],\n","        [-3.3424,  4.5215, -1.3269],\n","        [-3.8685,  2.7461,  1.0464],\n","        [-3.4722, -2.0272,  6.6116],\n","        [ 3.7091, -0.6138, -3.5778],\n","        [ 3.1829, -0.7671, -2.8066],\n","        [-3.7648, -1.3394,  5.9393],\n","        [-3.9535, -1.4486,  6.4200],\n","        [-4.6059, -0.4172,  5.6477],\n","        [-2.6514,  4.6727, -2.1921]]) tensor([1, 2, 1, 1, 1, 1, 0, 1, 1, 2, 0, 0, 2, 2, 2, 1]) 0.02139953337609768\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 20:  tensor([[ 2.4872,  0.1334, -3.0908],\n","        [-4.0224, -0.2428,  4.7394],\n","        [ 1.8577,  0.4899, -2.8107],\n","        [-2.3911,  4.5141, -2.3353],\n","        [ 2.3339,  0.5484, -3.4276],\n","        [-2.9882, -2.5655,  6.6451],\n","        [ 2.7056, -0.6412, -2.4401],\n","        [-4.0661,  3.7450,  0.2025],\n","        [-2.6800,  4.6731, -2.1655],\n","        [-2.3080,  4.2846, -2.2168],\n","        [-3.6574,  4.3363, -0.8238],\n","        [-2.6238,  4.6665, -2.2194],\n","        [-3.3061,  4.5342, -1.3812],\n","        [ 2.4131,  0.0268, -2.8897],\n","        [-4.0880, -0.6769,  5.4060],\n","        [-2.5587,  4.7082, -2.3266]]) tensor([0, 2, 0, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 2, 1]) 0.15387754142284393\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 21:  tensor([[-2.8047e+00, -2.7568e+00,  6.6284e+00],\n","        [ 1.9983e+00, -1.7115e-01, -2.1824e+00],\n","        [ 2.2175e+00, -5.4712e-03, -2.6261e+00],\n","        [-4.1738e+00,  3.8344e+00,  2.1747e-01],\n","        [-3.7003e+00, -1.8369e+00,  6.6971e+00],\n","        [-3.5253e+00, -2.0126e+00,  6.6805e+00],\n","        [-3.5827e+00,  4.4053e+00, -9.7016e-01],\n","        [-3.0633e+00,  4.6237e+00, -1.7150e+00],\n","        [-3.2150e+00,  4.4171e+00, -1.3586e+00],\n","        [-3.2534e+00, -2.3856e+00,  6.8517e+00],\n","        [-2.9548e+00,  4.7087e+00, -1.9123e+00],\n","        [-2.5225e+00,  4.6737e+00, -2.3400e+00],\n","        [-3.7407e+00,  4.0356e+00, -4.4104e-01],\n","        [-3.8005e+00, -1.2736e+00,  5.9040e+00],\n","        [-4.0837e+00,  4.0234e+00, -7.2297e-02],\n","        [-3.4631e+00,  4.5084e+00, -1.1973e+00]]) tensor([2, 0, 0, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1]) 0.01915525272488594\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 22:  tensor([[-0.6726,  2.1516, -1.8341],\n","        [-0.6822, -0.7400,  1.4898],\n","        [-3.3653,  4.5805, -1.3675],\n","        [-1.4760, -3.9284,  6.0876],\n","        [-4.2495, -0.1513,  4.8723],\n","        [-3.2665,  4.6028, -1.4921],\n","        [ 2.1170,  0.1903, -2.7403],\n","        [ 1.1422,  0.7739, -2.3166],\n","        [-4.3712,  2.8360,  1.4627],\n","        [-3.8505, -1.6446,  6.6030],\n","        [-2.0935, -3.4596,  6.4459],\n","        [ 2.1468,  0.3402, -2.9512],\n","        [-4.7533,  0.1549,  5.0043],\n","        [-3.4894, -2.1303,  6.8583],\n","        [ 1.2278,  1.5851, -3.3664],\n","        [ 2.0163,  0.0683, -2.4726]]) tensor([1, 0, 1, 2, 2, 1, 0, 0, 1, 2, 2, 0, 2, 2, 0, 1]) 0.40762650966644287\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 23:  tensor([[ 1.9255,  0.0316, -2.3367],\n","        [-2.7624,  4.6773, -2.0872],\n","        [ 2.3133,  0.9650, -3.8841],\n","        [-4.2284,  3.7907,  0.3172],\n","        [ 2.1755,  0.4225, -3.0821],\n","        [-2.8152,  4.7486, -2.0970],\n","        [-3.8544, -1.5926,  6.5126],\n","        [-4.4202,  3.0558,  1.2781],\n","        [ 3.6310, -0.8229, -3.2625],\n","        [-3.7291, -1.8310,  6.7531],\n","        [-4.1795,  3.2238,  0.8652],\n","        [-3.3908,  4.4676, -1.2317],\n","        [-4.3220, -0.7203,  5.7631],\n","        [ 1.9331, -0.1350, -2.1557],\n","        [-4.1052,  3.9029,  0.0752],\n","        [ 2.1456,  0.3227, -2.9328]]) tensor([0, 1, 0, 1, 0, 1, 2, 1, 0, 2, 1, 1, 2, 0, 1, 0]) 0.07249779999256134\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 24:  tensor([[ 2.6213,  0.0297, -3.1368],\n","        [-3.0239,  4.7076, -1.8433],\n","        [ 2.4844,  0.3038, -3.2954],\n","        [-3.8931, -1.3180,  6.0989],\n","        [-2.6486,  4.7038, -2.2308],\n","        [ 2.1951,  0.2984, -2.9571],\n","        [ 2.0753,  1.0913, -3.7730],\n","        [ 2.6338,  0.1453, -3.2893],\n","        [ 3.5649, -0.4245, -3.6489],\n","        [-3.4513,  4.4661, -1.1697],\n","        [-3.2683, -2.3699,  6.8610],\n","        [-4.2986, -0.9102,  6.0200],\n","        [ 2.7188, -0.1062, -3.1089],\n","        [-2.8554,  4.7333, -2.0410],\n","        [ 2.8794,  0.3992, -3.8551],\n","        [-3.1864, -0.3695,  3.9303]]) tensor([0, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 2, 0, 1, 0, 2]) 0.05736160650849342\n","epoch: 0, loss: 0.12962160035967826, acc: 0.95\n","nan: False same_parameter: False\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 0:  tensor([[ 2.3504, -0.2367, -2.5113],\n","        [-3.3499, -2.0977,  6.5196],\n","        [ 3.4272, -1.0105, -2.7954],\n","        [ 2.6137,  0.8787, -4.1598],\n","        [ 3.6456, -0.4852, -3.6781],\n","        [-3.8405,  4.1589, -0.4604],\n","        [-2.3527,  4.6307, -2.4874],\n","        [-3.7024, -1.7676,  6.5622],\n","        [ 2.1703,  0.0903, -2.6778],\n","        [ 3.7117, -0.2040, -4.0756],\n","        [-0.5928, -3.8176,  4.8343],\n","        [-3.0248,  4.7156, -1.8506],\n","        [ 2.7876,  0.1269, -3.4262],\n","        [-3.1454,  4.6483, -1.6641],\n","        [ 2.3299,  0.7206, -3.6077],\n","        [-3.1915,  4.6557, -1.6215]]) tensor([0, 2, 0, 0, 0, 1, 1, 2, 1, 0, 2, 1, 0, 1, 0, 1]) 0.17346839606761932\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 1:  tensor([[ 0.4748,  2.1886, -3.1922],\n","        [ 2.1371,  0.7632, -3.4568],\n","        [ 3.2887, -0.7231, -2.9799],\n","        [-3.3299, -2.2648,  6.7806],\n","        [-3.3560, -2.1115,  6.5528],\n","        [-4.3678, -0.6515,  5.7177],\n","        [ 2.4959,  0.5432, -3.5975],\n","        [ 3.7405, -0.1887, -4.1375],\n","        [-3.1388,  4.6631, -1.6851],\n","        [-2.2302, -3.3448,  6.5075],\n","        [-3.4444, -2.1176,  6.7325],\n","        [-2.5242,  4.6962, -2.3583],\n","        [-1.1795, -4.0891,  5.8459],\n","        [ 3.5219, -0.5456, -3.4460],\n","        [-2.1914,  4.6781, -2.7075],\n","        [ 2.3043,  0.5178, -3.3451]]) tensor([1, 0, 0, 2, 2, 2, 0, 0, 1, 2, 2, 1, 2, 0, 1, 0]) 0.04732244089245796\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 2:  tensor([[-3.7781, -1.3180,  5.9295],\n","        [ 2.3907,  0.7757, -3.7653],\n","        [ 2.5693, -0.0119, -3.0080],\n","        [-2.7350,  4.7660, -2.2004],\n","        [ 2.6602,  0.6689, -3.9293],\n","        [-3.6635,  2.8359,  0.7256],\n","        [-4.6425, -0.3977,  5.6524],\n","        [-4.3145, -0.8455,  5.9418],\n","        [ 2.4613,  0.4932, -3.4968],\n","        [-2.5525, -3.0302,  6.6040],\n","        [-3.6698,  4.3824, -0.8632],\n","        [ 1.9389,  0.6450, -3.0805],\n","        [-2.7619,  4.7702, -2.1749],\n","        [-3.7392,  4.2814, -0.6954],\n","        [-2.9674,  4.6945, -1.8923],\n","        [ 1.0824,  1.1509, -2.6993]]) tensor([2, 0, 0, 1, 1, 2, 2, 2, 0, 2, 1, 0, 1, 1, 1, 0]) 0.3592335283756256\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 3:  tensor([[-1.9504, -2.4823,  5.0479],\n","        [-4.0496,  3.3875,  0.5465],\n","        [ 2.3167,  0.9680, -3.9082],\n","        [-0.3403, -4.3114,  4.9874],\n","        [ 3.1053,  0.4377, -4.1908],\n","        [-3.1226,  4.6800, -1.7167],\n","        [ 1.8478,  0.4115, -2.7060],\n","        [ 2.4494,  0.5098, -3.5002],\n","        [-3.8682, -1.3853,  6.1812],\n","        [-3.2669,  4.5731, -1.4650],\n","        [-3.2918, -2.0843,  6.3922],\n","        [-2.8562, -1.0447,  4.3775],\n","        [-4.1388,  3.8348,  0.1739],\n","        [-3.9080,  3.4688,  0.3122],\n","        [-2.7087, -2.8106,  6.5470],\n","        [-2.5783, -3.0735,  6.7097]]) tensor([2, 1, 0, 2, 0, 1, 0, 0, 2, 1, 2, 2, 1, 1, 2, 2]) 0.050081346184015274\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 4:  tensor([[-3.5366e+00, -1.7920e+00,  6.3131e+00],\n","        [-2.1074e+00, -3.3462e+00,  6.3309e+00],\n","        [-2.7157e+00,  4.7597e+00, -2.2154e+00],\n","        [-2.7815e+00,  4.7432e+00, -2.1307e+00],\n","        [-2.3395e+00,  4.7363e+00, -2.5962e+00],\n","        [-3.7037e+00,  4.2733e+00, -7.1613e-01],\n","        [ 2.4101e+00,  3.7376e-01, -3.2845e+00],\n","        [ 2.7680e+00, -3.6095e-01, -2.8431e+00],\n","        [ 2.8378e+00, -1.0400e-01, -3.2133e+00],\n","        [-3.5027e+00, -1.6323e+00,  6.0105e+00],\n","        [-3.4892e+00,  4.4804e+00, -1.1443e+00],\n","        [-2.1152e+00, -3.4522e+00,  6.4670e+00],\n","        [ 4.0744e+00, -4.8544e-01, -4.1357e+00],\n","        [ 2.9971e+00,  2.4054e-03, -3.5196e+00],\n","        [-3.2643e+00, -2.2721e+00,  6.6555e+00],\n","        [ 3.6593e+00, -6.2363e-01, -3.5235e+00]]) tensor([2, 2, 1, 1, 1, 1, 0, 0, 0, 2, 1, 2, 0, 0, 2, 0]) 0.019891534000635147\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 5:  tensor([[ 2.9699, -0.1320, -3.3151],\n","        [ 2.5001,  1.1639, -4.3496],\n","        [-1.3979, -3.8314,  5.8784],\n","        [ 2.8726, -0.2111, -3.1155],\n","        [-4.3832, -0.5736,  5.6088],\n","        [ 3.1565,  0.1769, -3.9199],\n","        [-3.4389, -2.1305,  6.7348],\n","        [-2.0991,  4.6527, -2.7879],\n","        [-2.8459, -2.2413,  5.9403],\n","        [-3.6893, -1.7237,  6.4482],\n","        [-3.9439,  3.8465, -0.0378],\n","        [-4.3832, -0.5130,  5.5296],\n","        [-1.7692, -3.6850,  6.2324],\n","        [ 3.0676,  0.5382, -4.2624],\n","        [-2.0237, -0.0766,  2.2538],\n","        [-0.6382,  3.5411, -3.3827]]) tensor([0, 1, 2, 0, 2, 0, 2, 1, 2, 2, 1, 2, 2, 0, 2, 1]) 0.1213577538728714\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 6:  tensor([[-2.3324,  4.6580, -2.5354],\n","        [-2.8663,  4.7267, -2.0279],\n","        [ 4.1121, -0.8048, -3.8053],\n","        [ 4.1722, -0.5696, -4.1428],\n","        [-0.6442,  4.0239, -3.8695],\n","        [-2.7079,  4.7223, -2.1878],\n","        [-3.3232, -2.2796,  6.7790],\n","        [-1.9858, -3.4898,  6.3172],\n","        [ 0.0508,  3.4005, -4.0534],\n","        [-3.1473,  4.6530, -1.6670],\n","        [-3.3655,  3.4273, -0.2305],\n","        [-2.8473,  4.7244, -2.0438],\n","        [ 3.4649, -0.2059, -3.8050],\n","        [ 3.1507,  0.0259, -3.7292],\n","        [-3.2280,  4.6236, -1.5537],\n","        [-2.5151, -2.1592,  5.3777]]) tensor([1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 0, 0, 1, 2]) 0.010646519251167774\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 7:  tensor([[-3.0157,  4.6820, -1.8295],\n","        [-3.6457,  4.2268, -0.7377],\n","        [-2.7905,  4.6633, -2.0490],\n","        [-4.2525,  2.8059,  1.3683],\n","        [-3.9969,  3.3249,  0.5573],\n","        [-2.7778,  4.7416, -2.1337],\n","        [ 1.9938,  1.1589, -3.7312],\n","        [-3.8632,  3.0795,  0.6724],\n","        [ 3.2300,  0.0139, -3.8039],\n","        [ 3.5470, -0.4377, -3.6192],\n","        [-2.1725,  4.6609, -2.7155],\n","        [-3.1568,  4.6484, -1.6509],\n","        [-3.7754, -1.7615,  6.6805],\n","        [ 2.7994,  0.1523, -3.4706],\n","        [-3.6194, -1.7882,  6.4433],\n","        [-3.6061,  4.2170, -0.7669]]) tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 2, 0, 2, 1]) 0.10712448507547379\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 8:  tensor([[-3.5656, -1.8449,  6.4534],\n","        [-3.8717, -1.4417,  6.2685],\n","        [-3.0849,  4.6506, -1.7259],\n","        [ 0.6206, -0.8889,  0.1936],\n","        [-3.0557,  4.6708, -1.7812],\n","        [-3.0028,  4.6971, -1.8586],\n","        [ 4.1874, -0.8887, -3.7936],\n","        [ 3.6207, -0.6238, -3.4802],\n","        [-2.8441, -2.4520,  6.2332],\n","        [-2.1539, -3.4575,  6.5332],\n","        [-3.4925,  4.4866, -1.1506],\n","        [-3.3418,  4.4326, -1.2534],\n","        [-2.9084, -2.3503,  6.1797],\n","        [-2.7249,  4.7378, -2.1849],\n","        [-2.2385, -3.2336,  6.3786],\n","        [ 3.2935, -0.0156, -3.8306]]) tensor([2, 2, 1, 2, 1, 1, 0, 0, 2, 2, 1, 1, 2, 1, 2, 0]) 0.07064104825258255\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 9:  tensor([[ 3.6985, -0.5053, -3.7047],\n","        [-4.2376,  3.3266,  0.8015],\n","        [-1.5487, -3.2189,  5.4021],\n","        [-3.1331,  4.6701, -1.7003],\n","        [ 2.9406, -0.4026, -2.9745],\n","        [-4.4850, -0.2657,  5.2990],\n","        [-4.4526, -0.5679,  5.6850],\n","        [ 2.8645,  0.0260, -3.4043],\n","        [-2.4653, -3.0452,  6.4781],\n","        [ 2.8901,  0.1719, -3.6192],\n","        [ 2.8592,  0.5440, -4.0319],\n","        [-2.8968,  4.6732, -1.9498],\n","        [-3.1212, -2.0370,  6.0599],\n","        [-2.9622,  4.7070, -1.9102],\n","        [ 2.2902,  0.2670, -3.0249],\n","        [-3.1246,  4.6740, -1.7134]]) tensor([0, 2, 2, 1, 0, 2, 2, 0, 2, 1, 0, 1, 2, 1, 0, 1]) 0.3585309386253357\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 10:  tensor([[ 3.9433, -0.8299, -3.5833],\n","        [ 2.7389, -0.1871, -3.0004],\n","        [-2.5665, -3.0035,  6.5904],\n","        [ 1.0342,  1.5277, -3.0788],\n","        [-2.0175, -2.1434,  4.7292],\n","        [ 4.0189, -0.8107, -3.7014],\n","        [ 3.6795, -0.2596, -3.9713],\n","        [ 3.1492,  0.0566, -3.7588],\n","        [-3.4537,  4.4862, -1.1933],\n","        [-1.7090, -3.4968,  5.9427],\n","        [ 2.3874,  0.2710, -3.1497],\n","        [-4.8255, -0.0973,  5.4192],\n","        [ 2.8738,  0.9725, -4.5677],\n","        [-1.9102,  4.3270, -2.7118],\n","        [ 2.6292,  1.0629, -4.3909],\n","        [-3.2138, -2.3403,  6.6791]]) tensor([0, 0, 2, 1, 2, 0, 0, 0, 1, 2, 0, 2, 0, 1, 1, 2]) 0.16548798978328705\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 11:  tensor([[ 2.8793, -0.4983, -2.7865],\n","        [-1.0641, -4.1343,  5.7466],\n","        [-2.9848,  4.6964, -1.8770],\n","        [-2.8304,  4.7161, -2.0568],\n","        [-3.9777,  3.1591,  0.7043],\n","        [-3.8667,  4.0717, -0.3514],\n","        [-3.3728, -2.1527,  6.6492],\n","        [-2.7127, -2.8620,  6.6346],\n","        [-3.6667,  4.4064, -0.8963],\n","        [-2.7323,  4.7220, -2.1674],\n","        [-1.9091, -3.5940,  6.3421],\n","        [ 4.0638, -0.9131, -3.6178],\n","        [-3.3183,  4.6062, -1.4490],\n","        [ 2.7786, -0.2695, -2.9495],\n","        [ 3.2962,  0.2109, -4.1069],\n","        [ 2.3634,  0.3505, -3.2222]]) tensor([0, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 0, 1, 0, 0, 0]) 0.17704840004444122\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 12:  tensor([[-2.5955, -2.6386,  6.1359],\n","        [-3.3045,  4.5936, -1.4485],\n","        [-2.8654, -2.7187,  6.6844],\n","        [-2.4355, -3.0820,  6.4978],\n","        [-3.4917, -1.4701,  5.7643],\n","        [ 2.2364,  1.5578, -4.5370],\n","        [-2.8550, -2.7570,  6.7301],\n","        [-3.7199,  4.3595, -0.7944],\n","        [ 2.9054, -0.1530, -3.2328],\n","        [-3.7804,  4.3108, -0.6835],\n","        [ 3.0149, -0.4010, -3.0654],\n","        [-3.5619,  4.4966, -1.0914],\n","        [-2.8781,  4.7133, -2.0042],\n","        [-4.3315, -0.9459,  6.1185],\n","        [ 2.5812, -0.2417, -2.7575],\n","        [-2.5659, -2.8485,  6.3791]]) tensor([2, 1, 2, 2, 2, 1, 2, 1, 0, 1, 0, 1, 1, 2, 0, 2]) 0.0786760002374649\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 13:  tensor([[-4.3055, -1.0558,  6.2752],\n","        [ 2.5171, -0.0916, -2.8598],\n","        [-2.9769,  4.6197, -1.8118],\n","        [-3.8444,  4.3064, -0.6146],\n","        [ 2.9095, -0.5153, -2.7903],\n","        [-3.7398, -1.7756,  6.6512],\n","        [-2.8079, -2.3948,  6.1176],\n","        [-0.1428,  2.6776, -3.0394],\n","        [-3.6350, -1.8164,  6.5305],\n","        [ 0.1581, -1.8608,  1.8359],\n","        [ 2.5522, -0.3574, -2.5895],\n","        [ 2.3153,  0.2434, -3.0323],\n","        [-3.6821,  4.4480, -0.9194],\n","        [ 3.2181, -0.9822, -2.6110],\n","        [-3.3704, -2.1752,  6.6940],\n","        [ 2.2697,  0.4399, -3.2075]]) tensor([2, 0, 1, 1, 0, 2, 2, 1, 2, 2, 0, 0, 1, 0, 2, 0]) 0.04571668803691864\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 14:  tensor([[-3.6567, -1.8606,  6.6585],\n","        [-2.6430, -2.8185,  6.4715],\n","        [-3.1278, -2.0881,  6.1619],\n","        [-3.7191,  4.3620, -0.8005],\n","        [ 3.3680, -0.7527, -3.0328],\n","        [-2.9754,  4.5720, -1.7673],\n","        [-4.5129,  2.6760,  1.7783],\n","        [-3.4336,  4.4840, -1.2074],\n","        [ 2.3162, -0.0352, -2.6988],\n","        [-4.5050,  2.5096,  1.9476],\n","        [ 1.5487, -0.3876, -1.4315],\n","        [-3.1754,  4.5708, -1.5586],\n","        [-2.6883,  4.0588, -1.5996],\n","        [-3.3604,  4.5617, -1.3592],\n","        [-3.2028, -2.1807,  6.4158],\n","        [-4.0687,  4.1301, -0.2072]]) tensor([2, 2, 2, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 1]) 0.0702228918671608\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 15:  tensor([[-3.4804, -1.9888,  6.5655],\n","        [-3.6188, -1.1939,  5.5433],\n","        [ 1.8222, -0.7343, -1.3179],\n","        [ 2.3113, -0.1308, -2.5753],\n","        [-4.6505,  3.3427,  1.2016],\n","        [-1.7235, -3.6091,  6.1171],\n","        [-3.4490, -2.1270,  6.7697],\n","        [-4.6283,  2.6731,  1.8968],\n","        [-2.8893, -2.7653,  6.8229],\n","        [ 2.1576, -0.1812, -2.3436],\n","        [-3.7695,  4.3872, -0.7756],\n","        [-3.4938,  4.5327, -1.1983],\n","        [-4.5479,  2.9606,  1.4830],\n","        [-2.8559, -2.7076,  6.6606],\n","        [-2.9974, -2.5127,  6.6031],\n","        [ 1.2674, -0.7136, -0.7267]]) tensor([2, 2, 0, 0, 1, 2, 2, 1, 2, 0, 1, 1, 2, 2, 2, 0]) 0.1709362417459488\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 16:  tensor([[-3.8866e+00,  4.3100e+00, -5.8036e-01],\n","        [-4.4967e+00,  3.4101e+00,  9.7169e-01],\n","        [ 2.2608e+00, -2.4408e-01, -2.3953e+00],\n","        [ 3.3849e-01, -1.5958e+00,  1.3149e+00],\n","        [-2.4889e+00, -2.9401e+00,  6.4062e+00],\n","        [ 2.5443e+00, -3.9775e-01, -2.5375e+00],\n","        [-3.4946e+00,  4.4904e+00, -1.1539e+00],\n","        [-3.9705e+00,  4.2233e+00, -4.0403e-01],\n","        [-4.5818e+00,  2.0602e+00,  2.5210e+00],\n","        [-4.4347e+00,  2.6974e-03,  4.8666e+00],\n","        [-4.4483e+00,  3.4022e+00,  9.3368e-01],\n","        [ 2.2642e+00, -5.5912e-01, -2.0373e+00],\n","        [-3.9651e+00,  4.2733e+00, -4.6429e-01],\n","        [-2.2559e+00, -3.3303e+00,  6.5721e+00],\n","        [-3.5684e+00, -1.9597e+00,  6.6880e+00],\n","        [ 2.3058e+00, -4.4993e-01, -2.1877e+00]]) tensor([1, 1, 0, 0, 2, 0, 1, 1, 1, 2, 1, 0, 1, 2, 2, 0]) 0.17356589436531067\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 17:  tensor([[ 1.2895,  1.1487, -2.9293],\n","        [ 2.0569, -0.5973, -1.7535],\n","        [-1.8483, -3.5926,  6.2879],\n","        [-4.3740,  3.8426,  0.3931],\n","        [-0.7570, -2.0493,  3.1244],\n","        [ 0.5471,  0.3835, -1.1854],\n","        [ 2.3529, -0.5031, -2.1931],\n","        [ 1.8919, -0.4399, -1.7459],\n","        [-3.6829,  4.4596, -0.9366],\n","        [ 2.4396,  0.3238, -3.2642],\n","        [ 2.0973, -0.2410, -2.2094],\n","        [-3.7300,  4.4499, -0.8803],\n","        [-3.6640, -1.9255,  6.8175],\n","        [ 3.4007, -0.9580, -2.8319],\n","        [-3.6465, -1.9067,  6.7401],\n","        [-3.2860, -2.3514,  6.8814]]) tensor([0, 0, 2, 1, 2, 0, 0, 0, 1, 0, 0, 1, 2, 0, 2, 2]) 0.11961374431848526\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 18:  tensor([[ 1.1354,  0.0289, -1.4482],\n","        [-3.0804, -2.5556,  6.8418],\n","        [-0.8074,  2.8291, -2.4471],\n","        [ 2.5921, -1.0435, -1.8391],\n","        [-2.4079, -3.2042,  6.6497],\n","        [ 3.4163, -0.9251, -2.8835],\n","        [-3.6157,  4.5000, -1.0453],\n","        [-2.0598, -3.5275,  6.5230],\n","        [-2.6478, -2.9106,  6.6174],\n","        [-3.1496, -2.1853,  6.3332],\n","        [ 2.0027, -0.0724, -2.3057],\n","        [-4.1494,  3.8667,  0.1337],\n","        [-4.4699,  2.5002,  1.9185],\n","        [ 3.1405, -0.1403, -3.5169],\n","        [-3.0733,  4.5377, -1.6399],\n","        [-3.6146, -1.5392,  6.0423]]) tensor([0, 2, 1, 0, 2, 0, 1, 2, 2, 2, 1, 1, 1, 0, 1, 2]) 0.19653524458408356\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 19:  tensor([[ 3.2439, -0.2724, -3.4665],\n","        [-4.2249,  4.0343,  0.0408],\n","        [-2.6642, -2.5536,  6.1391],\n","        [-4.3313,  3.9410,  0.2434],\n","        [ 1.8424, -0.2658, -1.8907],\n","        [ 3.1495, -0.4806, -3.1166],\n","        [-2.2306, -3.3522,  6.5649],\n","        [-1.9786, -3.5553,  6.4335],\n","        [ 2.8515, -0.1710, -3.1439],\n","        [-0.5087, -4.5243,  5.4083],\n","        [-3.0597, -2.4481,  6.6105],\n","        [-1.8047, -3.3836,  5.9742],\n","        [ 1.9239, -0.2470, -2.0068],\n","        [ 3.1511, -0.7806, -2.7715],\n","        [-1.1382, -4.1281,  5.8700],\n","        [-5.3162,  1.3760,  3.9623]]) tensor([0, 1, 2, 1, 0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2]) 0.03204698860645294\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 20:  tensor([[-3.4739, -2.1216,  6.8192],\n","        [ 4.0369, -0.6212, -3.9253],\n","        [-3.3373,  4.6374, -1.4676],\n","        [-3.0238, -2.1583,  6.1097],\n","        [ 2.4743,  0.0677, -3.0115],\n","        [-3.8630,  4.3857, -0.6891],\n","        [-3.2611, -2.2921,  6.7150],\n","        [-3.7123, -1.3117,  5.8315],\n","        [-4.5773, -0.5801,  5.8503],\n","        [ 2.0783,  0.0947, -2.5892],\n","        [ 2.3178,  1.4870, -4.5536],\n","        [-2.8322,  4.5280, -1.8972],\n","        [-3.4958, -1.9035,  6.4471],\n","        [ 3.5495, -0.3685, -3.6895],\n","        [ 3.1958, -0.2310, -3.4622],\n","        [-4.2591,  3.1098,  1.0329]]) tensor([2, 0, 1, 2, 0, 1, 2, 2, 2, 1, 1, 1, 2, 0, 0, 1]) 0.22505183517932892\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 21:  tensor([[-3.1180, -2.0040,  6.0062],\n","        [-4.1772,  4.0981, -0.0770],\n","        [-3.2892,  4.6517, -1.5320],\n","        [ 3.0119, -0.7059, -2.7026],\n","        [-4.0677,  3.4640,  0.4659],\n","        [-3.2098, -2.3248,  6.6747],\n","        [-3.0137, -2.6124,  6.8151],\n","        [ 2.9813,  0.0515, -3.5814],\n","        [ 3.3740, -0.3325, -3.5383],\n","        [-2.9601, -2.6330,  6.7456],\n","        [-1.7506, -3.7630,  6.3474],\n","        [ 3.1734, -0.3861, -3.2508],\n","        [ 2.3716,  0.9806, -3.9776],\n","        [ 4.1688, -0.9864, -3.6397],\n","        [-3.4426,  4.5830, -1.3079],\n","        [-3.1109, -2.5185,  6.8422]]) tensor([2, 1, 1, 0, 1, 2, 2, 0, 0, 2, 2, 0, 1, 0, 1, 2]) 0.11423557251691818\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 22:  tensor([[-3.5259, -1.9170,  6.5275],\n","        [ 2.4798,  0.0759, -3.0302],\n","        [ 3.3751, -0.1767, -3.7378],\n","        [-2.0592, -3.4819,  6.4778],\n","        [-3.2974,  4.6325, -1.5061],\n","        [ 3.3195, -0.0492, -3.8281],\n","        [-4.0146,  4.2103, -0.3574],\n","        [ 2.4798,  0.0759, -3.0302],\n","        [-5.1025,  0.8244,  4.4615],\n","        [ 3.5353, -0.2232, -3.8638],\n","        [-1.9026,  4.3857, -2.8051],\n","        [-3.4497, -1.4095,  5.6181],\n","        [ 2.7559, -0.2101, -2.9815],\n","        [-1.2099,  3.7338, -2.9509],\n","        [-2.4491, -0.0109,  2.6497],\n","        [ 3.1551, -0.0466, -3.6410]]) tensor([2, 0, 0, 2, 1, 0, 1, 0, 2, 0, 1, 2, 0, 1, 1, 0]) 0.19671688973903656\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 23:  tensor([[-3.5002, -1.8943,  6.4473],\n","        [ 2.7549,  0.7592, -4.1681],\n","        [-2.8887, -2.1233,  5.8632],\n","        [ 3.7672, -0.5024, -3.7836],\n","        [-3.7739, -0.5514,  4.8521],\n","        [-3.7324,  4.4175, -0.8536],\n","        [-0.3750, -2.8574,  3.5849],\n","        [-3.8397,  4.4026, -0.7313],\n","        [-4.0124,  3.4448,  0.4225],\n","        [-1.5098, -2.9076,  5.0277],\n","        [ 3.3171,  0.2972, -4.2465],\n","        [-3.3201, -2.2032,  6.6773],\n","        [-4.1974,  0.2762,  4.2548],\n","        [-4.2223,  3.1213,  0.9854],\n","        [-3.5151,  4.6100, -1.2653],\n","        [-3.2436,  4.7238, -1.6523]]) tensor([2, 1, 2, 0, 2, 1, 2, 1, 1, 2, 0, 2, 2, 1, 1, 1]) 0.15063899755477905\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 24:  tensor([[-3.9863, -1.3646,  6.3368],\n","        [-2.2660, -3.2877,  6.5565],\n","        [ 2.6879,  1.0675, -4.4620],\n","        [-4.2887, -0.4681,  5.3426],\n","        [-2.8970, -2.7075,  6.7747],\n","        [-0.0471, -1.9557,  2.1908],\n","        [-3.2979, -2.2495,  6.7289],\n","        [-4.1888, -1.1247,  6.2319],\n","        [-3.1072, -2.3246,  6.5034],\n","        [ 4.0484, -0.1404, -4.5418],\n","        [ 4.1236, -0.4933, -4.1879],\n","        [-2.1745, -3.2132,  6.3154],\n","        [-3.2835, -2.2846,  6.7698],\n","        [ 3.1818,  0.5706, -4.4496],\n","        [-1.5074, -3.8349,  6.0973],\n","        [-3.8035, -1.6045,  6.4645]]) tensor([2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2]) 0.02497546188533306\n","epoch: 1, loss: 0.13039067324250936, acc: 0.9475\n","nan: False same_parameter: False\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 0:  tensor([[-2.0960, -3.2946,  6.3046],\n","        [-3.5966, -1.8052,  6.4781],\n","        [-3.6742,  4.5517, -1.0519],\n","        [-2.5647, -2.8368,  6.4017],\n","        [-4.0612, -1.1778,  6.1306],\n","        [ 1.6092,  2.2029, -4.5762],\n","        [ 2.8171,  0.8898, -4.4123],\n","        [-1.6824, -3.6418,  6.1274],\n","        [-3.6918,  4.5186, -0.9995],\n","        [-3.1729, -2.3856,  6.7416],\n","        [ 1.0221,  2.8006, -4.5765],\n","        [ 3.4788,  0.2920, -4.4238],\n","        [-3.6991,  3.3420,  0.1971],\n","        [-4.6772, -0.0549,  5.1973],\n","        [-3.5257, -1.7027,  6.1769],\n","        [-4.1357, -1.0586,  6.0437]]) tensor([2, 2, 1, 2, 2, 0, 1, 2, 1, 2, 0, 0, 1, 2, 2, 2]) 0.3208652436733246\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 1:  tensor([[-3.0338,  4.8109, -1.9554],\n","        [ 3.0899,  1.1226, -5.0340],\n","        [ 2.7329,  1.1979, -4.6970],\n","        [-4.1427, -0.2453,  4.8652],\n","        [ 3.7334,  0.4105, -4.8909],\n","        [-2.5665,  4.8665, -2.4976],\n","        [-1.1920, -3.4937,  5.2926],\n","        [-3.0436, -2.5045,  6.7070],\n","        [ 3.1615,  0.6542, -4.5235],\n","        [-3.6292, -1.7791,  6.4841],\n","        [-2.0580, -0.7142,  3.0748],\n","        [ 3.0259,  1.0187, -4.8206],\n","        [-3.7095,  4.5437, -1.0067],\n","        [ 4.1566, -0.0785, -4.7464],\n","        [ 3.0899,  0.7152, -4.5058],\n","        [-3.2391, -2.3171,  6.7487]]) tensor([1, 0, 0, 2, 0, 1, 2, 2, 0, 2, 2, 0, 1, 0, 0, 2]) 0.044682376086711884\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 2:  tensor([[-3.7136,  4.5209, -0.9777],\n","        [-3.2539,  4.7604, -1.6821],\n","        [ 3.1727,  0.8704, -4.8150],\n","        [-3.1278,  4.8045, -1.8514],\n","        [ 2.9728,  0.6568, -4.3094],\n","        [-3.8824,  4.2878, -0.5770],\n","        [-2.8745,  4.8253, -2.1319],\n","        [ 4.0303,  0.1829, -4.9412],\n","        [-0.7111, -1.4523,  2.3801],\n","        [ 3.1244,  1.3374, -5.3766],\n","        [ 3.2838,  0.4626, -4.4373],\n","        [-3.5234, -1.8687,  6.4531],\n","        [-2.8504,  4.8429, -2.1769],\n","        [-3.8837, -0.6754,  5.1524],\n","        [-3.0155, -2.5653,  6.7599],\n","        [-3.4127, -1.9815,  6.4564]]) tensor([1, 1, 0, 1, 0, 1, 1, 0, 2, 0, 0, 2, 1, 2, 2, 2]) 0.0320134237408638\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 3:  tensor([[ 3.3747,  0.8616, -5.0511],\n","        [ 2.9241,  1.0037, -4.6866],\n","        [-3.6212,  4.5365, -1.0881],\n","        [-3.6342,  4.5274, -1.0680],\n","        [-3.0449, -2.2478,  6.2742],\n","        [-2.8109,  4.8354, -2.2114],\n","        [-0.3350,  3.9022, -4.1451],\n","        [ 3.9770,  0.2671, -4.9941],\n","        [ 3.8147,  0.2315, -4.7565],\n","        [-1.1605, -3.3413,  5.0830],\n","        [ 2.7663,  1.7512, -5.4507],\n","        [-3.5480,  4.3751, -1.0053],\n","        [ 3.4200,  0.6713, -4.8600],\n","        [-2.5750,  4.8960, -2.5160],\n","        [ 3.6036, -0.1917, -3.9880],\n","        [-2.5411,  4.8616, -2.5191]]) tensor([0, 0, 1, 1, 2, 1, 1, 0, 0, 2, 0, 1, 0, 1, 0, 1]) 0.043455373495817184\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 4:  tensor([[-1.8422,  4.7492, -3.1953],\n","        [-2.3445, -3.1139,  6.4361],\n","        [-3.9524,  4.1623, -0.3788],\n","        [-1.7228,  2.2830, -0.8154],\n","        [-3.6945,  4.3760, -0.8564],\n","        [-1.2441, -2.9498,  4.7423],\n","        [-2.7210,  4.8874, -2.3530],\n","        [-3.2311,  4.7489, -1.6944],\n","        [-2.9508, -2.1211,  5.9430],\n","        [-1.1413, -3.1787,  4.8665],\n","        [-3.5930, -1.5377,  6.0186],\n","        [-3.2701,  0.0335,  3.5144],\n","        [-3.2590, -2.2560,  6.6667],\n","        [-0.7788, -3.0251,  4.2569],\n","        [ 3.3397,  0.8543, -4.9967],\n","        [-3.0678,  4.7977, -1.9084]]) tensor([1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 0, 1]) 0.20680037140846252\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 5:  tensor([[-2.0759, -1.7724,  4.3422],\n","        [ 3.8780,  0.3301, -4.9559],\n","        [-2.5401,  4.7650, -2.4364],\n","        [ 3.6559, -0.2248, -4.0015],\n","        [-4.0783,  1.6931,  2.4173],\n","        [ 3.7089,  0.1636, -4.5477],\n","        [-2.9513, -2.5815,  6.6531],\n","        [-2.7171, -2.8515,  6.6699],\n","        [-2.6983,  4.8525, -2.3448],\n","        [-3.4530, -1.9829,  6.5242],\n","        [-3.1149,  4.7920, -1.8530],\n","        [ 3.0882,  1.0397, -4.9373],\n","        [-2.9380, -2.6151,  6.6860],\n","        [ 3.5185,  0.2753, -4.4741],\n","        [-3.0909,  4.7497, -1.8396],\n","        [-3.2827, -1.9530,  6.2006]]) tensor([2, 0, 1, 0, 2, 0, 2, 2, 1, 2, 1, 0, 2, 0, 1, 2]) 0.04034862667322159\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 6:  tensor([[-1.8258, -2.9668,  5.5041],\n","        [ 3.2548,  0.6214, -4.5857],\n","        [-2.3758,  4.8878, -2.7206],\n","        [ 3.0167,  0.8727, -4.6223],\n","        [-3.3018,  4.6854, -1.5605],\n","        [ 3.6009,  0.3750, -4.6855],\n","        [-3.1465,  4.6393, -1.6795],\n","        [ 0.6318,  3.5227, -4.9104],\n","        [ 3.3726,  0.4559, -4.5251],\n","        [-2.2752, -3.1256,  6.3328],\n","        [-2.2547,  4.8721, -2.8391],\n","        [ 3.2704,  0.5657, -4.5390],\n","        [-2.8950,  4.8222, -2.1070],\n","        [ 1.6059,  2.5763, -5.0260],\n","        [ 3.4900,  0.5482, -4.7698],\n","        [ 3.9215, -0.2206, -4.3116]]) tensor([2, 0, 1, 0, 1, 0, 1, 1, 0, 2, 1, 0, 1, 0, 0, 0]) 0.1101139709353447\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 7:  tensor([[ 3.3563,  0.1697, -4.1395],\n","        [-2.9867,  4.7005, -1.9002],\n","        [-2.9844, -2.5718,  6.6828],\n","        [ 3.2702,  0.8003, -4.8329],\n","        [-2.5888,  4.8297, -2.4350],\n","        [-3.0996,  4.7147, -1.7957],\n","        [-3.4093, -1.6346,  5.8946],\n","        [-3.6892,  3.6671, -0.1572],\n","        [ 3.3609,  0.7752, -4.9245],\n","        [ 3.6761, -0.3321, -3.8893],\n","        [-3.2965, -2.1887,  6.6000],\n","        [-3.9034,  0.8800,  3.2059],\n","        [ 0.4322,  3.4625, -4.5904],\n","        [ 3.1870,  0.1165, -3.8865],\n","        [-3.6288, -1.6153,  6.1880],\n","        [ 3.6605,  0.4151, -4.8054]]) tensor([0, 1, 2, 0, 1, 1, 2, 1, 0, 0, 2, 2, 1, 0, 2, 0]) 0.02928718738257885\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 8:  tensor([[-1.7634e+00,  4.5836e+00, -3.1301e+00],\n","        [ 9.5213e-01, -4.3143e+00,  3.4986e+00],\n","        [ 4.5158e+00, -6.9253e-01, -4.3611e+00],\n","        [-3.4023e+00,  4.5149e+00, -1.2929e+00],\n","        [ 3.4390e+00, -1.6037e-01, -3.8266e+00],\n","        [ 3.8499e+00,  5.3914e-05, -4.5017e+00],\n","        [-2.5934e+00,  1.6100e-02,  2.7608e+00],\n","        [-2.9642e+00,  4.7054e+00, -1.9260e+00],\n","        [ 4.3058e+00, -4.2599e-01, -4.4655e+00],\n","        [-1.9378e+00, -3.1550e+00,  5.8742e+00],\n","        [ 3.7893e+00,  3.1415e-01, -4.8250e+00],\n","        [-2.9317e+00,  4.7836e+00, -2.0299e+00],\n","        [ 3.1210e+00,  4.4223e-01, -4.2126e+00],\n","        [-2.2722e+00,  4.7570e+00, -2.7145e+00],\n","        [ 3.2637e+00,  8.0426e-01, -4.8182e+00],\n","        [-3.2558e+00,  4.5992e+00, -1.5203e+00]]) tensor([1, 2, 0, 1, 0, 0, 2, 1, 0, 2, 0, 1, 0, 1, 0, 1]) 0.02496427670121193\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 9:  tensor([[-2.8689,  4.7360, -2.0503],\n","        [-2.3165, -3.1440,  6.4039],\n","        [-3.4178,  1.5844,  1.8109],\n","        [-3.0925, -2.2150,  6.2894],\n","        [-4.2538, -0.8442,  5.8544],\n","        [-2.6990, -1.6438,  4.9574],\n","        [ 0.7188,  3.4204, -4.8897],\n","        [-2.7326, -2.7850,  6.5650],\n","        [-3.3186,  4.6076, -1.4656],\n","        [ 3.6068,  0.4501, -4.7762],\n","        [ 3.1728,  0.6408, -4.5110],\n","        [-2.6838,  4.7842, -2.2906],\n","        [-3.2155, -2.3241,  6.6722],\n","        [-3.5070,  4.4445, -1.1128],\n","        [-2.2407,  4.7495, -2.7394],\n","        [ 3.8167, -0.3442, -4.0320]]) tensor([1, 2, 2, 2, 2, 2, 1, 2, 1, 0, 0, 1, 2, 1, 1, 0]) 0.05028069019317627\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 10:  tensor([[ 4.4318, -0.5959, -4.3915],\n","        [-2.7776,  4.7658, -2.1737],\n","        [ 3.5802,  0.1058, -4.3110],\n","        [-2.9058,  4.7215, -1.9975],\n","        [-2.6019, -2.9503,  6.5900],\n","        [-3.5268, -1.7220,  6.1871],\n","        [-3.8947,  4.0521, -0.3258],\n","        [-3.3969,  4.3875, -1.1686],\n","        [-2.5429,  4.7433, -2.4036],\n","        [ 4.5303, -1.0164, -3.9820],\n","        [ 3.3309,  0.2898, -4.2483],\n","        [-2.7961,  0.7894,  2.0667],\n","        [ 3.9083, -0.1958, -4.3075],\n","        [-3.7382,  4.2587, -0.6914],\n","        [-0.9852, -3.4937,  5.0125],\n","        [-3.6390,  4.3801, -0.9123]]) tensor([0, 1, 0, 1, 2, 2, 1, 1, 1, 0, 0, 2, 0, 2, 2, 1]) 0.3340792953968048\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 11:  tensor([[-1.4889, -3.7171,  5.8932],\n","        [ 0.0196, -0.3047,  0.2161],\n","        [ 3.2921, -0.0649, -3.7773],\n","        [-3.5551, -0.8013,  4.9158],\n","        [ 0.6002,  2.3374, -3.5251],\n","        [ 3.6625, -0.2696, -3.9360],\n","        [ 4.2518, -0.5239, -4.2785],\n","        [ 3.7169, -0.5147, -3.7073],\n","        [ 3.0585,  0.8622, -4.6413],\n","        [-4.2550,  0.2638,  4.3458],\n","        [ 3.7718, -0.4968, -3.7976],\n","        [-3.6032, -1.7458,  6.3567],\n","        [ 4.4748, -1.0336, -3.8928],\n","        [-3.7458,  3.2727,  0.3200],\n","        [-4.0065,  0.1512,  4.2037],\n","        [-3.7959, -1.1380,  5.6763]]) tensor([2, 2, 0, 2, 1, 0, 0, 0, 1, 2, 0, 2, 0, 1, 2, 2]) 0.2211132049560547\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 12:  tensor([[-3.8213,  3.9027, -0.2479],\n","        [-3.2795,  4.5222, -1.4153],\n","        [-4.2309,  3.9599,  0.1126],\n","        [-3.5969,  3.7293, -0.3225],\n","        [-2.6937, -2.7245,  6.4091],\n","        [ 3.7404, -0.4286, -3.8285],\n","        [-1.5022, -2.9237,  5.0208],\n","        [ 4.1438, -1.6321, -2.8558],\n","        [-4.0433, -0.8177,  5.5388],\n","        [-3.9450, -0.8457,  5.4600],\n","        [-3.5154, -1.9308,  6.5183],\n","        [-4.1783, -0.3713,  5.0849],\n","        [ 4.5274, -1.1515, -3.8112],\n","        [ 3.2515,  0.2002, -4.0418],\n","        [ 3.4044, -0.5059, -3.3671],\n","        [-3.4561,  4.5230, -1.2388]]) tensor([1, 1, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 1, 1]) 0.25461629033088684\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 13:  tensor([[ 3.4565, -0.0793, -3.9250],\n","        [-3.3561,  4.5535, -1.3666],\n","        [ 0.1765,  3.1744, -3.9720],\n","        [-2.0214, -3.1313,  5.9539],\n","        [ 3.1817, -0.2127, -3.4657],\n","        [ 2.7490,  0.1504, -3.3991],\n","        [ 4.1814, -0.7861, -3.8802],\n","        [ 4.0191, -1.3655, -3.0222],\n","        [-3.0773,  4.3992, -1.5123],\n","        [-2.2936, -3.1273,  6.3415],\n","        [-3.1211,  4.5655, -1.6217],\n","        [ 4.1509, -0.7521, -3.8886],\n","        [-3.4587,  2.4726,  0.8736],\n","        [-3.0912, -2.5046,  6.7423],\n","        [-3.1147, -1.8091,  5.7276],\n","        [ 3.7007, -0.7222, -3.4233]]) tensor([0, 1, 1, 2, 1, 0, 0, 0, 1, 2, 1, 0, 1, 2, 2, 0]) 0.23818789422512054\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 14:  tensor([[-3.1513, -2.4338,  6.7363],\n","        [-3.7062,  4.3715, -0.8320],\n","        [ 0.0620, -4.2457,  4.4607],\n","        [-3.4413,  4.4877, -1.2117],\n","        [-3.7925,  2.1519,  1.5844],\n","        [-3.0793, -2.3523,  6.4755],\n","        [-3.8622,  4.0018, -0.3054],\n","        [-3.0838, -2.3983,  6.5525],\n","        [ 3.4172, -0.5520, -3.3281],\n","        [-1.1838, -3.8165,  5.5940],\n","        [-3.3201, -1.4432,  5.4956],\n","        [-3.8462, -1.1612,  5.8017],\n","        [-4.0354,  3.6111,  0.2707],\n","        [-2.8712,  4.2492, -1.5922],\n","        [-0.5237, -2.9662,  3.8715],\n","        [ 2.9796, -0.7698, -2.5854]]) tensor([2, 1, 2, 1, 2, 2, 1, 2, 0, 2, 2, 2, 1, 1, 2, 0]) 0.07231341302394867\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 15:  tensor([[-3.3359,  0.9556,  2.4778],\n","        [ 3.4811, -1.0810, -2.7755],\n","        [-2.2742, -3.2734,  6.5052],\n","        [-4.2815,  3.3640,  0.7822],\n","        [ 2.9772, -0.6260, -2.7428],\n","        [-3.3003, -1.9828,  6.2523],\n","        [ 3.3841, -0.5555, -3.2913],\n","        [-3.3082,  4.4750, -1.3347],\n","        [ 4.2889, -1.3528, -3.3294],\n","        [-2.5184, -1.8628,  5.0224],\n","        [ 1.5256,  1.4821, -3.5983],\n","        [ 3.3921, -0.5869, -3.2489],\n","        [-1.0040, -3.9518,  5.5020],\n","        [ 2.6063, -1.1939, -1.6789],\n","        [-3.5619, -1.9027,  6.5509],\n","        [ 2.7590, -0.0684, -3.1570]]) tensor([1, 0, 2, 1, 0, 2, 0, 1, 0, 2, 1, 0, 2, 0, 2, 0]) 0.16894420981407166\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 16:  tensor([[-4.4229,  3.7085,  0.5763],\n","        [-1.4706, -3.5020,  5.6412],\n","        [-3.0547, -1.4268,  5.1331],\n","        [-3.2686,  4.4551, -1.3548],\n","        [-4.1082,  2.3220,  1.7297],\n","        [-3.9525,  3.0446,  0.7849],\n","        [-3.7102,  4.3522, -0.8037],\n","        [-3.1209, -1.5765,  5.4166],\n","        [-4.0392,  3.6613,  0.2258],\n","        [-3.9180,  4.2195, -0.4605],\n","        [ 3.4416, -1.4588, -2.2905],\n","        [-4.2165,  3.9941,  0.0726],\n","        [-3.5604,  4.4139, -1.0131],\n","        [ 2.8593, -0.3634, -2.9122],\n","        [ 2.8614, -0.5263, -2.7215],\n","        [-4.5144,  3.3125,  1.0789]]) tensor([1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0, 1, 1]) 0.2652057707309723\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 17:  tensor([[ 3.0905, -1.3946, -1.9977],\n","        [ 4.1140, -1.1750, -3.3467],\n","        [-3.6602, -1.4909,  6.0276],\n","        [ 2.7642, -0.3465, -2.8396],\n","        [ 2.9630, -0.7985, -2.5227],\n","        [-4.0856,  4.0970, -0.1649],\n","        [-1.3842, -2.7310,  4.6606],\n","        [ 2.9234, -1.6468, -1.5040],\n","        [-3.6659,  4.3422, -0.8364],\n","        [-3.7814,  4.3010, -0.6753],\n","        [-2.2796, -3.0003,  6.1665],\n","        [-3.1114, -2.4692,  6.7327],\n","        [-3.3407, -2.2309,  6.7458],\n","        [-2.5800, -2.9383,  6.5380],\n","        [-4.4088,  3.6955,  0.5733],\n","        [-3.0357, -2.5558,  6.7379]]) tensor([1, 0, 2, 1, 0, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2]) 0.7725252509117126\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 18:  tensor([[ 2.8773, -0.4041, -2.8935],\n","        [-3.9117,  1.7286,  2.2073],\n","        [-4.5324, -0.3911,  5.5272],\n","        [-4.2331,  3.8347,  0.2604],\n","        [-2.3638, -2.8989,  6.1557],\n","        [-2.5695,  3.8052, -1.4809],\n","        [ 2.8060, -0.3498, -2.8786],\n","        [-4.0965,  3.7446,  0.2103],\n","        [-4.1931,  3.8878,  0.1698],\n","        [-4.5863,  3.1828,  1.2906],\n","        [ 2.8809, -0.5387, -2.7357],\n","        [ 1.3684,  1.0094, -2.8575],\n","        [-3.9289,  3.7391,  0.0414],\n","        [ 2.8140, -0.8095, -2.3513],\n","        [-4.1971,  3.9333,  0.1234],\n","        [-3.7840, -0.5795,  4.9070]]) tensor([0, 1, 2, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 2]) 0.14345799386501312\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 19:  tensor([[ 3.7758, -0.9022, -3.3081],\n","        [ 1.4359,  1.2312, -3.1947],\n","        [ 1.7432,  0.6923, -2.9072],\n","        [-4.2046,  2.9953,  1.1075],\n","        [-3.0507,  4.1460, -1.2859],\n","        [-3.8696, -1.4312,  6.2680],\n","        [-2.6334, -2.4409,  5.9404],\n","        [ 2.8139, -0.3782, -2.8620],\n","        [ 3.3577, -0.7645, -3.0071],\n","        [ 1.7416, -1.5069, -0.3680],\n","        [ 1.8528,  0.1818, -2.4304],\n","        [ 3.2243, -0.5477, -3.1190],\n","        [ 2.5941, -0.4051, -2.5867],\n","        [-3.9227, -1.2626,  6.0752],\n","        [ 2.6330, -0.1762, -2.9049],\n","        [ 2.0693, -0.2686, -2.1493]]) tensor([0, 1, 1, 1, 1, 2, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0]) 0.2895711660385132\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 20:  tensor([[-3.6738, -1.7726,  6.5485],\n","        [ 2.7560, -0.6562, -2.4750],\n","        [-4.2103,  3.9029,  0.1774],\n","        [-4.5888, -0.1381,  5.2358],\n","        [-4.2904,  3.7315,  0.4337],\n","        [-0.7309,  2.7189, -2.4215],\n","        [-2.7487, -2.6973,  6.4766],\n","        [ 2.0346, -0.0948, -2.3147],\n","        [ 3.7071, -1.1023, -3.0013],\n","        [-3.8721,  4.1645, -0.4358],\n","        [-3.9095,  4.0805, -0.3140],\n","        [-3.5564,  4.3340, -0.9244],\n","        [-3.6104,  4.3274, -0.8605],\n","        [-2.5287, -2.9216,  6.4436],\n","        [-3.1198,  4.3812, -1.4279],\n","        [ 2.0908, -0.2727, -2.1832]]) tensor([2, 0, 1, 2, 1, 1, 2, 0, 0, 1, 1, 1, 1, 2, 1, 0]) 0.025893837213516235\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 21:  tensor([[ 1.5163e+00, -2.1689e-01, -1.5886e+00],\n","        [ 3.3301e+00, -7.9727e-01, -2.9426e+00],\n","        [-3.7509e+00, -1.4393e+00,  6.1059e+00],\n","        [ 2.4355e+00, -2.0315e-01, -2.6450e+00],\n","        [-3.3472e+00,  4.3388e+00, -1.1444e+00],\n","        [-4.2369e+00, -7.9415e-01,  5.7673e+00],\n","        [ 2.9284e+00, -4.5316e-01, -2.9061e+00],\n","        [ 2.3898e+00, -7.0609e-02, -2.7470e+00],\n","        [ 1.8195e+00,  2.9936e-03, -2.1853e+00],\n","        [-3.1719e+00, -2.1501e+00,  6.3369e+00],\n","        [-3.5105e+00,  4.3212e+00, -9.5282e-01],\n","        [ 1.8776e+00, -1.0063e-01, -2.1220e+00],\n","        [ 1.8678e+00,  1.0452e-01, -2.3652e+00],\n","        [ 2.2988e+00,  2.8117e-01, -3.0569e+00],\n","        [ 4.3417e-01,  1.3809e+00, -2.2013e+00],\n","        [-4.1339e+00,  2.6649e+00,  1.3997e+00]]) tensor([0, 0, 2, 0, 1, 2, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1]) 0.10233000665903091\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 22:  tensor([[ 1.3887,  0.4953, -2.2850],\n","        [ 1.5872,  0.5603, -2.5840],\n","        [-2.9740, -2.4150,  6.4323],\n","        [ 1.4161, -0.2012, -1.5021],\n","        [ 1.9464,  0.2338, -2.6022],\n","        [-4.1184,  2.8446,  1.1930],\n","        [-3.5954, -1.7214,  6.3314],\n","        [-3.6792,  4.1188, -0.5828],\n","        [-4.2295,  3.5096,  0.6073],\n","        [-3.3968, -2.1049,  6.6613],\n","        [-1.1299, -3.4174,  5.1149],\n","        [-4.2343, -0.5820,  5.4663],\n","        [ 3.6847, -1.2491, -2.8226],\n","        [-3.1158,  4.1873, -1.2419],\n","        [ 1.7028,  0.0162, -2.0769],\n","        [ 1.4432,  0.6952, -2.5618]]) tensor([1, 0, 2, 0, 0, 1, 2, 1, 1, 2, 2, 2, 0, 1, 0, 0]) 0.17618323862552643\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 23:  tensor([[-3.8065,  4.2068, -0.5334],\n","        [-1.9468, -1.4652,  3.8450],\n","        [-3.0854,  4.2256, -1.3104],\n","        [-3.6579, -1.5810,  6.1991],\n","        [ 1.9464, -0.3584, -1.9128],\n","        [-3.2193,  4.3602, -1.2979],\n","        [-2.3926, -2.9974,  6.3478],\n","        [-3.0199,  4.3228, -1.4732],\n","        [-3.3375,  4.4191, -1.2283],\n","        [ 1.1949,  0.3049, -1.8414],\n","        [-3.6826, -1.6646,  6.3821],\n","        [-1.5656,  3.6171, -2.4155],\n","        [-3.7001,  4.2476, -0.6884],\n","        [-0.6133, -3.5480,  4.6046],\n","        [-3.8405,  3.8223, -0.1192],\n","        [ 1.4028,  0.7185, -2.5592]]) tensor([1, 2, 1, 2, 0, 1, 2, 1, 1, 0, 2, 1, 1, 2, 1, 0]) 0.06173544377088547\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 24:  tensor([[-4.1459,  3.2399,  0.7979],\n","        [ 2.5287,  0.1131, -3.1408],\n","        [ 1.3828,  1.0391, -2.9091],\n","        [ 2.7842, -0.3784, -2.8382],\n","        [ 1.5825,  0.4958, -2.5044],\n","        [-3.9642,  4.0139, -0.1809],\n","        [ 1.6526,  0.3308, -2.4010],\n","        [ 1.8161, -0.0687, -2.1148],\n","        [-1.2113,  2.9487, -2.1186],\n","        [ 3.0713,  0.1254, -3.7658],\n","        [-2.7643,  4.2662, -1.6982],\n","        [-3.4811,  4.1456, -0.8175],\n","        [-3.9693, -0.6074,  5.1865],\n","        [ 1.0120,  0.7703, -2.1752],\n","        [ 2.4003, -1.1586, -1.5090],\n","        [ 1.6649,  0.8328, -2.9960]]) tensor([1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 2, 0, 0, 0]) 0.24472981691360474\n","epoch: 2, loss: 0.17094793491065502, acc: 0.9425\n","nan: False same_parameter: False\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 0:  tensor([[ 3.3840, -0.2274, -3.7129],\n","        [ 3.0616,  0.1567, -3.7962],\n","        [ 2.2948,  0.3556, -3.1709],\n","        [-3.1894,  4.4487, -1.4094],\n","        [-4.1584, -0.9967,  5.9933],\n","        [-3.6809, -1.7328,  6.5069],\n","        [ 1.9852,  0.2648, -2.6845],\n","        [ 3.0425, -0.3462, -3.1667],\n","        [ 1.5042,  0.8930, -2.8900],\n","        [-1.4510, -0.1298,  1.6726],\n","        [ 1.5318,  0.7260, -2.7070],\n","        [ 3.0653,  0.2034, -3.8557],\n","        [-2.0167, -3.4046,  6.3030],\n","        [-2.5244,  4.2121, -1.9102],\n","        [ 2.9913,  0.5633, -4.2130],\n","        [ 1.8771,  0.6826, -3.0608]]) tensor([0, 0, 0, 1, 2, 2, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0]) 0.11613070219755173\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 1:  tensor([[-2.4591, -1.4929,  4.4940],\n","        [ 1.7328,  0.6696, -2.8764],\n","        [-3.1595,  4.4529, -1.4437],\n","        [ 3.0909,  0.1487, -3.8119],\n","        [-3.8208, -0.8045,  5.2744],\n","        [ 1.3596,  1.1371, -3.0073],\n","        [-4.0974, -0.8197,  5.6419],\n","        [-3.3892, -2.0791,  6.6028],\n","        [ 0.0355,  2.5903, -3.1403],\n","        [-3.8194, -0.9185,  5.4296],\n","        [-4.1377,  0.1450,  4.3829],\n","        [ 3.4082, -0.3659, -3.5587],\n","        [ 3.2390, -0.1994, -3.5784],\n","        [-3.3137,  4.4787, -1.3083],\n","        [-3.1230,  4.4948, -1.5229],\n","        [ 1.8610,  0.8235, -3.2055]]) tensor([2, 0, 1, 0, 2, 0, 2, 2, 1, 2, 2, 0, 0, 1, 1, 0]) 0.08920535445213318\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 2:  tensor([[-3.0998,  4.5009, -1.5541],\n","        [-4.6152,  0.0556,  5.0093],\n","        [-3.6927, -0.9795,  5.3508],\n","        [-3.6142,  4.3038, -0.8318],\n","        [-3.7624, -0.6070,  4.9254],\n","        [ 1.4043,  0.6902, -2.5295],\n","        [-4.2550,  0.2696,  4.3441],\n","        [-3.8107, -1.2965,  5.9763],\n","        [ 2.4432,  0.0391, -2.9379],\n","        [-3.6425,  3.1131,  0.4097],\n","        [ 1.9190,  0.6722, -3.0964],\n","        [-3.8410,  3.1924,  0.5429],\n","        [ 2.5435, -0.1386, -2.8446],\n","        [-3.7789,  2.8974,  0.7884],\n","        [-3.5947,  4.3280, -0.8746],\n","        [ 3.4781, -0.2573, -3.7845]]) tensor([1, 2, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 0, 1, 1, 0]) 0.1165887638926506\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 3:  tensor([[-2.6210,  4.4752, -2.0404],\n","        [ 2.7030,  0.0338, -3.2469],\n","        [-3.2970, -2.2080,  6.6513],\n","        [ 2.1375, -0.0269, -2.5177],\n","        [-3.5099,  4.4088, -1.0396],\n","        [-1.5121, -2.2214,  4.2082],\n","        [-3.4828,  4.3246, -0.9821],\n","        [ 1.0927,  0.8190, -2.3173],\n","        [ 0.8364,  1.1987, -2.4852],\n","        [-2.8771, -1.2082,  4.6640],\n","        [-2.3173, -3.1413,  6.4119],\n","        [ 1.8089,  0.6539, -2.9470],\n","        [-3.2460, -2.1832,  6.5135],\n","        [-3.0761, -2.4139,  6.6008],\n","        [-3.0041,  4.5674, -1.7173],\n","        [ 1.9261,  0.6115, -3.0310]]) tensor([1, 0, 2, 0, 1, 2, 1, 0, 1, 2, 2, 0, 2, 2, 1, 0]) 0.11634217202663422\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 4:  tensor([[-2.6211e+00, -2.4861e+00,  5.9843e+00],\n","        [-3.8548e+00,  4.0234e+00, -3.0197e-01],\n","        [ 2.5938e+00,  4.1029e-01, -3.5585e+00],\n","        [-1.2608e+00, -3.5645e+00,  5.4329e+00],\n","        [-3.9620e+00,  9.5057e-04,  4.3758e+00],\n","        [ 3.5235e+00, -4.8899e-01, -3.5438e+00],\n","        [-3.7042e+00,  3.2540e+00,  3.3194e-01],\n","        [-3.0099e+00, -2.4093e+00,  6.4699e+00],\n","        [ 3.3089e+00, -6.6598e-01, -3.0943e+00],\n","        [-4.2162e+00,  2.3892e-01,  4.3468e+00],\n","        [ 1.6368e+00,  9.2170e-01, -3.0652e+00],\n","        [-3.2189e+00, -1.5653e+00,  5.5457e+00],\n","        [-2.0235e+00,  4.1096e+00, -2.3704e+00],\n","        [ 1.8207e+00,  4.9704e-01, -2.7735e+00],\n","        [-3.4111e+00,  4.4113e+00, -1.1479e+00],\n","        [ 1.5074e+00,  1.6182e+00, -3.7285e+00]]) tensor([2, 1, 0, 2, 2, 0, 1, 2, 0, 2, 0, 2, 1, 0, 1, 1]) 0.09654000401496887\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 5:  tensor([[ 1.9998e+00,  6.0673e-01, -3.1102e+00],\n","        [ 1.7340e+00,  1.1044e+00, -3.3922e+00],\n","        [ 2.1838e+00,  6.1796e-01, -3.3426e+00],\n","        [-4.3788e+00, -4.6999e-02,  4.8974e+00],\n","        [-3.5934e+00,  4.1888e+00, -7.4421e-01],\n","        [-3.3975e+00, -2.0465e+00,  6.5419e+00],\n","        [-3.1841e+00,  4.5526e+00, -1.5149e+00],\n","        [-2.7300e+00,  4.5877e+00, -2.0295e+00],\n","        [ 2.3507e+00,  3.1875e-03, -2.8010e+00],\n","        [ 3.6271e+00, -3.1009e-01, -3.8705e+00],\n","        [-2.9152e+00, -2.4641e+00,  6.3908e+00],\n","        [ 2.1464e+00,  6.1994e-01, -3.2925e+00],\n","        [-2.8102e+00,  4.4188e+00, -1.7931e+00],\n","        [ 2.1719e+00,  7.8263e-01, -3.5019e+00],\n","        [-3.2740e+00, -2.2395e+00,  6.6514e+00],\n","        [-3.3676e+00,  4.3357e+00, -1.1216e+00]]) tensor([0, 0, 0, 2, 1, 2, 1, 1, 0, 0, 2, 0, 1, 0, 2, 1]) 0.08875926584005356\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 6:  tensor([[-1.5869, -3.0410,  5.2587],\n","        [-3.5662, -1.8494,  6.4905],\n","        [-4.0450,  3.5395,  0.3847],\n","        [-1.5570, -3.6274,  5.8853],\n","        [ 3.5670, -0.1878, -3.9547],\n","        [ 1.9713,  0.4755, -2.9151],\n","        [-3.2919,  4.5046, -1.3599],\n","        [-1.9741, -2.5138,  5.1325],\n","        [ 2.4049,  0.2122, -3.1035],\n","        [-2.2668,  4.0995, -2.0967],\n","        [-3.9257,  0.9009,  3.2115],\n","        [-2.3057, -2.8604,  6.0149],\n","        [-3.6932,  4.1140, -0.5645],\n","        [ 1.6703,  1.4817, -3.7662],\n","        [-3.8176, -0.7882,  5.2430],\n","        [ 2.0285,  0.7147, -3.2734]]) tensor([2, 2, 1, 2, 0, 0, 1, 2, 0, 1, 2, 2, 1, 1, 2, 0]) 0.0961461141705513\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 7:  tensor([[-3.9625, -0.0335,  4.4173],\n","        [-2.7141, -2.1602,  5.6615],\n","        [ 3.1274, -0.1366, -3.5129],\n","        [-1.5005, -2.2702,  4.2342],\n","        [-0.2130,  3.0218, -3.3381],\n","        [-3.6457,  4.2186, -0.7171],\n","        [-3.6784,  3.5127,  0.0342],\n","        [-2.6910, -2.6010,  6.2275],\n","        [ 2.1739,  1.0137, -3.7981],\n","        [-3.1417, -2.3526,  6.5853],\n","        [-2.6453,  4.5372, -2.0765],\n","        [ 3.6310, -0.7707, -3.3344],\n","        [ 2.8273,  0.0450, -3.3874],\n","        [-3.6214,  4.2859, -0.8088],\n","        [-3.3504, -1.9706,  6.3261],\n","        [-2.5200,  4.5755, -2.2496]]) tensor([2, 2, 0, 2, 1, 1, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1]) 0.10349838435649872\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 8:  tensor([[-4.6439,  0.4481,  4.5332],\n","        [-3.6609, -1.7660,  6.5002],\n","        [-3.0744, -2.2856,  6.3629],\n","        [ 2.4671,  0.5504, -3.5910],\n","        [-3.3536, -2.1593,  6.6402],\n","        [ 1.8071,  1.4154, -3.8527],\n","        [ 2.2959,  0.1112, -2.8520],\n","        [ 2.7705, -0.3333, -2.8896],\n","        [-0.7822, -4.0106,  5.2636],\n","        [-3.3893, -2.1030,  6.6095],\n","        [ 3.6290,  0.0229, -4.2814],\n","        [-3.4377,  3.6628, -0.3832],\n","        [ 3.3457, -0.3758, -3.4741],\n","        [-3.2891, -2.0076,  6.2802],\n","        [-3.5734,  4.0067, -0.5834],\n","        [-2.6101,  4.5749, -2.1512]]) tensor([2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 1, 0, 2, 1, 1]) 0.057508472353219986\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 9:  tensor([[ 2.9027,  0.5319, -4.0629],\n","        [ 3.8612, -0.6075, -3.7757],\n","        [ 3.4342, -0.4442, -3.4917],\n","        [ 2.4855,  0.0518, -3.0058],\n","        [ 2.2689,  0.6578, -3.4720],\n","        [-3.5001,  4.1902, -0.8422],\n","        [ 2.6263,  0.3570, -3.5294],\n","        [-1.0895,  0.8254,  0.1450],\n","        [ 2.8535, -0.4561, -2.8200],\n","        [ 2.9422,  0.1314, -3.6222],\n","        [ 3.0653,  0.5630, -4.3017],\n","        [ 2.9637, -0.1252, -3.3441],\n","        [-2.7396,  4.7028, -2.1270],\n","        [-3.6532,  3.2197,  0.3005],\n","        [ 1.7488,  0.8742, -3.1350],\n","        [-2.4443,  0.4046,  2.1499]]) tensor([0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 2, 0, 2]) 0.3380620777606964\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 10:  tensor([[ 2.6492,  0.1688, -3.3264],\n","        [ 2.8758,  0.0640, -3.4697],\n","        [-3.4031, -2.0484,  6.5302],\n","        [-3.1602, -1.7724,  5.7411],\n","        [-3.5957, -1.7774,  6.3958],\n","        [-3.9752, -1.2711,  6.1575],\n","        [-3.2181,  4.5344, -1.4672],\n","        [ 3.8661, -0.4623, -3.9482],\n","        [ 3.5240,  0.0120, -4.1529],\n","        [ 2.8757,  0.4791, -3.9679],\n","        [-2.4550, -1.5195,  4.5048],\n","        [ 2.5629,  0.1533, -3.2121],\n","        [ 3.8505, -0.4932, -3.8989],\n","        [ 2.5378,  0.5410, -3.6579],\n","        [-4.2334,  0.0427,  4.6318],\n","        [-3.2484,  4.3759, -1.2919]]) tensor([0, 0, 2, 2, 2, 2, 1, 0, 0, 0, 2, 1, 0, 0, 2, 1]) 0.183589369058609\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 11:  tensor([[-0.2057, -4.1384,  4.6672],\n","        [-2.1630, -2.8889,  5.8334],\n","        [-2.1509,  4.5236, -2.6127],\n","        [-2.9630, -2.5135,  6.5214],\n","        [ 2.5913, -0.4031, -2.5864],\n","        [ 2.8928, -0.7184, -2.5586],\n","        [-3.8822,  3.9456, -0.2084],\n","        [-2.4994,  4.5717, -2.2693],\n","        [-3.1263, -2.4403,  6.6888],\n","        [ 2.5612,  0.0318, -3.0633],\n","        [ 2.8890, -0.4047, -2.9221],\n","        [-4.0880,  3.3028,  0.6823],\n","        [-3.2436, -2.2318,  6.5546],\n","        [-3.6409,  3.1972,  0.3184],\n","        [-3.2623, -2.3050,  6.7100],\n","        [ 3.3841, -0.3533, -3.5469]]) tensor([2, 2, 1, 2, 0, 0, 1, 1, 2, 0, 0, 1, 2, 1, 2, 0]) 0.024020934477448463\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 12:  tensor([[-2.7802,  4.6181, -2.0058],\n","        [-3.7147, -1.6545,  6.3867],\n","        [-2.4290,  4.5049, -2.2872],\n","        [-3.7532, -1.5249,  6.2259],\n","        [-3.2715, -2.1539,  6.4652],\n","        [ 2.1568, -0.0206, -2.5316],\n","        [-3.1788, -2.4106,  6.7275],\n","        [ 2.7258, -0.3532, -2.7955],\n","        [-4.2081, -0.2217,  4.9342],\n","        [-3.5633,  3.9475, -0.5404],\n","        [ 2.7729, -0.2773, -2.9398],\n","        [-0.6522, -3.7210,  4.8051],\n","        [-3.2411, -2.2581,  6.5823],\n","        [-5.0202,  0.8111,  4.4251],\n","        [ 2.3052, -0.1566, -2.5444],\n","        [-3.3960,  4.2784, -1.0403]]) tensor([1, 2, 1, 2, 2, 0, 2, 0, 2, 1, 0, 2, 2, 2, 0, 1]) 0.022647012025117874\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 13:  tensor([[-3.7595,  4.2269, -0.6088],\n","        [-3.2925, -1.9224,  6.1336],\n","        [-3.8528,  3.9235, -0.2120],\n","        [-3.0435,  4.6092, -1.7180],\n","        [ 3.9873, -0.7243, -3.7668],\n","        [ 3.7617, -1.2846, -2.8695],\n","        [ 1.5246,  0.7274, -2.6854],\n","        [-3.5694, -1.8696,  6.4998],\n","        [-3.1274, -2.4495,  6.6969],\n","        [-2.9031,  4.5941, -1.8526],\n","        [ 2.3393,  0.2677, -3.0919],\n","        [-3.2223,  4.5179, -1.4524],\n","        [ 2.3822,  0.5315, -3.4603],\n","        [-2.9515,  4.6241, -1.8287],\n","        [-3.6532, -1.0246,  5.3548],\n","        [ 3.8736, -1.3258, -2.9384]]) tensor([1, 2, 1, 1, 0, 0, 0, 2, 2, 1, 0, 1, 0, 1, 2, 0]) 0.04459179937839508\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 14:  tensor([[-3.0657,  4.5998, -1.6862],\n","        [-2.1141, -2.4121,  5.1768],\n","        [-3.0482,  4.5663, -1.6705],\n","        [-2.9123, -2.6396,  6.6170],\n","        [ 3.2159, -0.5402, -3.1321],\n","        [-3.3760, -2.1035,  6.5520],\n","        [ 2.6851, -0.1259, -3.0141],\n","        [-2.8059,  4.6225, -1.9825],\n","        [-3.3065, -2.2649,  6.7102],\n","        [-2.2267, -3.3025,  6.4324],\n","        [-0.8432, -4.1135,  5.4192],\n","        [ 2.7886, -0.4315, -2.7708],\n","        [-3.1727,  4.5594, -1.5373],\n","        [-3.3285, -1.7146,  5.8846],\n","        [ 2.6710, -0.3556, -2.7283],\n","        [-3.6156, -1.9123,  6.6570]]) tensor([1, 2, 1, 2, 0, 2, 0, 1, 2, 2, 2, 1, 1, 2, 0, 2]) 0.21344561874866486\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 15:  tensor([[ 2.6863, -0.3628, -2.7379],\n","        [-2.7873,  4.5575, -1.9407],\n","        [ 3.0283, -0.3674, -3.1217],\n","        [-2.9096,  4.2531, -1.5372],\n","        [-3.1608,  4.5832, -1.5693],\n","        [-3.5173, -1.4874,  5.8282],\n","        [-3.9762, -1.0049,  5.7504],\n","        [-3.6563, -1.4039,  5.8993],\n","        [-3.4351,  4.4521, -1.1644],\n","        [ 3.5826, -1.0989, -2.8912],\n","        [-3.1570, -2.3654,  6.5994],\n","        [-3.8015, -1.6810,  6.5713],\n","        [-3.7990,  3.8770, -0.2176],\n","        [-3.5933, -1.9191,  6.6208],\n","        [-3.2137,  4.5525, -1.4855],\n","        [ 3.2928, -0.7209, -3.0014]]) tensor([1, 1, 0, 1, 1, 2, 2, 2, 1, 0, 2, 2, 1, 2, 1, 0]) 0.2000529021024704\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 16:  tensor([[ 3.1028, -1.5486, -1.8486],\n","        [-3.7060,  3.2063,  0.3758],\n","        [-0.9425, -3.9150,  5.3550],\n","        [ 2.4700, -0.4489, -2.3941],\n","        [ 2.6618, -0.1339, -2.9739],\n","        [-3.8827,  1.9053,  1.9932],\n","        [-2.7557, -2.6872,  6.4205],\n","        [ 2.8233, -0.7334, -2.4581],\n","        [-3.8940,  3.4631,  0.3058],\n","        [ 3.4690, -0.5206, -3.4203],\n","        [ 2.6745, -0.6004, -2.4521],\n","        [-3.3635,  4.4419, -1.2296],\n","        [-3.2814, -2.2432,  6.6201],\n","        [-3.3333, -1.9550,  6.2427],\n","        [-1.7224, -2.0849,  4.3047],\n","        [ 3.1803, -1.0571, -2.4843]]) tensor([0, 1, 2, 0, 1, 2, 2, 1, 1, 0, 0, 1, 2, 2, 2, 0]) 0.4604434370994568\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 17:  tensor([[ 4.0028, -1.5401, -2.8377],\n","        [-2.2459, -3.3183,  6.4796],\n","        [-2.9091,  4.4888, -1.7429],\n","        [-3.3723, -0.8427,  4.7636],\n","        [ 3.1651, -1.3207, -2.1840],\n","        [-3.5188, -1.4888,  5.8214],\n","        [-3.1295,  4.5380, -1.5575],\n","        [-3.5265,  4.3604, -0.9767],\n","        [-3.5330,  3.0968,  0.3108],\n","        [ 2.4455, -0.3276, -2.5110],\n","        [-2.6397, -2.4952,  5.9893],\n","        [-3.8077, -1.5306,  6.3125],\n","        [-3.6711, -1.8254,  6.5930],\n","        [-3.2562,  4.4296, -1.3247],\n","        [-3.7885,  1.9577,  1.8361],\n","        [ 2.7824, -0.6985, -2.4510]]) tensor([0, 2, 1, 2, 0, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 0]) 0.22585341334342957\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 18:  tensor([[ 2.6961, -0.2830, -2.8509],\n","        [ 2.4156, -0.2886, -2.5154],\n","        [-2.4230,  4.3792, -2.1706],\n","        [-3.3534,  4.4576, -1.2417],\n","        [-3.5302,  4.3210, -0.9319],\n","        [ 2.4996, -0.6230, -2.2093],\n","        [-4.0460,  3.4622,  0.4717],\n","        [ 2.4814, -0.9436, -1.8383],\n","        [ 3.4601, -1.2246, -2.6111],\n","        [ 2.7131, -0.6260, -2.4613],\n","        [ 3.1029, -0.5229, -3.0227],\n","        [-3.7874,  3.1023,  0.5775],\n","        [ 3.9401, -1.5928, -2.7067],\n","        [ 2.6927, -0.8150, -2.2189],\n","        [-3.4256,  4.4099, -1.1221],\n","        [-4.0519, -1.2879,  6.2949]]) tensor([0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 2]) 0.030482690781354904\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 19:  tensor([[ 3.0705, -0.6256, -2.8737],\n","        [-1.8734, -2.1509,  4.5658],\n","        [-2.1000,  3.8085, -1.9867],\n","        [ 3.1424, -2.1726, -1.2044],\n","        [ 2.5717, -0.5944, -2.3356],\n","        [-3.1170, -2.4337,  6.6433],\n","        [-3.7746,  3.9408, -0.2921],\n","        [-2.9945,  4.5190, -1.6770],\n","        [ 3.9357, -1.8216, -2.4562],\n","        [-3.0022,  4.5363, -1.6840],\n","        [ 2.6456, -0.4995, -2.5368],\n","        [-3.3089, -2.1961,  6.5910],\n","        [ 2.2896,  0.5113, -3.3178],\n","        [-3.1778, -2.3972,  6.6931],\n","        [-3.4305,  4.4445, -1.1496],\n","        [-2.7611, -2.5267,  6.2152]]) tensor([0, 2, 1, 0, 0, 2, 1, 1, 0, 1, 0, 2, 1, 2, 1, 2]) 0.13227425515651703\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 20:  tensor([[-3.4935, -1.9973,  6.5835],\n","        [ 2.4625, -0.6343, -2.1775],\n","        [-3.2018,  4.4614, -1.3993],\n","        [-3.5630, -1.6431,  6.1200],\n","        [ 1.8058, -0.8267, -1.2241],\n","        [-0.3305, -0.1536,  0.4337],\n","        [-3.2281, -1.4772,  5.4216],\n","        [-3.6005, -1.9504,  6.6995],\n","        [-3.0809,  4.5188, -1.5826],\n","        [-1.3131, -3.5425,  5.4532],\n","        [ 1.9155, -0.7538, -1.4125],\n","        [-0.3150, -2.9832,  3.6208],\n","        [-3.8622,  3.8744, -0.1390],\n","        [-3.1322,  4.5135, -1.5239],\n","        [-3.3468, -2.2508,  6.7611],\n","        [ 4.0074, -1.5812, -2.8083]]) tensor([2, 0, 1, 2, 0, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 0]) 0.2677268981933594\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 21:  tensor([[-2.2441,  4.1918, -2.1917],\n","        [ 2.9758, -0.5709, -2.8270],\n","        [-3.7353, -1.6707,  6.4421],\n","        [ 2.3465, -0.4407, -2.2712],\n","        [-3.0850,  4.2402, -1.3155],\n","        [-3.2745,  4.4444, -1.3065],\n","        [-3.9037,  3.5526,  0.2411],\n","        [-3.2060,  4.3709, -1.3067],\n","        [-0.6450,  2.6529, -2.4163],\n","        [-3.2414, -0.8051,  4.5724],\n","        [-3.2922,  3.4553, -0.3236],\n","        [ 2.0963,  0.2378, -2.7764],\n","        [ 3.4162, -1.0177, -2.8041],\n","        [-2.1932, -3.1984,  6.2621],\n","        [-2.7935,  4.5846, -1.9439],\n","        [ 2.5003, -0.6411, -2.2167]]) tensor([1, 0, 2, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 2, 1, 0]) 0.14378134906291962\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 22:  tensor([[ 2.2703, -0.2431, -2.4171],\n","        [-3.0045,  1.5604,  1.4466],\n","        [-3.3937, -1.9099,  6.2825],\n","        [-2.6674,  4.4013, -1.9165],\n","        [-3.7615, -1.2110,  5.7701],\n","        [-2.7630,  0.8061,  2.0482],\n","        [-4.1392, -1.0284,  6.0111],\n","        [ 1.3451,  0.7681, -2.5341],\n","        [ 1.3447,  0.5846, -2.3440],\n","        [-2.3540,  4.2277, -2.1018],\n","        [-2.9294, -1.4101,  4.9610],\n","        [-3.9517, -1.0862,  5.8433],\n","        [-3.2069,  4.4503, -1.3791],\n","        [-3.6631, -1.2526,  5.6916],\n","        [-2.4557, -3.0076,  6.4097],\n","        [-2.1486,  0.8293,  1.3374]]) tensor([0, 1, 2, 1, 2, 1, 2, 1, 0, 1, 2, 2, 1, 2, 2, 2]) 0.26087716221809387\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 23:  tensor([[ 9.2682e-01,  1.4522e+00, -2.8651e+00],\n","        [-4.1171e+00, -9.8189e-01,  5.9094e+00],\n","        [-2.1890e-01,  2.8798e+00, -3.1637e+00],\n","        [ 1.6605e+00, -1.1046e+00, -7.5037e-01],\n","        [ 1.8902e+00,  1.7116e-01, -2.4623e+00],\n","        [-3.7078e+00,  4.0519e+00, -4.6942e-01],\n","        [ 2.3236e+00, -9.6352e-02, -2.6606e+00],\n","        [ 2.3430e+00,  9.0564e-03, -2.7988e+00],\n","        [-2.7374e+00,  4.6022e+00, -2.0202e+00],\n","        [-3.7604e+00,  3.1451e+00,  5.2502e-01],\n","        [-2.0502e+00, -1.1985e+00,  3.6385e+00],\n","        [ 1.8839e+00,  4.0037e-01, -2.7325e+00],\n","        [ 1.7535e+00,  6.7371e-01, -2.9026e+00],\n","        [ 1.8695e+00,  2.0992e-01, -2.4939e+00],\n","        [ 2.7343e+00,  2.1385e-03, -3.2500e+00],\n","        [-3.3055e+00,  4.3946e+00, -1.2255e+00]]) tensor([1, 2, 1, 0, 0, 1, 0, 0, 1, 1, 2, 0, 1, 0, 1, 1]) 0.35633572936058044\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00042187500000000005\n","for batch 24:  tensor([[-3.2020,  4.3920, -1.3335],\n","        [-3.1248,  4.5034, -1.5164],\n","        [-3.2070, -2.0296,  6.1875],\n","        [-2.4783,  4.4162, -2.1400],\n","        [-2.8510,  4.5833, -1.8828],\n","        [ 2.0817,  0.3463, -2.8961],\n","        [-3.4512, -2.0864,  6.6840],\n","        [-3.5378,  3.1750,  0.2515],\n","        [-2.6709,  4.5364, -2.0349],\n","        [ 3.2672, -0.3889, -3.3870],\n","        [-3.3867,  4.3637, -1.1092],\n","        [-1.1960,  3.7134, -2.9182],\n","        [-2.6316, -1.2965,  4.4476],\n","        [ 2.3687, -0.2051, -2.5880],\n","        [-2.8413,  4.4854, -1.8046],\n","        [ 2.6180, -0.4306, -2.6001]]) tensor([1, 1, 2, 1, 1, 0, 2, 1, 1, 0, 1, 1, 2, 0, 1, 0]) 0.025859475135803223\n","epoch: 3, loss: 0.15243053428828715, acc: 0.9525\n","nan: False same_parameter: False\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 0:  tensor([[-2.0593, -3.4163,  6.3439],\n","        [-2.7703,  4.5545, -1.9420],\n","        [ 1.9836,  1.0133, -3.5714],\n","        [ 1.6041,  0.9445, -3.0495],\n","        [-2.7594, -2.7847,  6.5958],\n","        [ 3.1342, -0.1313, -3.5389],\n","        [-3.4370,  4.1941, -0.8929],\n","        [-1.8789, -1.3098,  3.5672],\n","        [-2.6853, -2.6942,  6.3444],\n","        [-3.3208,  3.3128, -0.1231],\n","        [-3.6694,  3.6126, -0.0629],\n","        [ 2.0763,  0.5920, -3.1914],\n","        [ 1.9404,  0.7831, -3.2491],\n","        [-3.4529, -1.4238,  5.6625],\n","        [-2.8745, -2.7003,  6.6654],\n","        [ 1.9817,  0.4295, -2.8924]]) tensor([2, 1, 0, 1, 2, 0, 1, 2, 2, 1, 1, 0, 0, 2, 2, 0]) 0.13818670809268951\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 1:  tensor([[-3.2788, -1.8517,  6.0344],\n","        [ 2.0540,  0.5756, -3.1427],\n","        [-2.9746,  4.5950, -1.7590],\n","        [ 3.4263, -0.3791, -3.5802],\n","        [-2.4319,  4.5727, -2.3312],\n","        [ 1.8642,  0.4576, -2.7746],\n","        [ 3.3743, -0.3242, -3.5900],\n","        [-3.4554, -2.0688,  6.6694],\n","        [-4.0148, -1.2683,  6.2341],\n","        [ 2.0179,  0.4538, -2.9742],\n","        [-2.6645,  4.5941, -2.0932],\n","        [-2.5152, -1.6913,  4.8099],\n","        [-3.3190,  4.0032, -0.8286],\n","        [-2.5995,  3.0643, -0.6588],\n","        [ 2.3655,  0.5139, -3.4296],\n","        [ 3.2383, -0.6550, -3.0456]]) tensor([2, 0, 1, 0, 1, 0, 0, 2, 2, 1, 1, 2, 1, 1, 0, 0]) 0.15378354489803314\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 2:  tensor([[ 2.7291,  0.4039, -3.7272],\n","        [ 1.6783,  0.9194, -3.1146],\n","        [-3.5237,  0.5263,  3.2443],\n","        [ 1.9774,  0.7725, -3.2960],\n","        [ 1.8117,  0.6293, -2.9290],\n","        [-3.3761, -2.1650,  6.6948],\n","        [-3.4953,  3.8130, -0.4526],\n","        [-3.7208, -1.3313,  5.9103],\n","        [-3.2616, -1.8426,  6.0005],\n","        [-1.2171, -3.0582,  4.8083],\n","        [ 2.6011,  0.7647, -4.0064],\n","        [-2.6221, -2.4151,  5.8773],\n","        [-4.0557, -0.2507,  4.8278],\n","        [ 3.2374, -0.0490, -3.7586],\n","        [-2.8632,  4.6043, -1.8881],\n","        [ 2.8002,  0.6740, -4.1330]]) tensor([0, 1, 2, 0, 0, 2, 1, 2, 2, 2, 0, 2, 2, 0, 1, 0]) 0.13601887226104736\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 3:  tensor([[ 2.9068, -0.0519, -3.3710],\n","        [-3.5965, -1.8277,  6.5059],\n","        [-1.3600, -2.3340,  4.1583],\n","        [ 1.9787,  0.4808, -2.9467],\n","        [ 1.6766,  0.9020, -3.0901],\n","        [-3.0495, -2.3422,  6.4196],\n","        [-3.0150,  4.2995, -1.4470],\n","        [ 2.0397,  0.2847, -2.7911],\n","        [ 2.2134,  1.3972, -4.3153],\n","        [-3.0358,  4.4696, -1.5852],\n","        [-0.7793, -3.0111,  4.2110],\n","        [-2.1473,  4.1447, -2.2554],\n","        [-3.5471, -1.6086,  6.0665],\n","        [-3.0818,  4.3442, -1.4127],\n","        [ 2.5300,  0.7362, -3.8912],\n","        [-3.4935,  4.2027, -0.8411]]) tensor([0, 2, 2, 1, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 0, 1]) 0.1791524440050125\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 4:  tensor([[-2.7678,  4.5650, -1.9586],\n","        [-2.8930,  4.6299, -1.8800],\n","        [ 2.1934, -0.0174, -2.6007],\n","        [-3.2829, -2.2271,  6.6317],\n","        [ 2.6595,  0.0204, -3.1886],\n","        [-2.8658,  4.5702, -1.8581],\n","        [ 2.1633,  0.9535, -3.7282],\n","        [ 2.2232,  1.2051, -4.0981],\n","        [ 1.8460,  0.6723, -3.0267],\n","        [-3.7195, -1.7052,  6.5040],\n","        [-3.4430,  4.2446, -0.9343],\n","        [-3.6299, -1.8226,  6.5536],\n","        [-2.8709, -2.6838,  6.6422],\n","        [ 1.9446,  0.5762, -3.0209],\n","        [ 3.1807, -0.1106, -3.6211],\n","        [-2.7300,  4.6363, -2.0629]]) tensor([1, 1, 0, 2, 0, 1, 0, 0, 0, 2, 1, 2, 2, 1, 0, 1]) 0.16779451072216034\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 5:  tensor([[ 2.1146,  1.0661, -3.7886],\n","        [ 2.0003,  0.8999, -3.4601],\n","        [-3.1934, -2.0499,  6.2118],\n","        [-1.4881, -3.5179,  5.6711],\n","        [-2.8326,  4.6589, -1.9713],\n","        [-2.6495,  4.6830, -2.1934],\n","        [-3.2887,  4.4297, -1.2753],\n","        [ 2.1208,  1.4920, -4.3265],\n","        [ 3.0106,  0.2873, -3.9172],\n","        [ 3.3302,  0.1402, -4.1121],\n","        [-0.9284, -3.7197,  5.1615],\n","        [-2.6266, -0.9792,  4.0704],\n","        [ 1.1147,  1.2019, -2.8025],\n","        [-2.4917,  2.5919, -0.2695],\n","        [-2.9634,  4.5991, -1.7770],\n","        [-3.2902,  4.4269, -1.2712]]) tensor([0, 0, 2, 2, 1, 1, 1, 0, 0, 0, 2, 2, 1, 1, 1, 1]) 0.11704397946596146\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 6:  tensor([[-3.6410, -1.6661,  6.3045],\n","        [ 1.0937,  1.9850, -3.6871],\n","        [-2.2330,  4.6441, -2.6146],\n","        [ 3.3423,  0.0499, -4.0089],\n","        [ 3.4394, -0.2519, -3.7551],\n","        [-4.0828, -1.0279,  5.9469],\n","        [ 1.6485,  1.5207, -3.7865],\n","        [ 1.8023,  1.0441, -3.4170],\n","        [-2.2097, -3.0184,  6.0795],\n","        [ 1.5077,  1.1582, -3.2011],\n","        [ 1.9593,  0.8771, -3.3930],\n","        [ 1.5262,  0.9719, -3.0045],\n","        [ 2.8141,  0.6755, -4.1614],\n","        [ 1.7180,  0.9865, -3.2453],\n","        [ 1.2163,  1.3689, -3.1115],\n","        [ 1.6139,  1.0189, -3.1599]]) tensor([2, 0, 1, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]) 0.3345463275909424\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 7:  tensor([[ 2.2780,  0.8266, -3.7050],\n","        [-2.9699,  4.4770, -1.6600],\n","        [ 1.5827,  1.2872, -3.4364],\n","        [-2.8249,  4.6246, -1.9478],\n","        [ 1.5074,  0.5787, -2.5314],\n","        [-2.2684,  4.6244, -2.5554],\n","        [-3.0058, -2.5365,  6.6424],\n","        [ 1.4077,  2.1830, -4.2888],\n","        [ 3.5639, -0.1693, -4.0114],\n","        [-2.0375, -0.6612,  2.9866],\n","        [-0.3452,  3.4998, -3.6897],\n","        [-2.7548,  4.6153, -2.0193],\n","        [ 1.9757,  1.1504, -3.7476],\n","        [-3.5419, -1.8217,  6.3924],\n","        [-3.5900,  1.6477,  2.0081],\n","        [ 2.6798,  0.5219, -3.7948]]) tensor([0, 1, 1, 1, 0, 1, 2, 1, 0, 2, 1, 1, 0, 2, 2, 0]) 0.18050020933151245\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 8:  tensor([[-4.1925,  0.1390,  4.4780],\n","        [ 1.4443,  0.8021, -2.7015],\n","        [ 3.1067,  0.0667, -3.7567],\n","        [-4.5723,  0.3547,  4.6028],\n","        [-3.5844, -1.8894,  6.5803],\n","        [ 2.3380,  0.8733, -3.8368],\n","        [-2.2885,  2.6121, -0.5168],\n","        [ 3.0607,  0.2468, -3.9205],\n","        [-2.5449,  4.6980, -2.3160],\n","        [-3.1145,  3.5067, -0.5417],\n","        [ 3.4538, -0.1946, -3.8502],\n","        [ 1.8610,  0.7362, -3.1125],\n","        [-2.2935,  4.6198, -2.5219],\n","        [-2.9828,  0.5974,  2.5474],\n","        [ 1.6342,  1.6184, -3.8942],\n","        [ 3.1479,  0.2867, -4.0736]]) tensor([2, 0, 0, 2, 2, 0, 1, 0, 1, 1, 0, 0, 1, 2, 1, 0]) 0.12861262261867523\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 9:  tensor([[-0.7336, -4.0417,  5.2226],\n","        [ 2.4019,  0.1268, -3.0172],\n","        [-2.2862,  4.6369, -2.5447],\n","        [-3.6288, -1.3797,  5.8378],\n","        [-0.9688, -3.4898,  4.9615],\n","        [-2.3892,  4.6694, -2.4573],\n","        [ 2.1816,  1.1058, -3.9236],\n","        [-1.4625, -3.7321,  5.8569],\n","        [-2.9938,  4.4753, -1.6306],\n","        [-3.1001, -0.8523,  4.4607],\n","        [-2.9281,  3.6259, -0.8711],\n","        [-3.9571, -1.1829,  6.0053],\n","        [ 2.4238,  1.1046, -4.2265],\n","        [-3.1565, -2.2651,  6.4589],\n","        [-3.5257, -1.2560,  5.5303],\n","        [-3.3138, -2.2139,  6.6484]]) tensor([2, 0, 1, 2, 2, 1, 0, 2, 1, 2, 1, 2, 0, 2, 2, 2]) 0.041786033660173416\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 10:  tensor([[-3.2179, -2.3308,  6.6655],\n","        [-3.6177, -1.4944,  5.9866],\n","        [ 2.4991,  0.9515, -4.1118],\n","        [-2.9093,  4.5220, -1.7635],\n","        [-1.0883, -3.8983,  5.5291],\n","        [-1.4850,  4.2671, -3.1156],\n","        [-3.2379,  4.1715, -1.0797],\n","        [ 2.5825,  0.6070, -3.7909],\n","        [-3.4225, -2.0541,  6.5663],\n","        [-3.8198,  0.4696,  3.6527],\n","        [-3.3989, -1.8983,  6.2710],\n","        [-3.0815, -2.3785,  6.5101],\n","        [ 2.0988,  0.9363, -3.6228],\n","        [ 3.4801, -0.3056, -3.7399],\n","        [-3.2965, -2.1927,  6.5733],\n","        [ 2.7643,  0.9111, -4.3749]]) tensor([2, 2, 0, 1, 2, 1, 1, 0, 2, 2, 2, 2, 0, 0, 2, 0]) 0.051616545766592026\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 11:  tensor([[-2.0442,  4.6223, -2.7996],\n","        [-3.8834, -1.0187,  5.6565],\n","        [-3.7157, -1.6938,  6.4545],\n","        [ 0.4365,  2.9785, -4.0387],\n","        [-4.2823, -0.7409,  5.7750],\n","        [-3.5318, -0.8025,  4.9186],\n","        [-2.5082,  4.6778, -2.3348],\n","        [-2.5367,  4.6457, -2.2754],\n","        [-3.6444, -1.8514,  6.6043],\n","        [ 2.3436,  0.6009, -3.5080],\n","        [-3.2104,  3.7279, -0.6761],\n","        [-4.4682, -0.2479,  5.2966],\n","        [ 2.7038,  0.0551, -3.2750],\n","        [-3.5563, -1.0830,  5.3276],\n","        [-3.0203, -2.4902,  6.5646],\n","        [ 3.2569, -0.2938, -3.4961]]) tensor([1, 2, 2, 1, 2, 2, 1, 1, 2, 0, 1, 2, 0, 2, 2, 0]) 0.023231791332364082\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 12:  tensor([[-3.1533, -2.3720,  6.6080],\n","        [-3.9020, -0.7137,  5.2517],\n","        [ 2.5509,  0.5279, -3.6560],\n","        [ 1.7041,  0.9923, -3.2206],\n","        [ 2.4332,  0.5276, -3.5231],\n","        [ 3.1315, -0.0339, -3.6595],\n","        [-3.0745,  4.2569, -1.3381],\n","        [-3.6353, -1.8921,  6.6540],\n","        [-2.8175,  4.5509, -1.8878],\n","        [ 2.3286,  0.5883, -3.4750],\n","        [ 2.3988,  0.3354, -3.2571],\n","        [-4.2260, -0.6459,  5.5715],\n","        [-2.7396,  4.5655, -1.9872],\n","        [ 2.9486,  0.7100, -4.3439],\n","        [-2.3330,  4.5204, -2.3872],\n","        [-3.8672, -1.3888,  6.1892]]) tensor([2, 2, 0, 0, 0, 0, 1, 2, 1, 1, 0, 2, 1, 0, 1, 2]) 0.17868611216545105\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 13:  tensor([[-3.4268,  4.1543, -0.8591],\n","        [ 2.7364,  0.3596, -3.6742],\n","        [-2.5211,  4.6243, -2.2715],\n","        [-3.4297,  3.8823, -0.5853],\n","        [-0.1425, -2.1251,  2.4542],\n","        [ 2.0869,  1.1251, -3.8199],\n","        [ 2.0624, -0.4566, -1.9524],\n","        [-3.6667, -1.8300,  6.5954],\n","        [-3.8067, -0.9675,  5.4929],\n","        [-2.7759,  4.6273, -1.9983],\n","        [-2.7193,  4.5157, -1.9628],\n","        [ 2.1491,  0.4041, -3.0483],\n","        [-2.6191,  3.2042, -0.7791],\n","        [-3.6779,  4.0779, -0.5176],\n","        [-3.4371, -2.1166,  6.6769],\n","        [-2.6777,  3.6372, -1.1637]]) tensor([1, 0, 1, 1, 2, 0, 0, 2, 2, 1, 1, 0, 1, 1, 2, 1]) 0.05163031443953514\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 14:  tensor([[-1.2352, -2.0485,  3.6492],\n","        [ 3.4454, -0.5175, -3.4479],\n","        [ 3.6286, -0.1331, -4.1046],\n","        [-3.5854,  3.4434,  0.0342],\n","        [ 3.5706,  0.3650, -4.6682],\n","        [ 2.7542,  0.2152, -3.5173],\n","        [ 2.9611,  0.0559, -3.5715],\n","        [ 2.7952,  0.8036, -4.2771],\n","        [-4.6232,  0.5624,  4.3924],\n","        [-3.8315, -1.2459,  5.9140],\n","        [-1.8348, -3.4479,  6.0298],\n","        [-3.3161, -1.3289,  5.3434],\n","        [-1.5838, -3.5368,  5.7891],\n","        [-3.7990, -1.6643,  6.5306],\n","        [ 2.0604,  1.2041, -3.9067],\n","        [-3.0728, -2.4985,  6.6538]]) tensor([2, 0, 0, 1, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2]) 0.10163386166095734\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 15:  tensor([[ 2.4138,  0.1526, -3.0618],\n","        [-2.8552,  3.7135, -1.0402],\n","        [-2.5732,  4.6450, -2.2339],\n","        [-2.6927,  3.2582, -0.7523],\n","        [-2.4156,  4.5608, -2.3315],\n","        [-2.8032, -2.5923,  6.3490],\n","        [ 2.8517,  0.5047, -3.9761],\n","        [-2.8207,  4.5317, -1.8681],\n","        [-2.1441,  4.5548, -2.6233],\n","        [-2.3302,  4.6392, -2.4958],\n","        [-3.8053, -1.4595,  6.2036],\n","        [-2.2783,  4.6703, -2.5795],\n","        [-2.6440,  4.6058, -2.1212],\n","        [-2.0223,  4.6753, -2.8639],\n","        [-2.4863,  4.6488, -2.3336],\n","        [-2.4556, -2.8536,  6.1846]]) tensor([0, 1, 1, 1, 1, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 2]) 0.01522460114210844\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 16:  tensor([[ 1.9535,  1.6903, -4.3566],\n","        [-1.8750,  4.6117, -2.9726],\n","        [-2.2953,  4.6326, -2.5262],\n","        [-3.7670, -1.7127,  6.5537],\n","        [-3.2442, -2.3087,  6.6394],\n","        [ 2.6595,  0.0162, -3.1721],\n","        [-3.7745,  0.5732,  3.4631],\n","        [-2.3243,  4.6623, -2.5193],\n","        [ 2.9303,  0.1601, -3.6568],\n","        [-3.8541, -1.5549,  6.4287],\n","        [-1.5808,  4.3750, -3.0988],\n","        [ 2.3094,  0.7482, -3.6435],\n","        [-1.9880, -3.3220,  6.0898],\n","        [-4.3969, -0.5664,  5.6582],\n","        [-3.0149, -2.3312,  6.2930],\n","        [-2.7368,  4.5908, -2.0093]]) tensor([1, 1, 1, 2, 2, 0, 2, 1, 0, 2, 1, 0, 2, 2, 2, 1]) 0.07684525102376938\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 17:  tensor([[ 3.8507, -0.5330, -3.8751],\n","        [-3.0757, -2.0541,  6.0051],\n","        [-2.9921,  3.1911, -0.3521],\n","        [ 2.8515,  0.3845, -3.8353],\n","        [-4.2175,  0.6147,  3.9018],\n","        [-2.9717,  4.2634, -1.4564],\n","        [-1.4249, -2.3351,  4.2106],\n","        [ 3.0779, -0.5759, -2.9662],\n","        [-2.1703,  4.6497, -2.6807],\n","        [ 2.7185,  0.1829, -3.4405],\n","        [-3.0248,  3.2367, -0.3604],\n","        [-0.9124, -3.6408,  5.0308],\n","        [ 2.9740, -0.3368, -3.1185],\n","        [ 2.6729,  0.2000, -3.4114],\n","        [ 2.5916,  0.4428, -3.6017],\n","        [-3.2038, -2.2593,  6.4911]]) tensor([0, 2, 1, 0, 2, 1, 2, 1, 1, 0, 1, 2, 0, 0, 0, 2]) 0.2624426484107971\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 18:  tensor([[-4.0957, -0.3841,  5.0461],\n","        [-2.1724,  4.5346, -2.5712],\n","        [-2.2212,  4.6525, -2.6244],\n","        [-3.8427, -1.5932,  6.4644],\n","        [-2.6239,  4.5813, -2.1250],\n","        [ 3.3202, -0.7107, -3.0722],\n","        [-3.4506, -1.0371,  5.1208],\n","        [ 2.9319,  0.0434, -3.5264],\n","        [ 3.3612,  0.0136, -3.9734],\n","        [-0.7262, -4.2701,  5.3888],\n","        [-4.0126, -1.1756,  6.0631],\n","        [-2.9605, -2.5525,  6.5327],\n","        [-0.6482, -3.9719,  5.0289],\n","        [ 2.7759,  0.1302, -3.4387],\n","        [-3.6882, -0.7035,  4.9734],\n","        [ 3.4439, -0.1774, -3.8358]]) tensor([2, 1, 1, 2, 1, 0, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0]) 0.0144247030839324\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 19:  tensor([[-3.1758,  3.1751, -0.1314],\n","        [ 3.0680,  0.0162, -3.6447],\n","        [ 3.6657, -0.7241, -3.4568],\n","        [-3.7075, -1.7655,  6.5335],\n","        [ 2.8303,  0.3404, -3.7563],\n","        [ 1.8276,  1.1380, -3.5430],\n","        [-2.9260,  0.6123,  2.4575],\n","        [ 3.2421, -0.9789, -2.6746],\n","        [-3.4401, -2.1426,  6.7009],\n","        [-4.6594,  0.1987,  4.9053],\n","        [-2.3333, -2.5045,  5.5821],\n","        [ 1.0696,  2.5452, -4.2981],\n","        [-3.6142, -1.9554,  6.6966],\n","        [-2.3442,  4.6865, -2.5196],\n","        [-3.4923, -2.0033,  6.5571],\n","        [-1.4169,  4.3930, -3.2992]]) tensor([1, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2, 1, 2, 1, 2, 1]) 0.061199840158224106\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 20:  tensor([[ 2.2701,  0.6253, -3.4549],\n","        [-3.2861, -1.9762,  6.1853],\n","        [ 2.8061, -0.0386, -3.2777],\n","        [-3.7024, -1.6991,  6.4163],\n","        [ 3.5795, -0.3493, -3.7866],\n","        [ 0.5585, -1.8922,  1.3828],\n","        [-2.8611,  4.4484, -1.7495],\n","        [-3.9345, -1.0213,  5.7248],\n","        [-3.2756, -1.3445,  5.2996],\n","        [-2.0331, -3.3803,  6.2140],\n","        [ 3.0294, -0.2851, -3.2490],\n","        [ 2.4483,  0.5854, -3.6119],\n","        [-3.7993, -1.3932,  6.0719],\n","        [-2.3593,  4.4929, -2.3366],\n","        [ 2.6405,  0.3340, -3.5379],\n","        [ 2.4697,  0.7214, -3.7952]]) tensor([0, 2, 0, 2, 0, 2, 1, 2, 2, 2, 0, 1, 2, 1, 0, 0]) 0.1851576715707779\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 21:  tensor([[-2.6164e+00,  4.5755e+00, -2.1310e+00],\n","        [-1.2629e+00, -3.4151e+00,  5.2310e+00],\n","        [-2.1634e+00,  4.6846e+00, -2.7181e+00],\n","        [-3.2798e+00,  3.8856e+00, -7.5287e-01],\n","        [ 2.9236e+00, -2.4019e-01, -3.1870e+00],\n","        [-1.8486e+00,  2.3471e+00, -7.1148e-01],\n","        [ 2.5180e+00,  5.8831e-01, -3.6921e+00],\n","        [ 2.9907e+00, -7.1710e-02, -3.4562e+00],\n","        [ 2.7945e+00, -2.5515e-03, -3.3029e+00],\n","        [ 2.8051e+00, -7.9349e-02, -3.2282e+00],\n","        [ 2.7816e+00, -4.3800e-02, -3.2492e+00],\n","        [-1.8263e+00, -3.6254e+00,  6.1971e+00],\n","        [-2.6083e+00, -1.3624e+00,  4.4870e+00],\n","        [-2.1290e+00,  4.6537e+00, -2.7303e+00],\n","        [ 2.8212e+00,  1.4731e-01, -3.5151e+00],\n","        [-2.5447e+00, -3.0245e+00,  6.5250e+00]]) tensor([1, 2, 1, 1, 0, 1, 0, 0, 0, 0, 0, 2, 2, 1, 0, 2]) 0.03476091846823692\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 22:  tensor([[ 3.4604, -0.0351, -4.0293],\n","        [-2.2532,  4.6232, -2.5664],\n","        [ 2.4945,  0.1922, -3.1927],\n","        [-2.9921,  2.9352, -0.0802],\n","        [-3.5875, -1.8619,  6.4798],\n","        [-2.6793,  4.5458, -2.0309],\n","        [-2.3200,  4.6734, -2.5379],\n","        [-3.2768,  3.5066, -0.3708],\n","        [-1.7416,  4.3932, -2.9366],\n","        [ 4.1006, -0.8558, -3.7706],\n","        [-3.0946,  4.1273, -1.1922],\n","        [ 2.7708,  0.0772, -3.3730],\n","        [-3.2116, -2.3541,  6.6355],\n","        [-2.5663,  1.7589,  0.7367],\n","        [-4.2088, -0.6587,  5.5537],\n","        [-2.9073, -0.9572,  4.3464]]) tensor([0, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 0, 2, 2, 2, 2]) 0.10231604427099228\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 23:  tensor([[-1.8870,  4.5274, -2.8893],\n","        [-2.9878, -2.5834,  6.6071],\n","        [-2.4020,  4.4824, -2.2811],\n","        [-2.4758, -2.1033,  5.2514],\n","        [-2.9255,  3.6501, -0.9043],\n","        [-2.2042,  4.6781, -2.6697],\n","        [-1.7495,  4.6439, -3.1400],\n","        [ 2.8464, -0.0521, -3.3049],\n","        [-2.7016, -1.2976,  4.5484],\n","        [-4.0376,  1.2152,  2.9854],\n","        [-3.1964,  3.2132, -0.1482],\n","        [ 3.0017,  0.1004, -3.6783],\n","        [-3.1669,  4.2626, -1.2454],\n","        [-3.1794,  4.2376, -1.2084],\n","        [-3.4998, -2.1059,  6.7356],\n","        [ 3.4696, -0.2439, -3.7848]]) tensor([1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 0, 1, 1, 2, 0]) 0.022714219987392426\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 24:  tensor([[-3.5373, -2.0814,  6.7572],\n","        [-2.6298,  4.5891, -2.1268],\n","        [-3.1916,  3.0900, -0.0267],\n","        [ 2.8284,  0.0232, -3.3860],\n","        [ 2.9720,  0.2090, -3.7599],\n","        [-1.9461,  4.5635, -2.8551],\n","        [-3.6232, -1.9952,  6.7674],\n","        [ 2.6590,  0.1821, -3.3684],\n","        [-3.1447,  4.2015, -1.2104],\n","        [-3.1901, -2.1172,  6.2378],\n","        [-2.4113, -1.4046,  4.3011],\n","        [-1.8931,  4.5761, -2.9266],\n","        [ 3.1158, -0.8747, -2.6608],\n","        [ 0.6609,  2.6078, -3.8870],\n","        [-3.3634, -2.0665,  6.4332],\n","        [ 2.4367,  0.4076, -3.3739]]) tensor([2, 1, 1, 0, 0, 1, 2, 0, 1, 2, 2, 1, 1, 1, 2, 1]) 0.41059303283691406\n","epoch: 4, loss: 0.1267961123585701, acc: 0.9575\n","nan: False same_parameter: False\n","validating model.... at epoch_4\n","loss_now: 0.045514605939388275\n","batch_acc: 1.0\n","loss_now: 0.0369613952934742\n","batch_acc: 1.0\n","loss_now: 0.3264710307121277\n","batch_acc: 0.9\n","loss_now: 0.35417747497558594\n","batch_acc: 0.9\n","loss_now: 0.0979447215795517\n","batch_acc: 0.95\n","loss_now: 0.15423424541950226\n","batch_acc: 0.9\n","loss_now: 0.009444416500627995\n","batch_acc: 1.0\n","loss_now: 0.5544434785842896\n","batch_acc: 0.8\n","loss_now: 0.02240043506026268\n","batch_acc: 1.0\n","loss_now: 0.31826359033584595\n","batch_acc: 0.9\n","loss_now: 0.026275599375367165\n","batch_acc: 1.0\n","loss_now: 0.2888128459453583\n","batch_acc: 0.9\n","loss_now: 0.24380286037921906\n","batch_acc: 0.9\n","loss_now: 0.6798216104507446\n","batch_acc: 0.85\n","loss_now: 0.028591543436050415\n","batch_acc: 1.0\n","loss_now: 0.12255670130252838\n","batch_acc: 0.95\n","loss_now: 0.22447414696216583\n","batch_acc: 0.95\n","loss_now: 0.26212966442108154\n","batch_acc: 0.9\n","loss_now: 0.20660734176635742\n","batch_acc: 0.95\n","loss_now: 0.058831073343753815\n","batch_acc: 1.0\n","loss_now: 0.027262995019555092\n","batch_acc: 1.0\n","loss_now: 0.0189005546271801\n","batch_acc: 1.0\n","loss_now: 0.471060186624527\n","batch_acc: 0.8\n","loss_now: 0.2782233953475952\n","batch_acc: 0.9\n","loss_now: 0.31717926263809204\n","batch_acc: 0.9\n","loss_now: 0.04698600620031357\n","batch_acc: 1.0\n","loss_now: 0.09442940354347229\n","batch_acc: 0.95\n","loss_now: 0.02113526687026024\n","batch_acc: 1.0\n","loss_now: 0.34903663396835327\n","batch_acc: 0.9\n","loss_now: 0.2569954991340637\n","batch_acc: 0.9\n","loss_now: 0.017170162871479988\n","batch_acc: 1.0\n","loss_now: 0.07648857682943344\n","batch_acc: 0.95\n","loss_now: 0.24247583746910095\n","batch_acc: 0.9\n","loss_now: 0.31787317991256714\n","batch_acc: 0.95\n","loss_now: 0.6158072352409363\n","batch_acc: 0.9\n","loss_now: 0.11013226211071014\n","batch_acc: 0.95\n","loss_now: 0.09250631183385849\n","batch_acc: 0.95\n","loss_now: 0.022735580801963806\n","batch_acc: 1.0\n","loss_now: 0.02421913854777813\n","batch_acc: 1.0\n","loss_now: 0.1359710693359375\n","batch_acc: 0.95\n","loss_now: 0.01904970034956932\n","batch_acc: 1.0\n","loss_now: 0.03841957077383995\n","batch_acc: 1.0\n","loss_now: 0.2998163104057312\n","batch_acc: 0.85\n","loss_now: 0.10881836712360382\n","batch_acc: 0.9\n","loss_now: 0.18897755444049835\n","batch_acc: 0.95\n","loss_now: 0.020429516211152077\n","batch_acc: 1.0\n","loss_now: 0.3183172345161438\n","batch_acc: 0.95\n","loss_now: 0.023841697722673416\n","batch_acc: 1.0\n","loss_now: 0.04369478300213814\n","batch_acc: 1.0\n","loss_now: 0.3515598177909851\n","batch_acc: 0.85\n","loss_now: 0.2634117305278778\n","batch_acc: 0.9\n","loss_now: 0.06525692343711853\n","batch_acc: 1.0\n","loss_now: 0.20714311301708221\n","batch_acc: 0.95\n","loss_now: 0.6610192060470581\n","batch_acc: 0.75\n","loss_now: 0.3236413598060608\n","batch_acc: 0.95\n","loss_now: 0.33877670764923096\n","batch_acc: 0.9\n","loss_now: 0.19927570223808289\n","batch_acc: 0.95\n","loss_now: 0.24793903529644012\n","batch_acc: 0.9\n","loss_now: 0.16553300619125366\n","batch_acc: 0.95\n","loss_now: 0.4833564758300781\n","batch_acc: 0.9\n","loss_now: 0.10096486657857895\n","batch_acc: 0.95\n","loss_now: 0.2018592357635498\n","batch_acc: 0.95\n","loss_now: 0.04097868874669075\n","batch_acc: 1.0\n","loss_now: 0.3054654598236084\n","batch_acc: 0.95\n","loss_now: 0.01946144551038742\n","batch_acc: 1.0\n","loss_now: 0.05794863775372505\n","batch_acc: 1.0\n","loss_now: 0.1403162032365799\n","batch_acc: 0.95\n","loss_now: 0.020361991599202156\n","batch_acc: 1.0\n","loss_now: 0.031161773949861526\n","batch_acc: 1.0\n","loss_now: 0.2063378095626831\n","batch_acc: 0.9\n","loss_now: 0.3455938696861267\n","batch_acc: 0.9\n","loss_now: 0.013251188211143017\n","batch_acc: 1.0\n","loss_now: 0.19556893408298492\n","batch_acc: 0.9\n","loss_now: 0.06373431533575058\n","batch_acc: 1.0\n","loss_now: 0.5274555087089539\n","batch_acc: 0.8\n","loss_now: 0.8373955488204956\n","batch_acc: 0.8\n","loss_now: 0.09077569842338562\n","batch_acc: 0.95\n","loss_now: 0.030073881149291992\n","batch_acc: 1.0\n","loss_now: 0.018441839143633842\n","batch_acc: 1.0\n","loss_now: 0.04885896295309067\n","batch_acc: 1.0\n","loss_now: 0.4723842740058899\n","batch_acc: 0.85\n","loss_now: 0.05793570727109909\n","batch_acc: 1.0\n","loss_now: 0.18420659005641937\n","batch_acc: 0.95\n","loss_now: 0.14590246975421906\n","batch_acc: 0.9\n","loss_now: 0.25393521785736084\n","batch_acc: 0.9\n","loss_now: 0.015732591971755028\n","batch_acc: 1.0\n","loss_now: 0.1474991887807846\n","batch_acc: 0.9\n","loss_now: 0.03856427222490311\n","batch_acc: 1.0\n","loss_now: 0.3617151081562042\n","batch_acc: 0.85\n","loss_now: 0.235500305891037\n","batch_acc: 0.9\n","loss_now: 0.5494776964187622\n","batch_acc: 0.85\n","loss_now: 0.01905359886586666\n","batch_acc: 1.0\n","loss_now: 0.051558613777160645\n","batch_acc: 1.0\n","loss_now: 0.18357008695602417\n","batch_acc: 0.9\n","loss_now: 0.6603092551231384\n","batch_acc: 0.85\n","loss_now: 0.4160824418067932\n","batch_acc: 0.9\n","loss_now: 0.4537225365638733\n","batch_acc: 0.9\n","loss_now: 0.22101552784442902\n","batch_acc: 0.9\n","loss_now: 0.0179293192923069\n","batch_acc: 1.0\n","loss_now: 0.2076152265071869\n","batch_acc: 0.95\n","tot_loss: 0.19956341041252018, accuracy: 0.9385\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 0:  tensor([[ 1.8039,  0.3292, -2.5697],\n","        [-3.6790, -1.9365,  6.7652],\n","        [-3.2186,  3.5565, -0.4943],\n","        [-2.5485,  4.5677, -2.1900],\n","        [ 3.9700, -1.0947, -3.3424],\n","        [ 3.5242, -0.1355, -3.9816],\n","        [-3.0791,  2.7093,  0.2540],\n","        [-3.4333, -1.5659,  5.8190],\n","        [-2.8373,  4.4961, -1.8186],\n","        [-3.3392,  3.3305, -0.1150],\n","        [-4.2126, -0.1647,  4.8942],\n","        [-3.8915, -1.6766,  6.6858],\n","        [ 3.8801, -1.5505, -2.7383],\n","        [-2.4959,  4.6531, -2.3261],\n","        [ 3.1987, -0.1424, -3.5996],\n","        [-2.5382,  4.6159, -2.2489]]) tensor([0, 2, 1, 1, 0, 0, 1, 2, 1, 1, 2, 2, 0, 1, 0, 1]) 0.027657529339194298\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 1:  tensor([[-3.6600e+00, -1.7815e+00,  6.4657e+00],\n","        [ 2.7169e+00, -5.7057e-01, -2.5598e+00],\n","        [-3.0509e+00, -1.9381e+00,  5.7914e+00],\n","        [ 3.9205e+00, -1.1750e+00, -3.2011e+00],\n","        [-3.9565e+00, -2.7508e-03,  4.3847e+00],\n","        [ 2.7964e+00, -3.6381e-01, -2.8861e+00],\n","        [-1.2880e+00, -3.3095e+00,  5.1490e+00],\n","        [-1.8441e+00,  4.4563e+00, -2.8761e+00],\n","        [-2.9327e+00, -2.5308e+00,  6.4479e+00],\n","        [-2.7069e+00,  4.5433e+00, -2.0033e+00],\n","        [-3.7374e+00, -1.8625e+00,  6.7392e+00],\n","        [ 2.5385e+00, -1.5974e-01, -2.8252e+00],\n","        [ 2.7828e+00, -8.6900e-01, -2.2856e+00],\n","        [-3.0379e+00,  4.3527e+00, -1.4688e+00],\n","        [-2.9582e+00, -2.0901e+00,  5.8742e+00],\n","        [ 2.6444e+00,  2.6351e-01, -3.4429e+00]]) tensor([2, 0, 2, 0, 2, 0, 2, 1, 2, 1, 2, 0, 0, 1, 2, 0]) 0.019342951476573944\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 2:  tensor([[-3.5185, -2.1137,  6.7785],\n","        [ 3.1387, -0.3900, -3.2460],\n","        [-2.1512, -3.2617,  6.2386],\n","        [-2.2286,  4.6092, -2.5805],\n","        [-3.1552, -2.3130,  6.4727],\n","        [-3.6868, -1.9348,  6.7750],\n","        [-3.1799,  3.7466, -0.7185],\n","        [ 2.5596,  0.0770, -3.1446],\n","        [-3.0993,  3.4909, -0.5499],\n","        [-3.8612, -1.5528,  6.4186],\n","        [ 1.9409, -0.0178, -2.3216],\n","        [-3.7194, -1.7386,  6.4926],\n","        [ 2.8063,  0.0544, -3.3809],\n","        [ 2.6772, -0.6597, -2.3919],\n","        [ 2.1929,  0.3035, -2.9866],\n","        [ 2.8604, -0.0622, -3.3202]]) tensor([2, 0, 2, 1, 2, 2, 1, 0, 1, 2, 0, 2, 0, 0, 1, 0]) 0.15542587637901306\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 3:  tensor([[ 2.4862,  0.4150, -3.4568],\n","        [-3.5567, -2.0504,  6.7359],\n","        [-3.4217, -2.2286,  6.7977],\n","        [-2.7784,  3.4966, -0.9017],\n","        [-1.6179,  4.4100, -3.0859],\n","        [-3.1012,  4.3115, -1.3599],\n","        [-2.2039,  4.6256, -2.6241],\n","        [-3.2772,  4.0282, -0.8940],\n","        [-3.6346, -1.7927,  6.4425],\n","        [ 2.8234, -0.7389, -2.4858],\n","        [-2.9017,  2.0890,  0.7504],\n","        [ 3.5858, -0.6115, -3.4899],\n","        [-2.8965,  4.4372, -1.7018],\n","        [ 2.8446,  0.1089, -3.4945],\n","        [-0.6815,  3.3732, -3.1401],\n","        [-2.6161, -2.7081,  6.2152]]) tensor([0, 2, 2, 1, 1, 1, 1, 1, 2, 0, 1, 0, 1, 0, 1, 2]) 0.032841164618730545\n","training shape of data: torch.Size([16, 10, 514]) and lr: 0.00031640625000000006\n","for batch 4:  tensor([[-1.8624,  4.6274, -3.0011],\n","        [-2.2428,  4.6295, -2.5843],\n","        [-3.2650,  4.0608, -0.9415],\n","        [ 3.5752, -0.6226, -3.4655],\n","        [ 2.0900, -1.2246, -1.1075],\n","        [-1.8537, -2.9481,  5.4646],\n","        [-1.0258, -3.5408,  5.0671],\n","        [-2.7718,  4.0260, -1.4476],\n","        [ 2.1406,  0.6201, -3.2777],\n","        [-2.3321,  4.5657, -2.4312],\n","        [-3.6927, -1.9607,  6.8325],\n","        [-2.2203,  4.6526, -2.6276],\n","        [ 2.7343, -0.2084, -2.9942],\n","        [-2.6891,  4.4129, -1.9034],\n","        [ 2.6025, -0.6161, -2.3689],\n","        [-3.8040, -1.4847,  6.2256]]) tensor([1, 1, 1, 0, 0, 2, 2, 1, 0, 1, 2, 1, 0, 1, 0, 2]) 0.02615734376013279\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-94569d1d92da>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mtot_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mloop_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mimageArrarr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimeStampArrarr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcellStateArrarr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredNextarr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgnn_data_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0maug_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_augmented_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimageArrarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimeStampArrarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcellStateArrarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredNextarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mbatch_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maug_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_frame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-f57256ecfcec>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mimageInd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartInd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstartInd\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mNUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mimageArr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetImageFromPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimageInd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0mimageArr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageArr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-f57256ecfcec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mimageInd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartInd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstartInd\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mNUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mimageArr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetImageFromPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimageInd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0mimageArr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageArr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-f57256ecfcec>\u001b[0m in \u001b[0;36mgetImageFromPath\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetImageFromPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model.train()\n","\n","\n","\n","trainLoss=[]\n","trainAcc = []\n","\n","\n","###\n","#k val= 5\n","###\n","\n","\n","# print(\"len is: \",len(gnn_data_loader))\n","\n","__grad_vals_prev=None\n","__grad_vals_now=[]\n","k_fold_val=1\n","\n","for epoch in range(epoch_num):\n","  model.train()\n","  same_parameter_anywhere=False\n","  nan_anywhere=False\n","\n","  batch_number=0\n","  tot_loss=0\n","  tot_acc=0\n","  loop_start=time.time()\n","  for imageArrarr,timeStampArrarr,cellStateArrarr,predNextarr in gnn_data_loader:\n","    aug_data=[get_augmented_data(feature_model,imageArrarr[i],timeStampArrarr[i],cellStateArrarr[i],predNextarr[i]) for i in range(batch_size)]\n","    batch_x=torch.cat([aug_data[i][0].reshape([1,num_frame,-1]) for i in range(batch_size)],dim=0)\n","    print(f\"training shape of data: {batch_x.shape} and lr: {optimizer.param_groups[0]['lr']}\")\n","    batch_y=torch.zeros((batch_size,3)).to(device)\n","    batch_y.requires_grad=False\n","\n","    for i in range(batch_size):\n","      batch_y[i][int(aug_data[i][1])]=1\n","    batch_y=smoothen_labels(batch_y,label_smoothening_eps,CLASS)\n","    # gso=torch.cat([get_gso(aug_data[i][0]).reshape([1,num_frame,num_frame]) for i in range(batch_size)],dim=0).mean(dim=0) ####change since resnet\n","    gso=torch.cat([get_gso(aug_data[i][0]).reshape([1,num_frame,num_frame]) for i in range(batch_size)],dim=0)\n","    batch_y = torch.argmax(batch_y,dim=1)\n","\n","\n","    optimizer.zero_grad()\n","    output_y=model((batch_x,gso))\n","\n","    loss_val=loss_func(output_y,batch_y)\n","    loss_val.backward()\n","    for i in model.parameters():\n","      __grad_vals_now.extend(torch.flatten(i).tolist())\n","\n","    if __grad_vals_prev is not None:\n","      # print(len(__grad_vals_prev),len(__grad_vals_now))\n","      # print(\"Same parameters: \",__grad_vals_prev==__grad_vals_now)\n","      if __grad_vals_now==__grad_vals_prev:\n","        same_parameter_anywhere=True\n","    if torch.isnan(torch.tensor(__grad_vals_now)).any():\n","      nan_anywhere=True\n","\n","    __grad_vals_prev=__grad_vals_now\n","    __grad_vals_now=[]\n","    optimizer.step()\n","\n","\n","\n","    # print(output_y.shape)\n","\n","    with torch.no_grad():\n","      print(f\"for batch {batch_number}: \",output_y.detach().cpu(),batch_y.detach().cpu(),loss_val.detach().cpu().item())\n","      tot_loss+=loss_val.cpu().item()\n","      cnt=0\n","      for i in range(batch_size):\n","        if batch_y[i]==torch.argmax(smax(output_y[i])).item():\n","          cnt+=1\n","      tot_acc+=cnt/batch_size\n","    batch_number+=1\n","    loop_start=time.time()\n","\n","  tot_loss/=batch_number\n","  tot_acc/=batch_number\n","\n","  trainAcc.append(tot_acc)\n","  trainLoss.append(tot_loss)\n","  print(f\"epoch: {epoch}, loss: {tot_loss}, acc: {tot_acc}\")\n","  print(f\"nan: {nan_anywhere} same_parameter: {same_parameter_anywhere}\")\n","  # print(\"printing parameters:\",*model.parameters())\n","  scheduler.step()\n","  if (epoch+1)%5==0:\n","    if tot_loss<loss_now:\n","      loss_now=tot_loss\n","      print(\"saving model.\")\n","      torch.save(model,\"/content/drive/MyDrive/Cell Tracking/graph_original3_centreresnet18.pth\")\n","  if (epoch+1)%5==0:\n","    print(f\"validating model.... at epoch_{epoch}\")\n","    validate_model(model,feature_model,val_gnn_data_loader)"]},{"cell_type":"code","source":["val_batch_size=20\n","num_frame=10\n","smax=nn.Softmax(dim=0)\n","\n","test_model=torch.load(\"/content/drive/My Drive/Cell Tracking/graph_original3_centreresnet18.pth\")\n","\n","val_gnn_dataset=getGNNDataset(index_list=val_files,model=None)\n","val_gnn_dataset.set_len(2000)\n","val_gnn_data_loader=DataLoader(val_gnn_dataset,batch_size=val_batch_size,shuffle=True)\n","\n"],"metadata":{"id":"TV1nO7kQARXQ","executionInfo":{"status":"ok","timestamp":1700597628217,"user_tz":-330,"elapsed":421,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["act_y,pred_y=validate_model(test_model,contrastive_resnet_model,val_gnn_data_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lQYywu4lBLYH","executionInfo":{"status":"ok","timestamp":1700597838979,"user_tz":-330,"elapsed":210307,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}},"outputId":"efc890ca-6270-4e23-83b6-05974582a6d9"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["loss_now: 0.3518330156803131\n","batch_acc: 0.85\n","loss_now: 0.5448037385940552\n","batch_acc: 0.85\n","loss_now: 0.0693308487534523\n","batch_acc: 1.0\n","loss_now: 0.19880017638206482\n","batch_acc: 0.95\n","loss_now: 0.30530065298080444\n","batch_acc: 0.95\n","loss_now: 0.04086509346961975\n","batch_acc: 1.0\n","loss_now: 0.25949007272720337\n","batch_acc: 0.9\n","loss_now: 0.10513180494308472\n","batch_acc: 0.95\n","loss_now: 0.16539520025253296\n","batch_acc: 0.95\n","loss_now: 0.21646468341350555\n","batch_acc: 0.95\n","loss_now: 0.24276086688041687\n","batch_acc: 0.95\n","loss_now: 0.05645940452814102\n","batch_acc: 1.0\n","loss_now: 0.11097218096256256\n","batch_acc: 1.0\n","loss_now: 0.09043120592832565\n","batch_acc: 1.0\n","loss_now: 0.05169146507978439\n","batch_acc: 0.95\n","loss_now: 0.122007355093956\n","batch_acc: 0.95\n","loss_now: 0.14295318722724915\n","batch_acc: 0.95\n","loss_now: 0.09149076044559479\n","batch_acc: 0.95\n","loss_now: 0.4397810101509094\n","batch_acc: 0.9\n","loss_now: 0.8490310907363892\n","batch_acc: 0.85\n","loss_now: 0.1546352654695511\n","batch_acc: 0.95\n","loss_now: 0.7140098810195923\n","batch_acc: 0.85\n","loss_now: 0.09339150041341782\n","batch_acc: 0.95\n","loss_now: 0.07076204568147659\n","batch_acc: 1.0\n","loss_now: 0.10513977706432343\n","batch_acc: 0.95\n","loss_now: 0.056483883410692215\n","batch_acc: 1.0\n","loss_now: 0.49516764283180237\n","batch_acc: 0.8\n","loss_now: 0.8814078569412231\n","batch_acc: 0.7\n","loss_now: 0.06968934834003448\n","batch_acc: 0.95\n","loss_now: 0.24194319546222687\n","batch_acc: 0.85\n","loss_now: 0.26126545667648315\n","batch_acc: 0.9\n","loss_now: 0.11077700555324554\n","batch_acc: 1.0\n","loss_now: 0.09412933140993118\n","batch_acc: 0.95\n","loss_now: 0.34083080291748047\n","batch_acc: 0.9\n","loss_now: 0.6234063506126404\n","batch_acc: 0.75\n","loss_now: 0.062004901468753815\n","batch_acc: 1.0\n","loss_now: 0.43781447410583496\n","batch_acc: 0.95\n","loss_now: 0.14762938022613525\n","batch_acc: 0.95\n","loss_now: 0.27878692746162415\n","batch_acc: 0.95\n","loss_now: 0.14195449650287628\n","batch_acc: 0.95\n","loss_now: 0.05514322593808174\n","batch_acc: 1.0\n","loss_now: 0.2871084213256836\n","batch_acc: 0.9\n","loss_now: 0.17218801379203796\n","batch_acc: 0.95\n","loss_now: 0.15978866815567017\n","batch_acc: 0.95\n","loss_now: 0.2339153289794922\n","batch_acc: 0.95\n","loss_now: 0.16711077094078064\n","batch_acc: 0.95\n","loss_now: 0.17699392139911652\n","batch_acc: 0.95\n","loss_now: 0.07721543312072754\n","batch_acc: 0.95\n","loss_now: 0.07750167697668076\n","batch_acc: 1.0\n","loss_now: 0.06460835039615631\n","batch_acc: 1.0\n","loss_now: 0.14798757433891296\n","batch_acc: 0.95\n","loss_now: 0.1342482566833496\n","batch_acc: 0.95\n","loss_now: 0.18010523915290833\n","batch_acc: 0.9\n","loss_now: 0.08300699293613434\n","batch_acc: 1.0\n","loss_now: 0.13092952966690063\n","batch_acc: 0.95\n","loss_now: 0.16185954213142395\n","batch_acc: 0.95\n","loss_now: 0.6814337968826294\n","batch_acc: 0.85\n","loss_now: 0.015558788552880287\n","batch_acc: 1.0\n","loss_now: 0.37227562069892883\n","batch_acc: 0.9\n","loss_now: 0.07177905738353729\n","batch_acc: 0.95\n","loss_now: 0.10064449161291122\n","batch_acc: 0.95\n","loss_now: 0.6293505430221558\n","batch_acc: 0.9\n","loss_now: 0.16523848474025726\n","batch_acc: 0.95\n","loss_now: 0.44023337960243225\n","batch_acc: 0.85\n","loss_now: 0.17930956184864044\n","batch_acc: 0.9\n","loss_now: 0.029562165960669518\n","batch_acc: 1.0\n","loss_now: 0.2300557792186737\n","batch_acc: 0.9\n","loss_now: 0.05711076781153679\n","batch_acc: 1.0\n","loss_now: 0.16632792353630066\n","batch_acc: 0.95\n","loss_now: 0.031527649611234665\n","batch_acc: 1.0\n","loss_now: 0.2266790121793747\n","batch_acc: 0.9\n","loss_now: 0.060690779238939285\n","batch_acc: 1.0\n","loss_now: 0.21598288416862488\n","batch_acc: 0.85\n","loss_now: 0.039749011397361755\n","batch_acc: 1.0\n","loss_now: 0.3092329800128937\n","batch_acc: 0.95\n","loss_now: 0.039358317852020264\n","batch_acc: 1.0\n","loss_now: 0.4943532347679138\n","batch_acc: 0.95\n","loss_now: 0.13459917902946472\n","batch_acc: 0.95\n","loss_now: 0.23647825419902802\n","batch_acc: 0.9\n","loss_now: 0.1981784552335739\n","batch_acc: 0.95\n","loss_now: 0.03522735834121704\n","batch_acc: 1.0\n","loss_now: 0.5712019205093384\n","batch_acc: 0.9\n","loss_now: 0.07260562479496002\n","batch_acc: 1.0\n","loss_now: 0.2198190987110138\n","batch_acc: 0.9\n","loss_now: 0.4763656258583069\n","batch_acc: 0.95\n","loss_now: 0.05903644114732742\n","batch_acc: 1.0\n","loss_now: 0.0551488921046257\n","batch_acc: 1.0\n","loss_now: 0.01916060969233513\n","batch_acc: 1.0\n","loss_now: 0.03790358826518059\n","batch_acc: 1.0\n","loss_now: 0.9655226469039917\n","batch_acc: 0.85\n","loss_now: 0.027944233268499374\n","batch_acc: 1.0\n","loss_now: 0.5201023817062378\n","batch_acc: 0.8\n","loss_now: 0.3024985194206238\n","batch_acc: 0.95\n","loss_now: 0.31045210361480713\n","batch_acc: 0.95\n","loss_now: 0.15608687698841095\n","batch_acc: 0.95\n","loss_now: 0.1626061499118805\n","batch_acc: 0.95\n","loss_now: 0.21669211983680725\n","batch_acc: 0.95\n","loss_now: 0.2943715453147888\n","batch_acc: 0.95\n","loss_now: 0.054437290877103806\n","batch_acc: 1.0\n","loss_now: 0.0895608514547348\n","batch_acc: 0.95\n","tot_loss: 0.21918388281017542, accuracy: 0.9405\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy\n","from sklearn import metrics\n","\n","\n","confusion_matrix = metrics.confusion_matrix(act_y, pred_y)\n","\n","cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix,display_labels=[\"state1\",\"state2\",\"state3\"])\n","plt.figure(figsize=(10,10))\n","cm_display.plot()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"0BMPK5tOySfE","executionInfo":{"status":"ok","timestamp":1700514174087,"user_tz":-330,"elapsed":612,"user":{"displayName":"Coral Reef","userId":"08596900024327775576"}},"outputId":"b551c119-86c4-4bbf-e2bd-b28a97315ffd"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x1000 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["\"\"\"\n","LSM710(sullied):\n","  CentreResnet50: Train->95-97 Test-> 96\n","  CentreVGG16: Train->95-97 Test->95\n","LSD1:\n","  CentreResnet:CentreResnet,98.6,96.5\n","  CentreVGG16:CentreVGG16,98.5,93.8\n","\n","\"\"\""],"metadata":{"id":"jAvXk4AtU0Hg"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1_S8-iZlo90783yJGZMnEVFAPX1cF7_UM","authorship_tag":"ABX9TyM0WbBv2h123Xj9FLSpZSZ0"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}